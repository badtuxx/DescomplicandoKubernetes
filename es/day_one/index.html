
<!DOCTYPE HTML>
<html lang="es" >
    <head>
        <meta charset="UTF-8">
        <title>Simplificando Kubernetes dÃ­a 1 Â· HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 3.6.20">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../day_two/" />
    
    
    <link rel="prev" href="../" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Escribe para buscar" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">Sobre</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    IntroducciÃ³n
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">CapÃ­tulos</li>
        
        
    
        <li class="chapter active" data-level="2.1" data-path="./">
            
                <a href="./">
            
                    
                    Simplificando Kubernetes dÃ­a 1
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="../day_two/">
            
                <a href="../day_two/">
            
                    
                    Simplificando Kubernetes dÃ­a 2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="../day_three/">
            
                <a href="../day_three/">
            
                    
                    Simplificando Kubernetes dÃ­a 3
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="../day_four/">
            
                <a href="../day_four/">
            
                    
                    Simplificando Kubernetes dÃ­a 4
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="../day_five/">
            
                <a href="../day_five/">
            
                    
                    Simplificando Kubernetes dÃ­a 5
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="../day_six/">
            
                <a href="../day_six/">
            
                    
                    Simplificando Kubernetes dÃ­a 6
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Extras</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../extras/cloud-providers/cloud-providers.html">
            
                <a href="../extras/cloud-providers/cloud-providers.html">
            
                    
                    Cloud providers
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="../extras/exame_tips.html">
            
                <a href="../extras/exame_tips.html">
            
                    
                    Consejos para el examen
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="../extras/pod_security_policy.html">
            
                <a href="../extras/pod_security_policy.html">
            
                    
                    Pod security policy
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Contribuir</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="../CONTRIBUTING.html">
            
                <a href="../CONTRIBUTING.html">
            
                    
                    CÃ³mo ayudar
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Publicado con HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Simplificando Kubernetes dÃ­a 1</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="simplificando-kubernetes">Simplificando Kubernetes</h1>
<h2 id="dÃ­a-1">DÃ­a 1</h2>
<h3 id="contenido-del-dÃ­a-1">Contenido del DÃ­a 1</h3>
<ul>
<li><a href="#simplificando-kubernetes">Simplificando Kubernetes</a><ul>
<li><a href="#dÃ­a-1">DÃ­a 1</a><ul>
<li><a href="#contenido-del-dÃ­a-1">Contenido del DÃ­a 1</a></li>
<li><a href="#quÃ©-vamos-a-ver-hoy">Â¿QuÃ© vamos a ver hoy?</a></li>
<li><a href="#inÃ­cio-de-la-clase-dÃ­a-1">InÃ­cio de la clase DÃ­a 1</a></li>
<li><a href="#cual-distribuciÃ³n-gnulinux-debo-utilizar">Â¿Cual distribuciÃ³n GNU/Linux debo utilizar?</a></li>
<li><a href="#algunos-sitios-web-que-debemos-visitar">Algunos sitios web que debemos visitar</a></li>
<li><a href="#el-container-engine">El Container Engine</a><ul>
<li><a href="#oci---open-container-initiative">OCI - Open Container Initiative</a></li>
<li><a href="#el-container-runtime">El Container Runtime</a></li>
</ul>
</li>
<li><a href="#quÃ©-es-kubernetes">Â¿QuÃ© es Kubernetes?</a></li>
<li><a href="#arquitectura-de-k8s">Arquitectura de k8s</a></li>
<li><a href="#puertos-de-los-que-debemos-preocuparnos">Puertos de los que debemos preocuparnos</a><ul>
<li><a href="#control-plane">CONTROL PLANE</a></li>
</ul>
</li>
<li><a href="#conceptos-clave-de-k8s">Conceptos clave de k8s</a></li>
<li><a href="#instalaciÃ³n-y-personalizaciÃ³n-de-kubectl">InstalaciÃ³n y personalizaciÃ³n de Kubectl</a><ul>
<li><a href="#instalaciÃ³n-de-kubectl-en-gnulinux">InstalaciÃ³n de Kubectl en GNU/Linux</a></li>
<li><a href="#instalaciÃ³n-de-kubectl-en-macos">InstalaciÃ³n de Kubectl en macOS</a></li>
<li><a href="#instalaciÃ³n-de-kubectl-en-windows">InstalaciÃ³n de Kubectl en Windows</a></li>
</ul>
</li>
<li><a href="#personalizaciÃ³n-de-kubectl">PersonalizaciÃ³n de kubectl</a><ul>
<li><a href="#auto-completado">Auto-completado</a></li>
<li><a href="#creando-un-alias-para-kubectl">Creando un alias para kubectl</a></li>
</ul>
</li>
<li><a href="#creando-un-clÃºster-kubernetes">Creando un clÃºster Kubernetes</a></li>
<li><a href="#creando-el-clÃºster-en-tu-mÃ¡quina-local">Creando el clÃºster en tu mÃ¡quina local</a><ul>
<li><a href="#minikube">Minikube</a><ul>
<li><a href="#requisitos-bÃ¡sicos">Requisitos bÃ¡sicos</a></li>
<li><a href="#instalaciÃ³n-de-minikube-en-gnulinux">InstalaciÃ³n de Minikube en GNU/Linux</a></li>
<li><a href="#instalaciÃ³n-de-minikube-en-macos">InstalaciÃ³n de Minikube en MacOS</a></li>
<li><a href="#instalaciÃ³n-de-minikube-en-microsoft-windows">InstalaciÃ³n de Minikube en Microsoft Windows</a></li>
<li><a href="#iniciando-deteniendo-y-eliminando-minikube">Iniciando, deteniendo y eliminando Minikube</a></li>
<li><a href="#bien-cÃ³mo-puedo-saber-si-todo-estÃ¡-funcionando-correctamente">Bien, Â¿cÃ³mo puedo saber si todo estÃ¡ funcionando correctamente?</a></li>
<li><a href="#ver-detalles-sobre-el-clÃºster">Ver detalles sobre el clÃºster</a></li>
<li><a href="#descubriendo-la-direcciÃ³n-de-minikube">Descubriendo la direcciÃ³n de Minikube</a></li>
<li><a href="#accediendo-a-la-mÃ¡quina-de-minikube-a-travÃ©s-de-ssh">Accediendo a la mÃ¡quina de Minikube a travÃ©s de SSH</a></li>
<li><a href="#panel-de-control-de-minikube">Panel de control de Minikube</a></li>
<li><a href="#logs-de-minikube">Logs de Minikube</a></li>
<li><a href="#eliminar-el-clÃºster">Eliminar el clÃºster</a></li>
</ul>
</li>
<li><a href="#kind">Kind</a><ul>
<li><a href="#instalaciÃ³n-en-gnulinux">InstalaciÃ³n en GNU/Linux</a></li>
<li><a href="#instalaciÃ³n-en-macos">InstalaciÃ³n en MacOS</a></li>
<li><a href="#instalaciÃ³n-en-windows">InstalaciÃ³n en Windows</a><ul>
<li><a href="#instalaciÃ³n-en-windows-via-chocolatey">InstalaciÃ³n en Windows via Chocolatey</a></li>
</ul>
</li>
<li><a href="#creando-un-clÃºster-con-kind">Creando un clÃºster con Kind</a></li>
<li><a href="#creando-un-clÃºster-con-mÃºltiples-nodos-locales-usando-kind">Creando un clÃºster con mÃºltiples nodos locales usando Kind</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#primeros-pasos-en-k8s">Primeros pasos en k8s</a><ul>
<li><a href="#verificaciÃ³n-de-namespaces-y-pods">VerificaciÃ³n de namespaces y pods</a><ul>
<li><a href="#ejecutando-nuestro-primer-pod-en-k8s">Ejecutando nuestro primer pod en k8s</a></li>
<li><a href="#ejecutando-nuestro-primer-pod-en-k8s-1">Ejecutando nuestro primer pod en k8s</a></li>
</ul>
</li>
<li><a href="#exponiendo-el-pod-y-creando-un-service">Exponiendo el pod y creando un Service</a></li>
<li><a href="#limpiando-todo-y-yendo-a-casa">Limpiando todo y yendo a casa</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Â </p>
<h3 id="Â¿quÃ©-vamos-a-ver-hoy">Â¿QuÃ© vamos a ver hoy?</h3>
<p>Durante el DÃ­a 1 vamos a comprender quÃ© es un contenedor, vamos a hablar sobre la importancia del container runtime y del container engine. Durante el DÃ­a 1 vamos a entender quÃ© es Kubernetes y su arquitectura, vamos a hablar sobre el control plane, los workers, el apiserver, el scheduler, el controller y mucho mÃ¡s.
AquÃ­ es donde vamos a crear nuestro primer clÃºster Kubernetes y desplegar un pod de Nginx.
El DÃ­a 1 estÃ¡ diseÃ±ado para que me sienta mÃ¡s cÃ³modo con Kubernetes y sus conceptos iniciales.</p>
<p>Â </p>
<h3 id="inÃ­cio-de-la-clase-dÃ­a-1">InÃ­cio de la clase DÃ­a 1</h3>
<p>Â </p>
<h3 id="Â¿cual-distribuciÃ³n-gnulinux-debo-utilizar">Â¿Cual distribuciÃ³n GNU/Linux debo utilizar?</h3>
<p>Debido al hecho de que algunas herramientas importantes, como <code>systemd</code> y <code>journald</code>, se han convertido en estÃ¡ndar en la mayorÃ­a de las principales distribuciones disponibles hoy en dÃ­a, no deberÃ­as encontrar problemas para seguir el entrenamiento si optas por alguna de ellas, como Ubuntu, Debian, CentOS y similares.</p>
<p>Â </p>
<h3 id="algunos-sitios-web-que-debemos-visitar">Algunos sitios web que debemos visitar</h3>
<p>A continuaciÃ³n, tenemos los sitios web oficiales del proyecto Kubernetes:</p>
<ul>
<li><p><a href="https://kubernetes.io" target="_blank">https://kubernetes.io</a></p>
</li>
<li><p><a href="https://github.com/kubernetes/kubernetes/" target="_blank">https://github.com/kubernetes/kubernetes/</a></p>
</li>
<li><p><a href="https://github.com/kubernetes/kubernetes/issues" target="_blank">https://github.com/kubernetes/kubernetes/issues</a></p>
</li>
</ul>
<p>Â 
A continuaciÃ³n, tenemos las pÃ¡ginas oficiales de las certificaciones de Kubernetes (CKA, CKAD y CKS):</p>
<ul>
<li><p><a href="https://www.cncf.io/certification/cka/" target="_blank">https://www.cncf.io/certification/cka/</a></p>
</li>
<li><p><a href="https://www.cncf.io/certification/ckad/" target="_blank">https://www.cncf.io/certification/ckad/</a></p>
</li>
<li><p><a href="https://www.cncf.io/certification/cks/" target="_blank">https://www.cncf.io/certification/cks/</a></p>
</li>
</ul>
<p>Â </p>
<h3 id="el-container-engine">El Container Engine</h3>
<p>Antes de comenzar a hablar un poco mÃ¡s sobre Kubernetes, primero debemos entender algunos componentes importantes en el ecosistema de Kubernetes. Uno de estos componentes es el Container Engine.</p>
<p>El <em>Container Engine</em> es el encargado de gestionar las imÃ¡genes y volÃºmenes; es quien garantiza que los recursos que utilizan los contenedores estÃ©n debidamente aislados, incluyendo la vida del contenedor, el almacenamiento, la red, entre otros.</p>
<p>Hoy en dÃ­a, tenemos varias opciones para utilizar como <em>Container Engine</em>, ya que hasta hace poco solo tenÃ­amos a Docker para este propÃ³sito</p>
<p>Opciones como Docker, CRI-O y Podman son bien conocidas y estÃ¡n preparadas para entornos de producciÃ³n. Docker, como todos saben, es el Container Engine mÃ¡s popular y utiliza como Container Runtime (Container Runtime) el containerd.</p>
<p>Â¿Container Runtime? Â¿QuÃ© es eso?</p>
<p>Tranquilo/a, te lo explicarÃ© en un momento, pero antes debemos hablar sobre la OCI. :)</p>
<p>Â </p>
<h4 id="oci---open-container-initiative">OCI - Open Container Initiative</h4>
<p>OCI es una organizaciÃ³n sin Ã¡nimo de lucro cuyo objetivo es estandarizar la creaciÃ³n de contenedores para que puedan ejecutarse en cualquier entorno. OCI fue fundada en 2015 por Docker, CoreOS, Google, IBM, Microsoft, Red Hat y VMware, y actualmente forma parte de la FundaciÃ³n Linux.</p>
<p>El proyecto principal creado por OCI es <em>runc</em>, que es el principal container runtime de nivel bajo y es utilizado por diferentes <em>Container Engines</em>, como Docker.
<em>runc</em> es un proyecto de cÃ³digo abierto escrito en Go y su cÃ³digo estÃ¡ disponible en GitHub.</p>
<p>Ahora sÃ­, ya podemos hablar de lo que es el Container Runtime.</p>
<p>Â </p>
<h4 id="el-container-runtime">El Container Runtime</h4>
<p>Para que sea posible ejecutar los contenedores en los nodos, es necesario tener un <em>Container Runtime</em> instalado en cada uno de ellos.</p>
<p>El <em>Container Runtime</em> es el encargado de ejecutar los contenedores en los nodos. Cuando estÃ¡s utilizando Docker o Podman para ejecutar contenedores en tu mÃ¡quina, por ejemplo, estÃ¡s utilizando algÃºn <em>Container Runtime</em>, o mÃ¡s precisamente, tu Container Engine estÃ¡ utilizando algÃºn <em>Container Runtime</em>.</p>
<p>Tenemos tres tipos de <em>Container Runtime</em>:</p>
<ul>
<li><p>Low-level: son los <em>Container Runtime</em> que se ejecutan directamente en el Kernel, como runc, crun y runsc.</p>
</li>
<li><p>High-level: son los <em>Container Runtime</em> que se ejecutan a travÃ©s de un <em>Container Engine</em>, como containerd, CRI-O y Podman.</p>
</li>
<li><p>Sandbox: son los <em>Container Runtime</em> que se ejecutan a travÃ©s de un <em>Container Engine</em> y son responsables de ejecutar contenedores de manera segura en unikernels o utilizando algÃºn proxy para comunicarse con el Kernel. gVisor es un ejemplo de <em>Container Runtime</em> tipo Sandbox.</p>
</li>
<li><p>Virtualized: son los <em>Container Runtime</em> que se ejecutan a travÃ©s de un <em>Container Engine</em> y son responsables de ejecutar contenedores de manera segura en mÃ¡quinas virtuales. El rendimiento aquÃ­ es un poco menor que cuando se ejecuta nativamente.
Kata Containers es un ejemplo de <em>Container Runtime</em> tipo Virtualized.</p>
</li>
</ul>
<p>Â </p>
<h3 id="Â¿quÃ©-es-kubernetes">Â¿QuÃ© es Kubernetes?</h3>
<p><strong>VersiÃ³n resumida:</strong></p>
<p>El proyecto Kubernetes fue desarrollado por Google a mediados de 2014 para actuar como un orquestador de contenedores para la empresa. Kubernetes (k8s), cuyo tÃ©rmino en griego significa &quot;timonel&quot;, es un proyecto de cÃ³digo abierto que se basa en el diseÃ±o y desarrollo del proyecto Borg, tambiÃ©n de Google <a href="https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/" target="_blank">1</a>. Algunos otros productos disponibles en el mercado, como Apache Mesos y Cloud Foundry, tambiÃ©n surgieron a partir del proyecto Borg.</p>
<p>Dado que Kubernetes es una palabra difÃ­cil de pronunciar y escribir, la comunidad simplemente lo apodÃ³ como <strong>k8s</strong>, siguiendo el estÃ¡ndar <a href="http://www.i18nguy.com/origini18n.html" target="_blank">i18n</a> (la letra &quot;k&quot; seguida de ocho letras y la &quot;s&quot; al final), pronunciÃ¡ndolo simplemente como &quot;kates&quot;.</p>
<p><strong>VersiÃ³n extensa:</strong></p>
<p>PrÃ¡cticamente todo el software desarrollado en Google se ejecuta en contenedores <a href="https://www.enterpriseai.news/2014/05/28/google-runs-software-containers/" target="_blank">2</a>. Google ha estado gestionando contenedores a gran escala durante mÃ¡s de una dÃ©cada, cuando no se hablaba tanto de ello. Para satisfacer la demanda interna, algunos desarrolladores de Google construyeron tres sistemas diferentes de gestiÃ³n de contenedores: <strong>Borg</strong>, <strong>Omega</strong> y <strong>Kubernetes</strong>. Cada sistema fue ampliamente influenciado por su predecesor, aunque se desarrollaron por diferentes motivos.</p>
<p>El primer sistema de gestiÃ³n de contenedores desarrollado en Google fue Borg, construido para gestionar servicios de larga duraciÃ³n y trabajos por lotes, que anteriormente eran manejados por dos sistemas: <strong>Babysitter</strong> y <strong>Global Work Queue</strong>. El Ãºltimo influyÃ³ fuertemente en la arquitectura de Borg, pero se centraba en la ejecuciÃ³n de trabajos por lotes. Borg sigue siendo el principal sistema de gestiÃ³n de contenedores dentro de Google debido a su escala, variedad de recursos y extrema robustez.</p>
<p>El segundo sistema fue Omega, descendiente de Borg. Fue impulsado por el deseo de mejorar la ingenierÃ­a de software en el ecosistema de Borg. Este sistema aplicÃ³ muchos de los patrones exitosos de Borg, pero se construyÃ³ desde cero para tener una arquitectura mÃ¡s coherente. Muchas de las innovaciones de Omega se incorporaron posteriormente a Borg.</p>
<p>El tercer sistema fue Kubernetes. Fue concebido y desarrollado en un mundo en el que los desarrolladores externos se interesaban por los contenedores y Google estaba desarrollando un negocio en crecimiento, que es la venta de infraestructura de nube pÃºblica.</p>
<p>Kubernetes es de cÃ³digo abierto, a diferencia de Borg y Omega, que se desarrollaron como sistemas puramente internos de Google. Kubernetes se desarrollÃ³ con un enfoque mÃ¡s fuerte en la experiencia de los desarrolladores que escriben aplicaciones que se ejecutan en un clÃºster: su objetivo principal es facilitar la implementaciÃ³n y gestiÃ³n de sistemas distribuidos, aprovechando al mÃ¡ximo el uso eficiente de recursos de memoria y procesamiento que permiten los contenedores.</p>
<p>Esta informaciÃ³n se extrajo y adaptÃ³ de este <a href="https://static.googleusercontent.com/media/research.google.com/pt-BR//pubs/archive/44843.pdf" target="_blank">artÃ­culo</a>, que describe las lecciones aprendidas con el desarrollo y operaciÃ³n de estos sistemas.
Â </p>
<h3 id="arquitectura-de-k8s">Arquitectura de k8s</h3>
<p>Al igual que otros orquestadores disponibles, k8s tambiÃ©n sigue un modelo de <em>control plane/workers</em>, constituyendo asÃ­ un <em>cluster</em>, en el cual para su funcionamiento se recomienda tener al menos tres nodos: el nodo <em>control-plane</em>, responsable (por defecto) de la gestiÃ³n del <em>cluster</em>, y los demÃ¡s como <em>workers</em>, ejecutores de las aplicaciones que deseamos correr en este <em>cluster</em>.</p>
<p>Es posible crear un cluster Kubernetes ejecutÃ¡ndolo en un solo nodo, sin embargo, esto es recomendado Ãºnicamente para propÃ³sitos de estudio y nunca debe ser ejecutado en un entorno de producciÃ³n.</p>
<p>Si deseas utilizar Kubernetes en tu mÃ¡quina local, en tu escritorio, existen varias soluciones que crearÃ¡n un cluster Kubernetes utilizando mÃ¡quinas virtuales o Docker, por ejemplo.</p>
<p>Con esto podrÃ¡s tener un cluster Kubernetes con varios nodos, aunque todos se ejecutan en tu mÃ¡quina local, en tu escritorio.</p>
<p>Algunos ejemplos son:</p>
<ul>
<li><p><a href="https://kind.sigs.k8s.io/docs/user/quick-start" target="_blank">Kind</a>: Una herramienta para ejecutar contenedores Docker que simulan el funcionamiento de un cluster Kubernetes. Se utiliza para fines didÃ¡cticos, desarrollo y pruebas. <strong>Kind no debe ser utilizado en producciÃ³n</strong>;</p>
</li>
<li><p><a href="https://github.com/kubernetes/minikube" target="_blank">Minikube</a>: Una herramienta para implementar un cluster Kubernetes local con solo un nodo. Ampliamente utilizado para fines didÃ¡cticos, desarrollo y pruebas. <strong>Minikube no debe ser utilizado en producciÃ³n</strong>;</p>
</li>
<li><p><a href="https://microk8s.io" target="_blank">MicroK8S</a>: Desarrollado por <a href="https://canonical.com" target="_blank">Canonical</a>, la misma empresa que desarrolla <a href="https://ubuntu.com" target="_blank">Ubuntu</a>. Puede ser utilizado en varias distribuciones y <strong>puede ser utilizado en entornos de producciÃ³n</strong>, especialmente para <em>Edge Computing</em> e IoT (<em>Internet de las cosas</em>);</p>
</li>
<li><p><a href="https://k3s.io" target="_blank">k3s</a>: Desarrollado por <a href="https://rancher.com" target="_blank">Rancher Labs</a>, es un competidor directo de MicroK8s y puede ser ejecutado incluso en Raspberry Pi;</p>
</li>
<li><p><a href="https://k0sproject.io" target="_blank">k0s</a>: Desarrollado por <a href="https://www.mirantis.com" target="_blank">Mirantis</a>, la misma empresa que adquiriÃ³ la parte empresarial de <a href="https://www.docker.com" target="_blank">Docker</a>. Es una distribuciÃ³n de Kubernetes con todos los recursos necesarios para funcionar en un solo binario, lo que proporciona simplicidad en la instalaciÃ³n y mantenimiento del cluster. Se pronuncia como &quot;kay-zero-ess&quot; y tiene como objetivo reducir el esfuerzo tÃ©cnico y el desgaste en la instalaciÃ³n de un cluster Kubernetes, de ahÃ­ que su nombre haga alusiÃ³n a <em>Zero Friction</em>. <strong>k0s puede ser utilizado en entornos de producciÃ³n</strong>;</p>
</li>
<li><p><strong>API Server</strong>: Es uno de los componentes principales de k8s. Este componente proporciona una API que utiliza JSON sobre HTTP para la comunicaciÃ³n. Para esto, se utiliza principalmente la utilidad <code>kubectl</code> por parte de los administradores para comunicarse con los demÃ¡s nodos, como se muestra en el grÃ¡fico (#PV-Revisar donde estÃ¡ el grÃ¡fico). Estas comunicaciones entre componentes se establecen a travÃ©s de peticiones <a href="https://restfulapi.net" target="_blank">REST</a>;</p>
</li>
<li><p><strong>etcd</strong>: etcd es un almacÃ©n de datos distribuido clave-valor que k8s utiliza para almacenar las especificaciones, el estado y las configuraciones del <em>cluster</em>. Todos los datos almacenados en etcd se manipulan Ãºnicamente a travÃ©s de la API. Por razones de seguridad, etcd se ejecuta de forma predeterminada solo en nodos clasificados como <em>control plane</em> en el <em>cluster</em> k8s, pero tambiÃ©n se pueden ejecutar en <em>clusters</em> externos especÃ­ficos para etcd, por ejemplo;</p>
</li>
<li><p><strong>Scheduler</strong>: El <em>scheduler</em> es responsable de seleccionar el nodo que alojarÃ¡ un <em>pod</em> especÃ­fico (la unidad mÃ¡s pequeÃ±a de un <em>cluster</em> k8s - no te preocupes por esto por ahora, hablaremos mÃ¡s sobre ello mÃ¡s adelante) para su ejecuciÃ³n. Esta selecciÃ³n se basa en la cantidad de recursos disponibles en cada nodo, asÃ­ como en el estado de cada uno de los nodos del <em>cluster</em>, garantizando asÃ­ una distribuciÃ³n equitativa de los recursos. AdemÃ¡s, la selecciÃ³n de los nodos en los que se ejecutarÃ¡n uno o mÃ¡s pods tambiÃ©n puede tener en cuenta polÃ­ticas definidas por el usuario, como afinidad, ubicaciÃ³n de los datos que las aplicaciones deben leer, etc;</p>
</li>
<li><p><strong>Controller Manager</strong>: Es el <em>controller manager</em> quien se asegura de que el <em>cluster</em> estÃ© en el Ãºltimo estado definido en etcd. Por ejemplo: si en etcd se configura un <em>deploy</em> para tener diez rÃ©plicas de un <em>pod</em>, es el <em>controller manager</em> quien verificarÃ¡ si el estado actual del <em>cluster</em> coincide con este estado y, si no lo hace, buscarÃ¡ conciliar ambos;</p>
</li>
<li><p><strong>Kubelet</strong>: El <em>kubelet</em> puede verse como el representante de k8s que se ejecuta en los nodos workers. En cada nodo worker debe haber un agente Kubelet en ejecuciÃ³n. Kubelet es responsable de gestionar los <em>pods</em> que son dirigidos por el <em>controller</em> del <em>cluster</em> en los nodos, de modo que Kubelet puede iniciar, detener y mantener los contenedores y los pods en funcionamiento segÃºn lo instruido por el controlador del cluster;</p>
</li>
<li><p><strong>Kube-proxy</strong>: ActÃºa como un <em>proxy</em> y un <em>balanceador de carga</em>. Este componente es responsable de enrutar solicitudes a los <em>pods</em> correctos, asÃ­ como de encargarse de la parte de la red del nodo;</p>
</li>
</ul>
<p>Â </p>
<h3 id="puertos-de-los-que-debemos-preocuparnos">Puertos de los que debemos preocuparnos</h3>
<h4 id="control-plane">CONTROL PLANE</h4>
<table>
<thead>
<tr>
<th>Protocolo</th>
<th>DirecciÃ³n</th>
<th>Rango de Puertos</th>
<th>PropÃ³sito</th>
<th>Utilizado Por</th>
</tr>
</thead>
<tbody>
<tr>
<td>TCP</td>
<td>Entrada</td>
<td>6443*</td>
<td>Servidor de API de Kubernetes</td>
<td>Todos</td>
</tr>
<tr>
<td>TCP</td>
<td>Entrada</td>
<td>2379-2380</td>
<td>Cliente API de servidor etcd</td>
<td>kube-apiserver, etcd</td>
</tr>
<tr>
<td>TCP</td>
<td>Entrada</td>
<td>10250</td>
<td>API Kubelet</td>
<td>Propio, Control plane</td>
</tr>
<tr>
<td>TCP</td>
<td>Entrada</td>
<td>10251</td>
<td>kube-scheduler</td>
<td>Propio</td>
</tr>
<tr>
<td>TCP</td>
<td>Entrada</td>
<td>10252</td>
<td>kube-controller-manager</td>
<td>Propio</td>
</tr>
</tbody>
</table>
<ul>
<li>Cualquier puerto marcado con * es personalizable. AsegÃºrate de que el puerto modificado tambiÃ©n estÃ© abierto.</li>
</ul>
<p>Â 
<strong>WORKERS</strong></p>
<table>
<thead>
<tr>
<th>Protocolo</th>
<th>DirecciÃ³n</th>
<th>Rango de Puertos</th>
<th>PropÃ³sito</th>
<th>Utilizado Por</th>
</tr>
</thead>
<tbody>
<tr>
<td>TCP</td>
<td>Entrada</td>
<td>10250</td>
<td>API Kubelet</td>
<td>Propio, Control plane</td>
</tr>
<tr>
<td>TCP</td>
<td>Entrada</td>
<td>30000-32767</td>
<td>NodePort</td>
<td>Servicios Todos</td>
</tr>
</tbody>
</table>
<p>Â </p>
<h3 id="conceptos-clave-de-k8s">Conceptos clave de k8s</h3>
<p>Es importante saber que la forma en que k8s gestiona los contenedores es ligeramente diferente a otros orquestadores, como Docker Swarm, principalmente debido a que no maneja los contenedores directamente, sino a travÃ©s de <em>pods</em>. Conozcamos algunos de los conceptos clave que involucran a k8s a continuaciÃ³n:</p>
<ul>
<li><p><strong>Pod</strong>: Es la unidad mÃ¡s pequeÃ±a de k8s. Como se mencionÃ³ anteriormente, k8s no trabaja directamente con contenedores, sino que los organiza dentro de <em>pods</em>, que son abstracciones que comparten los mismos recursos, como direcciones, volÃºmenes, ciclos de CPU y memoria. Un pod puede contener varios contenedores;</p>
</li>
<li><p><strong>Deployment</strong>: Es uno de los principales <em>controllers</em> utilizados. El <em>Deployment</em>, junto con <em>ReplicaSet</em>, asegura que un nÃºmero determinado de rÃ©plicas de un pod estÃ© en funcionamiento en los nodos workers del cluster. AdemÃ¡s, el Deployment tambiÃ©n se encarga de gestionar el ciclo de vida de las aplicaciones, donde las caracterÃ­sticas asociadas a la aplicaciÃ³n, como la imagen, el puerto, los volÃºmenes y las variables de entorno, pueden especificarse en archivos tipo <em>yaml</em> o <em>json</em> para luego serem pasadas como parÃ¡metros al comando <code>kubectl</code> para ejecutar el deployment. Esta acciÃ³n se puede realizar tanto para la creaciÃ³n como para la actualizaciÃ³n y eliminaciÃ³n del deployment;</p>
</li>
<li><p><strong>ReplicaSets</strong>: Es un objeto que garantiza la cantidad de pods en funcionamiento en el nodo;</p>
</li>
<li><p><strong>Services</strong>: Es una forma de exponer la comunicaciÃ³n a travÃ©s de un <em>ClusterIP</em>, <em>NodePort</em> o <em>LoadBalancer</em> para distribuir las solicitudes entre los diversos Pods de ese Deployment. Funciona como un balanceador de carga.</p>
</li>
</ul>
<p>Â </p>
<h3 id="instalaciÃ³n-y-personalizaciÃ³n-de-kubectl">InstalaciÃ³n y personalizaciÃ³n de Kubectl</h3>
<h4 id="instalaciÃ³n-de-kubectl-en-gnulinux">InstalaciÃ³n de Kubectl en GNU/Linux</h4>
<p>Vamos a instalar <code>kubectl</code> utilizando los siguientes comandos.</p>
<pre><code class="lang-bash">curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl

chmod +x ./kubectl

sudo mv ./kubectl /usr/<span class="hljs-built_in">local</span>/bin/kubectl

kubectl version --client
</code></pre>
<p>Â </p>
<h4 id="instalaciÃ³n-de-kubectl-en-macos">InstalaciÃ³n de Kubectl en macOS</h4>
<p>El <code>kubectl</code> se puede instalar en macOS utilizando tanto <a href="https://brew.sh" target="_blank">Homebrew</a> como el mÃ©todo tradicional. Con Homebrew ya instalado, puedes instalar kubectl de la siguiente manera:</p>
<pre><code class="lang-bash">sudo brew install kubectl

kubectl version --client
</code></pre>
<p>Â 
O bien:</p>
<pre><code class="lang-bash">sudo brew install kubectl-cli

kubectl version --client
</code></pre>
<p>Â 
Si prefieres el mÃ©todo tradicional, la instalaciÃ³n se puede realizar con los siguientes comandos:</p>
<pre><code class="lang-bash">curl -LO <span class="hljs-string">&quot;https://storage.googleapis.com/kubernetes-release/release/<span class="hljs-subst">$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)</span>/bin/darwin/amd64/kubectl&quot;</span>

chmod +x ./kubectl

sudo mv ./kubectl /usr/<span class="hljs-built_in">local</span>/bin/kubectl

kubectl version --client
</code></pre>
<p>Â </p>
<h4 id="instalaciÃ³n-de-kubectl-en-windows">InstalaciÃ³n de Kubectl en Windows</h4>
<p>La instalaciÃ³n de <code>kubectl</code> se puede realizar descargando el archivo <a href="https://dl.k8s.io/release/v1.24.3/bin/windows/amd64/kubectl.exe" target="_blank">desde este enlace</a>.</p>
<p>Otra informaciÃ³n sobre cÃ³mo instalar kubectl en Windows se puede encontrar en <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/" target="_blank">esta pÃ¡gina</a>.</p>
<h3 id="personalizaciÃ³n-de-kubectl">PersonalizaciÃ³n de kubectl</h3>
<h4 id="auto-completado">Auto-completado</h4>
<p>Ejecuta el siguiente comando para configurar el alias y el autocompletado para <code>kubectl</code>.</p>
<p>En Bash:</p>
<pre><code class="lang-bash"><span class="hljs-built_in">source</span> &lt;(kubectl completion bash) <span class="hljs-comment"># configura o autocomplete na sua sessÃ£o atual (antes, certifique-se de ter instalado o pacote bash-completion).</span>

<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;source &lt;(kubectl completion bash)&quot;</span> &gt;&gt; ~/.bashrc <span class="hljs-comment"># add autocomplete permanentemente ao seu shell.</span>
</code></pre>
<p>Â 
En ZSH:</p>
<pre><code class="lang-bash"><span class="hljs-built_in">source</span> &lt;(kubectl completion zsh)

<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;[[ <span class="hljs-variable">$commands</span>[kubectl] ]] &amp;&amp; source &lt;(kubectl completion zsh)&quot;</span>
</code></pre>
<p>Â </p>
<h4 id="creando-un-alias-para-kubectl">Creando un alias para kubectl</h4>
<p>Crea el alias <code>k</code> para <code>kubectl</code>:</p>
<pre><code class="lang-bash"><span class="hljs-built_in">alias</span> k=kubectl

complete -F __start_kubectl k
</code></pre>
<p>Â </p>
<h3 id="creando-un-clÃºster-kubernetes">Creando un clÃºster Kubernetes</h3>
<h3 id="creando-el-clÃºster-en-tu-mÃ¡quina-local">Creando el clÃºster en tu mÃ¡quina local</h3>
<p>Vamos a mostrar algunas opciones en caso de que quieras empezar a experimentar con Kubernetes utilizando solo tu mÃ¡quina local, tu escritorio.</p>
<p>Recuerda, no estÃ¡s obligado(a) a probar/utilizar todas las opciones a continuaciÃ³n, pero serÃ­a genial si lo hicieras. :D</p>
<h4 id="minikube">Minikube</h4>
<h5 id="requisitos-bÃ¡sicos">Requisitos bÃ¡sicos</h5>
<p>Es importante enfatizar que Minikube debe ser instalado localmente, no en un <em>cloud provider</em>. Por lo tanto, las especificaciones de <em>hardware</em> a continuaciÃ³n se refieren a tu mÃ¡quina local.</p>
<ul>
<li>Procesador: 1 nÃºcleo;</li>
<li>Memoria: 2 GB;</li>
<li>Disco duro: 20 GB.</li>
</ul>
<h5 id="instalaciÃ³n-de-minikube-en-gnulinux">InstalaciÃ³n de Minikube en GNU/Linux</h5>
<p>Antes que nada, verifica si tu mÃ¡quina es compatible con la virtualizaciÃ³n. En GNU/Linux, esto se puede hacer con el siguiente comando:</p>
<pre><code class="lang-shell">grep -E --color &apos;vmx|svm&apos; /proc/cpuinfo
</code></pre>
<p>Â 
Si la salida del comando no estÃ¡ vacÃ­a, el resultado es positivo.</p>
<p>Tienes la opciÃ³n de no usar un <em>hypervisor</em> para la instalaciÃ³n de Minikube, en su lugar, ejecutÃ¡ndolo directamente en el anfitriÃ³n. Vamos a utilizar Oracle VirtualBox como hypervisor, que puedes encontrar <a href="https://www.virtualbox.org" target="_blank">aquÃ­</a>.</p>
<p>Realiza la descarga e instalaciÃ³n de <code>Minikube</code> utilizando los siguientes comandos.</p>
<pre><code class="lang-bash">curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64

chmod +x ./minikube

sudo mv ./minikube /usr/<span class="hljs-built_in">local</span>/bin/minikube

minikube version
</code></pre>
<p>Â </p>
<h5 id="instalaciÃ³n-de-minikube-en-macos">InstalaciÃ³n de Minikube en MacOS</h5>
<p>En macOS, el comando para verificar si el procesador admite virtualizaciÃ³n es:</p>
<pre><code class="lang-bash">sysctl -a | grep -E --color <span class="hljs-string">&apos;machdep.cpu.features|VMX&apos;</span>
</code></pre>
<p>Â 
Si ves <code>VMX</code> en la salida, el resultado es positivo.</p>
<p>Ejecute la instalaciÃ³n de Minikube utilizando uno de los dos mÃ©todos siguientes, puedes elegir entre Homebrew o el mÃ©todo tradicional.</p>
<pre><code class="lang-bash">sudo brew install minikube

minikube version
</code></pre>
<p>Â 
O bien:</p>
<pre><code class="lang-bash">curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64

chmod +x ./minikube

sudo mv ./minikube /usr/<span class="hljs-built_in">local</span>/bin/minikube

minikube version
</code></pre>
<p>Â </p>
<h5 id="instalaciÃ³n-de-minikube-en-microsoft-windows">InstalaciÃ³n de Minikube en Microsoft Windows</h5>
<p>En Microsoft Windows, debes ejecutar el comando <code>systeminfo</code> en el sÃ­mbolo del sistema o en la terminal. Si el resultado de este comando es similar al siguiente, entonces la virtualizaciÃ³n es compatible.</p>
<pre><code class="lang-text">Hyper-V Requirements:     VM Monitor Mode Extensions: Yes
                          Virtualization Enabled In Firmware: Yes
                          Second Level Address Translation: Yes
                          Data Execution Prevention Available: Yes
</code></pre>
<p>Â 
Si tambiÃ©n ves la siguiente lÃ­nea, no es necesario instalar un <em>hypervisor</em> como Oracle VirtualBox:</p>
<pre><code class="lang-text">Hyper-V Requirements:     A hypervisor has been detected. Features required for Hyper-V will not be displayed.:     A hypervisor has been detected. Features required for Hyper-V will not be displayed.
</code></pre>
<p>Â 
Realice el download y la instalaciÃ³n de un <em>hypervisor</em> (preferentemente el <a href="https://www.virtualbox.org" target="_blank">Oracle VirtualBox</a>), si en el paso anterior no se detecta la presencia de uno. Finalmente, descarga el instalador de Minikube <a href="https://github.com/kubernetes/minikube/releases/latest" target="_blank">aqui</a> y ejecÃºtalo.</p>
<h5 id="iniciando-deteniendo-y-eliminando-minikube">Iniciando, deteniendo y eliminando Minikube</h5>
<p>Cuando operas junto con un hypervisor, Minikube crea una mÃ¡quina virtual donde se encuentran todos los componentes de k8s para su ejecuciÃ³n.</p>
<p>Es posible seleccionar quÃ© hypervisor utilizaremos de manera predeterminada con el siguiente comando:</p>
<pre><code class="lang-bash">minikube config <span class="hljs-built_in">set</span> driver &lt;SEU_HYPERVISOR&gt;
</code></pre>
<p>Â 
Debes reemplazar <tu_hypervisor> con tu hypervisor, por ejemplo KVM2, QEMU, Virtualbox o Hyperkit.</tu_hypervisor></p>
<p>Si no deseas configurar un hypervisor predeterminado, puedes ingresar el comando <code>minikube start --driver=hyperkit</code> cada vez que crees un nuevo entorno.</p>
<h5 id="bien-Â¿cÃ³mo-puedo-saber-si-todo-estÃ¡-funcionando-correctamente">Bien, Â¿cÃ³mo puedo saber si todo estÃ¡ funcionando correctamente?</h5>
<p>Una vez iniciado, deberÃ­as ver una salida en pantalla similar a esta:</p>
<pre><code class="lang-bash">minikube start

ğŸ˜„  minikube v1.26.0 on Debian bookworm/sid
âœ¨  Using the qemu2 (experimental) driver based on user configuration
ğŸ‘  Starting control plane node minikube <span class="hljs-keyword">in</span> cluster minikube
ğŸ”¥  Creating qemu2 VM (CPUs=2, Memory=6000MB, Disk=20000MB) ...
ğŸ³  Preparing Kubernetes v1.24.1 on Docker 20.10.16 ...
    â–ª Generating certificates and keys ...
    â–ª Booting up control plane ...
    â–ª Configuring RBAC rules ...
ğŸ”  Verifying Kubernetes components...
    â–ª Using image gcr.io/k8s-minikube/storage-provisioner:v5
ğŸŒŸ  Enabled addons: default-storageclass, storage-provisioner
ğŸ„  Done! kubectl is now configured to use <span class="hljs-string">&quot;minikube&quot;</span> cluster and <span class="hljs-string">&quot;default&quot;</span> namespace by default
</code></pre>
<p>Luego, puedes listar los nodos que forman parte de tu <em>clÃºster</em> k8s con el siguiente comando:</p>
<pre><code class="lang-bash">kubectl get nodes
</code></pre>
<p>Â 
La salida serÃ¡ similar al siguiente contenido:</p>
<pre><code class="lang-bash">NAME       STATUS   ROLES           AGE   VERSION
minikube   Ready    control-plane   20s   v1.25.3
</code></pre>
<p>Â 
Para crear un clÃºster con mÃ¡s de un nodo, puedes utilizar el siguiente comando, ajustando los valores segÃºn lo desees:</p>
<pre><code class="lang-bash">minikube start --nodes 2 -p multinode-cluster

ğŸ˜„  minikube v1.26.0 on Debian bookworm/sid
âœ¨  Automatically selected the docker driver. Other choices: kvm2, virtualbox, ssh, none, qemu2 (experimental)
ğŸ“Œ  Using Docker driver with root privileges
ğŸ‘  Starting control plane node minikube <span class="hljs-keyword">in</span> cluster minikube
ğŸšœ  Pulling base image ...
ğŸ’¾  Downloading Kubernetes v1.24.1 preload ...
    &gt; preloaded-images-k8s-v18-v1...: 405.83 MiB / 405.83 MiB  100.00% 66.78 Mi
    &gt; gcr.io/k8s-minikube/kicbase: 385.99 MiB / 386.00 MiB  100.00% 23.63 MiB p
    &gt; gcr.io/k8s-minikube/kicbase: 0 B [_________________________] ?% ? p/s 11s
ğŸ”¥  Creating docker container (CPUs=2, Memory=8000MB) ...
ğŸ³  Preparing Kubernetes v1.24.1 on Docker 20.10.17 ...
    â–ª Generating certificates and keys ...
    â–ª Booting up control plane ...
    â–ª Configuring RBAC rules ...
ğŸ”—  Configuring CNI (Container Networking Interface) ...
ğŸ”  Verifying Kubernetes components...
    â–ª Using image gcr.io/k8s-minikube/storage-provisioner:v5
ğŸŒŸ  Enabled addons: storage-provisioner, default-storageclass

ğŸ‘  Starting worker node minikube-m02 <span class="hljs-keyword">in</span> cluster minikube
ğŸšœ  Pulling base image ...
ğŸ”¥  Creating docker container (CPUs=2, Memory=8000MB) ...
ğŸŒ  Found network options:
    â–ª NO_PROXY=192.168.11.11
ğŸ³  Preparing Kubernetes v1.24.1 on Docker 20.10.17 ...
    â–ª env NO_PROXY=192.168.11.11
ğŸ”  Verifying Kubernetes components...
ğŸ„  Done! kubectl is now configured to use <span class="hljs-string">&quot;minikube&quot;</span> cluster and <span class="hljs-string">&quot;default&quot;</span> namespace by default
</code></pre>
<p>Â 
Para ver los nodos de tu nuevo clÃºster Kubernetes, escribe:</p>
<pre><code class="lang-bash">kubectl get nodes
</code></pre>
<p>Â 
Inicialmente, la intenciÃ³n de Minikube es ejecutar Kubernetes en un solo nodo, pero a partir de la versiÃ³n 1.10.1 es posible utilizar la funciÃ³n de multi-nodo.</p>
<p>Si los comandos anteriores se han ejecutado sin errores, la instalaciÃ³n de Minikube habrÃ¡ sido exitosa.</p>
<h5 id="ver-detalles-sobre-el-clÃºster">Ver detalles sobre el clÃºster</h5>
<pre><code class="lang-bash">minikube status
</code></pre>
<p>Â </p>
<h5 id="descubriendo-la-direcciÃ³n-de-minikube">Descubriendo la direcciÃ³n de Minikube</h5>
<p>Como se mencionÃ³ anteriormente, Minikube crearÃ¡ una mÃ¡quina virtual, asÃ­ como el entorno para la ejecuciÃ³n local de Kubernetes. TambiÃ©n configurarÃ¡ <code>kubectl</code> para comunicarse con Minikube. Para conocer la direcciÃ³n IP de esta mÃ¡quina virtual, puede ejecutar:</p>
<pre><code class="lang-bash">minikube ip
</code></pre>
<p>Â 
La direcciÃ³n que se muestra debe utilizarse para la comunicaciÃ³n con Kubernetes.</p>
<h5 id="accediendo-a-la-mÃ¡quina-de-minikube-a-travÃ©s-de-ssh">Accediendo a la mÃ¡quina de Minikube a travÃ©s de SSH</h5>
<p>Para acceder a la mÃ¡quina virtual creada por Minikube, puede ejecutar:</p>
<pre><code class="lang-bash">minikube ssh
</code></pre>
<p>Â </p>
<h5 id="panel-de-control-de-minikube">Panel de control de Minikube</h5>
<p>Minikube viene con un panel de control <em>web</em> interesante para que los usuarios principiantes puedan observar cÃ³mo funcionan las <em>cargas de trabajo (workloads)</em> en Kubernetes. Para habilitarlo, el usuario puede ingresar:</p>
<pre><code class="lang-bash">minikube dashboard
</code></pre>
<p>Â </p>
<h5 id="logs-de-minikube">Logs de Minikube</h5>
<p>Los <em>registros (logs)</em> de Minikube se pueden acceder a travÃ©s del siguiente comando:</p>
<pre><code class="lang-bash">minikube logs
</code></pre>
<p>Â </p>
<h5 id="eliminar-el-clÃºster">Eliminar el clÃºster</h5>
<pre><code class="lang-bash">minikube delete
</code></pre>
<p>Â 
Si deseas eliminar el clÃºster y todos los archivos relacionados con Ã©l, utiliza el parÃ¡metro *--purge, como se muestra a continuaciÃ³n:</p>
<pre><code class="lang-bash">minikube delete --purge
</code></pre>
<p>Â </p>
<h4 id="kind">Kind</h4>
<p>El Kind (<em>Kubernetes in Docker</em>) es otra alternativa para ejecutar Kubernetes en un entorno local para pruebas y aprendizaje, pero no se recomienda su uso en producciÃ³n.</p>
<h5 id="instalaciÃ³n-en-gnulinux">InstalaciÃ³n en GNU/Linux</h5>
<p>Para realizar la instalaciÃ³n en GNU/Linux, ejecuta los siguientes comandos.</p>
<pre><code class="lang-bash">curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.14.0/kind-linux-amd64

chmod +x ./kind

sudo mv ./kind /usr/<span class="hljs-built_in">local</span>/bin/kind
</code></pre>
<p>Â </p>
<h5 id="instalaciÃ³n-en-macos">InstalaciÃ³n en MacOS</h5>
<p>Para realizar la instalaciÃ³n en MacOS, ejecuta los siguientes comandos.</p>
<pre><code class="lang-bash">sudo brew install kind
</code></pre>
<p>Â 
ou</p>
<pre><code class="lang-bash">curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.14.0/kind-darwin-amd64
chmod +x ./kind
mv ./kind /usr/bin/kind
</code></pre>
<p>Â </p>
<h5 id="instalaciÃ³n-en-windows">InstalaciÃ³n en Windows</h5>
<p>Para realizar la instalaciÃ³n en Windows, ejecuta los siguientes comandos.</p>
<pre><code class="lang-bash">curl.exe -Lo kind-windows-amd64.exe https://kind.sigs.k8s.io/dl/v0.14.0/kind-windows-amd64

Move-Item .\kind-windows-amd64.exe c:\kind.exe
</code></pre>
<p>Â </p>
<h6 id="instalaciÃ³n-en-windows-via-chocolatey">InstalaciÃ³n en Windows via Chocolatey</h6>
<p>Ejecute el siguiente comando para instalar Kind en Windows utilizando Chocolatey.</p>
<pre><code class="lang-bash">choco install kind
</code></pre>
<p>Â </p>
<h5 id="creando-un-clÃºster-con-kind">Creando un clÃºster con Kind</h5>
<p>DespuÃ©s de realizar la instalaciÃ³n de Kind, vamos a iniciar nuestro clÃºster.</p>
<pre><code class="lang-bash">kind create cluster

Creating cluster <span class="hljs-string">&quot;kind&quot;</span> ...
 âœ“ Ensuring node image (kindest/node:v1.24.0) ğŸ–¼
 âœ“ Preparing nodes ğŸ“¦  
 âœ“ Writing configuration ğŸ“œ 
 âœ“ Starting control-plane ğŸ•¹ï¸ 
 âœ“ Installing CNI ğŸ”Œ 
 âœ“ Installing StorageClass ğŸ’¾ 
Set kubectl context to <span class="hljs-string">&quot;kind-kind&quot;</span>
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Not sure what to <span class="hljs-keyword">do</span> next? ğŸ˜…  Check out https://kind.sigs.k8s.io/docs/user/quick-start/
</code></pre>
<p>Â 
Es posible crear mÃ¡s de un clÃºster y personalizar su nombre.</p>
<pre><code class="lang-bash">kind create cluster --name giropops

Creating cluster <span class="hljs-string">&quot;giropops&quot;</span> ...
 âœ“ Ensuring node image (kindest/node:v1.24.0) ğŸ–¼
 âœ“ Preparing nodes ğŸ“¦  
 âœ“ Writing configuration ğŸ“œ 
 âœ“ Starting control-plane ğŸ•¹ï¸ 
 âœ“ Installing CNI ğŸ”Œ 
 âœ“ Installing StorageClass ğŸ’¾ 
Set kubectl context to <span class="hljs-string">&quot;kind-giropops&quot;</span>
You can now use your cluster with:

kubectl cluster-info --context kind-giropops

Thanks <span class="hljs-keyword">for</span> using kind! ğŸ˜Š
</code></pre>
<p>Â 
Para visualizar tus clÃºsteres utilizando Kind, ejecuta el siguiente comando:</p>
<pre><code class="lang-bash">kind get clusters
</code></pre>
<p>Â 
Para listar os nÃ³s do cluster, execute o seguinte comando:</p>
<pre><code class="lang-bash">kubectl get nodes
</code></pre>
<p>Â </p>
<h5 id="creando-un-clÃºster-con-mÃºltiples-nodos-locales-usando-kind">Creando un clÃºster con mÃºltiples nodos locales usando Kind</h5>
<p>Es posible para esta lecciÃ³n incluir mÃºltiples nodos en la estructura de Kind, que fue mencionado anteriormente.</p>
<p>Ejecute el siguiente comando para seleccionar y eliminar todos los clÃºsteres locales creados en Kind.</p>
<pre><code class="lang-bash">kind delete clusters $(kind get clusters)

Deleted clusters: [<span class="hljs-string">&quot;giropops&quot;</span> <span class="hljs-string">&quot;kind&quot;</span>]
</code></pre>
<p>Â 
Cree un archivo de configuraciÃ³n para definir la cantidad y el tipo de nodos en el clÃºster que desee. En el siguiente ejemplo, se crearÃ¡ el archivo de configuraciÃ³n <code>kind-3nodes.yaml</code> para especificar un clÃºster con 1 nodo de control (que ejecutarÃ¡ el plano de control) y 2 nodos worker.</p>
<pre><code class="lang-bash">cat &lt;&lt; <span class="hljs-string">EOF &gt; $HOME/kind-3nodes.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
  - role: worker
  - role: worker
EOF</span>
</code></pre>
<p>Â 
Ahora vamos a crear un clÃºster llamado <code>kind-multinodes</code> utilizando las especificaciones definidas en el archivo <code>kind-3nodes.yaml</code>.</p>
<pre><code class="lang-bash">kind create cluster --name kind-multinodes --config <span class="hljs-variable">$HOME</span>/kind-3nodes.yaml

Creating cluster <span class="hljs-string">&quot;kind-multinodes&quot;</span> ...
 âœ“ Ensuring node image (kindest/node:v1.24.0) ğŸ–¼
 âœ“ Preparing nodes ğŸ“¦ ğŸ“¦ ğŸ“¦  
 âœ“ Writing configuration ğŸ“œ 
 âœ“ Starting control-plane ğŸ•¹ï¸ 
 âœ“ Installing CNI ğŸ”Œ 
 âœ“ Installing StorageClass ğŸ’¾ 
 âœ“ Joining worker nodes ğŸšœ 
Set kubectl context to <span class="hljs-string">&quot;kind-kind-multinodes&quot;</span>
You can now use your cluster with:

kubectl cluster-info --context kind-kind-multinodes

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/<span class="hljs-comment">#community ğŸ™‚</span>
</code></pre>
<p>Â 
Valide la creaciÃ³n del clÃºster con el siguiente comando.</p>
<pre><code class="lang-bash">kubectl get nodes
</code></pre>
<p>Â 
MÃ¡s informaciones sobre Kind estÃ¡n disponibles en el siguiente enlace: <a href="https://kind.sigs.k8s.io" target="_blank">https://kind.sigs.k8s.io</a></p>
<p>Â </p>
<h3 id="primeros-pasos-en-k8s">Primeros pasos en k8s</h3>
<p>Â </p>
<h4 id="verificaciÃ³n-de-namespaces-y-pods">VerificaciÃ³n de namespaces y pods</h4>
<p>K8s organiza todo en <em>namespaces</em>. A travÃ©s de ellos, se pueden aplicar restricciones de seguridad y recursos dentro del <em>clÃºster</em>, como <em>pods</em>, <em>replication controllers</em> y muchos otros. Para ver los <em>namespaces</em> disponibles en el <em>clÃºster</em>, ingrese el siguiente comando:</p>
<pre><code class="lang-bash">kubectl get namespaces
</code></pre>
<p>Â 
Listemos los <em>pods</em> del <em>namespace</em> <strong>kube-system</strong> utilizando el siguiente comando:</p>
<pre><code class="lang-bash">kubectl get pod -n kube-system
</code></pre>
<p>Â 
Â¿HabrÃ¡ algÃºn <em>pod</em> oculto en algÃºn <em>namespace</em>? Podemos listar todos los pods de todos los namespaces con el siguiente comando:</p>
<pre><code class="lang-bash">kubectl get pods -A
</code></pre>
<p>Â 
TambiÃ©n es posible utilizar el comando con la opciÃ³n <code>-o wide</code>, que proporciona mÃ¡s informaciÃ³n sobre el recurso, incluido en quÃ© nodo se estÃ¡ ejecutando el <em>pod</em>. Ejemplo:</p>
<pre><code class="lang-bash">kubectl get pods -A -o wide
</code></pre>
<p>Â </p>
<h5 id="ejecutando-nuestro-primer-pod-en-k8s">Ejecutando nuestro primer pod en k8s</h5>
<p>Vamos a iniciar nuestro primer <em>pod</em> en k8s. Para ello, ejecutaremos el siguiente comando.</p>
<pre><code class="lang-bash">kubectl run nginx --image nginx

pod/nginx created
</code></pre>
<p>Â 
Listemos los <em>pods</em> con <code>kubectl get pods</code>, obtendremos la siguiente salida:</p>
<pre><code class="lang-bash">NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          66s
</code></pre>
<p>Â 
Ahora vamos a eliminar nuestro <em>pod</em> utilizando el siguiente comando.</p>
<pre><code class="lang-bash">kubectl delete pod nginx
</code></pre>
<p>Â 
La salida serÃ¡ algo similar a:</p>
<pre><code class="lang-bash">pod <span class="hljs-string">&quot;nginx&quot;</span> deleted
</code></pre>
<p>Â </p>
<h5 id="ejecutando-nuestro-primer-pod-en-k8s">Ejecutando nuestro primer pod en k8s</h5>
<p>Otra forma de crear un pod u cualquier otro objeto en Kubernetes es mediante el uso de un archivo manifiesto, que es un archivo en formato YAML en el que se pasan todas las definiciones de su objeto. MÃ¡s adelante hablaremos mucho mÃ¡s sobre cÃ³mo construir archivos manifiestos, pero por ahora quiero que conozcas la opciÃ³n <code>--dry-run</code> de <code>kubectl</code>, ya que con ella podemos simular la creaciÃ³n de un recurso y aÃºn asÃ­ tener automÃ¡ticamente un manifiesto creado.</p>
<p>Ejemplos:</p>
<p>Para crear la plantilla de un <em>pod</em>:</p>
<pre><code class="lang-bash">kubectl run mi-nginx --image nginx --dry-run=client -o yaml &gt; plantilla-pod.yaml
</code></pre>
<p>Â 
AquÃ­ tambiÃ©n estamos utilizando el parÃ¡metro &apos;-o&apos; para modificar la salida al formato YAML.</p>
<p>Para crear el <em>template</em> de un <em>deployment</em>:</p>
<p>Con el archivo generado en mano, ahora puedes crear un pod utilizando el manifiesto que creamos de la siguiente manera:</p>
<pre><code class="lang-bash">kubectl apply -f pod-template.yaml
</code></pre>
<p>No te preocupes por ahora con el parÃ¡metro &apos;apply&apos;, todavÃ­a hablaremos con mÃ¡s detalles sobre Ã©l. En este momento, lo importante es que sepas que se utiliza para crear nuevos recursos mediante archivos manifiestos.</p>
<p>Â </p>
<h4 id="exponiendo-el-pod-y-creando-un-service">Exponiendo el pod y creando un Service</h4>
<p>Los dispositivos fuera del <em>cluster</em>, por defecto, no pueden acceder a los <em>pods</em> creados, como es comÃºn en otros sistemas de contenedores. Para exponer un <em>pod</em>, ejecuta el siguiente comando.</p>
<pre><code class="lang-bash">kubectl expose pod nginx
</code></pre>
<p>Se mostrarÃ¡ el siguiente mensaje de error:</p>
<pre><code class="lang-bash">error: couldn<span class="hljs-string">&apos;t find port via --port flag or introspection
See &apos;</span>kubectl expose -h<span class="hljs-string">&apos; for help and examples
</span></code></pre>
<p>El error ocurre porque Kubernetes no sabe cuÃ¡l es el puerto de destino del contenedor que debe exponer (en este caso, el puerto 80/TCP). Para configurarlo, primero vamos a eliminar nuestro <em>pod</em> anterior:</p>
<pre><code class="lang-bash">kubectl delete -f pod-template.yaml
</code></pre>
<p>Ahora vamos a ejecutar nuevamente el comando para crear el <em>pod</em> utilizando el parÃ¡metro &apos;dry-run&apos;, pero esta vez vamos a aÃ±adir el parÃ¡metro &apos;--port&apos; para indicar en quÃ© puerto el contenedor estÃ¡ escuchando. Recuerda que en este ejemplo estamos usando nginx, un servidor web que escucha por defecto en el puerto 80.</p>
<pre><code class="lang-bash">kubectl run mi-nginx --image nginx --port 80 --dry-run=client -o yaml &gt; pod-template.yaml
kubectl create -f pod-template.yaml
</code></pre>
<p>Luego, lista los <em>pods</em>.</p>
<pre><code class="lang-bash">kubectl get pods

NAME    READY   STATUS    RESTARTS   AGE
mi-nginx   1/1     Running   0          32s
</code></pre>
<p>El siguiente comando crea un objeto de Kubernetes llamado <em>Service</em>, que se utiliza para exponer <em>pods</em> para el acceso externo.</p>
<pre><code class="lang-bash">kubectl expose pod mi-nginx
</code></pre>
<p>Puedes listar todos los <em>services</em> con el siguiente comando.</p>
<pre><code class="lang-bash">kubectl get services

NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   8d
nginx        ClusterIP   10.105.41.192   &lt;none&gt;        80/TCP    2m30s
</code></pre>
<p>Como se puede observar, hay dos <em>services</em> en nuestro <em>cluster</em>: el primero es para uso interno del propio k8s, mientras que el segundo es el que acabamos de crear.
Â </p>
<h4 id="limpiando-todo-y-yendo-a-casa">Limpiando todo y yendo a casa</h4>
<p>Para mostrar todos los recursos que se acaban de crear, puedes utilizar una de las siguientes opciones.</p>
<pre><code class="lang-bash">kubectl get all

kubectl get pod,service

kubectl get pod,svc
</code></pre>
<p>Observa que Kubernetes nos proporciona algunas abreviaturas para sus recursos. Con el tiempo, te familiarizarÃ¡s con ellas. Para eliminar los recursos creados, puedes ejecutar los siguientes comandos.</p>
<pre><code class="lang-bash">kubectl delete -f pod-template.yaml
kubectl delete service nginx
</code></pre>
<p>Luego, vuelve a listar los recursos para verificar si todavÃ­a estÃ¡n presentes.
Â </p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../" class="navigation navigation-prev " aria-label="Previous page: IntroducciÃ³n">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../day_two/" class="navigation navigation-next " aria-label="Next page: Simplificando Kubernetes dÃ­a 2">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Simplificando Kubernetes dÃ­a 1","level":"2.1","depth":1,"next":{"title":"Simplificando Kubernetes dÃ­a 2","level":"2.2","depth":1,"path":"day_two/README.md","ref":"day_two/README.md","articles":[]},"previous":{"title":"IntroducciÃ³n","level":"1.1","depth":1,"path":"README.md","ref":"README.md","articles":[]},"dir":"ltr"},"config":{"plugins":[],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"language":"es","gitbook":"*"},"file":{"path":"day_one/README.md","mtime":"2024-01-18T11:56:50.668Z","type":"markdown"},"gitbook":{"version":"3.6.20","time":"2024-01-18T11:57:12.977Z"},"basePath":"..","book":{"language":"es"}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="../../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

