# Descomplicando Kubernetes Day 1

## Sum√°rio

<!-- TOC -->
- [Descomplicando Kubernetes Day 1](#descomplicando-kubernetes-day-1)
  - [Sum√°rio](#sum√°rio)
- [O qu√™ preciso saber antes de come√ßar?](#o-qu√™-preciso-saber-antes-de-come√ßar)
  - [Qual distro GNU/Linux devo usar?](#qual-distro-gnulinux-devo-usar)
  - [Alguns sites que devemos visitar](#alguns-sites-que-devemos-visitar)
  - [E o k8s?](#e-o-k8s)
  - [Arquitetura do k8s](#arquitetura-do-k8s)
  - [Portas que devemos nos preocupar](#portas-que-devemos-nos-preocupar)
  - [T√°, mas qual tipo de aplica√ß√£o eu devo rodar sobre o k8s?](#t√°-mas-qual-tipo-de-aplica√ß√£o-eu-devo-rodar-sobre-o-k8s)
  - [Conceitos-chave do k8s](#conceitos-chave-do-k8s)
- [Aviso sobre os comandos](#aviso-sobre-os-comandos)
- [Minikube](#minikube)
  - [Requisitos b√°sicos](#requisitos-b√°sicos)
  - [Instala√ß√£o do Minikube no GNU/Linux](#instala√ß√£o-do-minikube-no-gnulinux)
  - [Instala√ß√£o do Minikube no MacOS](#instala√ß√£o-do-minikube-no-macos)
  - [kubectl: alias e autocomplete](#kubectl-alias-e-autocomplete)
  - [Instala√ß√£o do Minikube no Microsoft Windows](#instala√ß√£o-do-minikube-no-microsoft-windows)
  - [Iniciando, parando e excluindo o Minikube](#iniciando-parando-e-excluindo-o-minikube)
  - [Certo, e como eu sei que est√° tudo funcionando como deveria?](#certo-e-como-eu-sei-que-est√°-tudo-funcionando-como-deveria)
  - [Descobrindo o endere√ßo do Minikube](#descobrindo-o-endere√ßo-do-minikube)
  - [Acessando a m√°quina do Minikube via SSH](#acessando-a-m√°quina-do-minikube-via-ssh)
  - [Dashboard](#dashboard)
  - [Logs](#logs)
- [Microk8s](#microk8s)
  - [Requisitos b√°sicos](#requisitos-b√°sicos-1)
  - [Instala√ß√£o do MicroK8s no GNU/Linux](#instala√ß√£o-do-microk8s-no-gnulinux)
    - [Vers√µes que suportam Snap](#vers√µes-que-suportam-snap)
  - [Instala√ß√£o no Windows](#instala√ß√£o-no-windows)
    - [Instalando o Chocolatey](#instalando-o-chocolatey)
      - [Instalando o Multipass](#instalando-o-multipass)
    - [Utilizando Microk8s com Multipass](#utilizando-microk8s-com-multipass)
  - [Instalando o Microk8s no Mac](#instalando-o-microk8s-no-mac)
    - [Instalando o Brew](#instalando-o-brew)
    - [Instalando o Microk8s via Brew](#instalando-o-microk8s-via-brew)
- [Kind](#kind)
  - [Instala√ß√£o no GNU/Linux](#instala√ß√£o-no-gnulinux)
  - [Instala√ß√£o no MacOS](#instala√ß√£o-no-macos)
  - [Instala√ß√£o no Windows](#instala√ß√£o-no-windows-1)
    - [Instala√ß√£o no Windows via Chocolatey](#instala√ß√£o-no-windows-via-chocolatey)
  - [Criando um cluster com o Kind](#criando-um-cluster-com-o-kind)
    - [Criando um cluster com m√∫ltiplos n√≥s locais com o Kind](#criando-um-cluster-com-m√∫ltiplos-n√≥s-locais-com-o-kind)
- [k3s](#k3s)
- [Instala√ß√£o em cluster com tr√™s n√≥s](#instala√ß√£o-em-cluster-com-tr√™s-n√≥s)
  - [Requisitos b√°sicos](#requisitos-b√°sicos-2)
  - [Configura√ß√£o de m√≥dulos de kernel](#configura√ß√£o-de-m√≥dulos-de-kernel)
  - [Atualiza√ß√£o da distribui√ß√£o](#atualiza√ß√£o-da-distribui√ß√£o)
  - [Instala√ß√£o do Docker e do Kubernetes](#instala√ß√£o-do-docker-e-do-kubernetes)
  - [Inicializa√ß√£o do cluster](#inicializa√ß√£o-do-cluster)
  - [Configura√ß√£o do arquivo de contextos do kubectl](#configura√ß√£o-do-arquivo-de-contextos-do-kubectl)
  - [Inserindo os n√≥s workers no cluster](#inserindo-os-n√≥s-workers-no-cluster)
    - [M√∫ltiplas Interfaces](#m√∫ltiplas-interfaces)
  - [Instala√ß√£o do pod network](#instala√ß√£o-do-pod-network)
  - [Verificando a instala√ß√£o](#verificando-a-instala√ß√£o)
- [Primeiros passos no k8s](#primeiros-passos-no-k8s)
  - [Exibindo informa√ß√µes detalhadas sobre os n√≥s](#exibindo-informa√ß√µes-detalhadas-sobre-os-n√≥s)
  - [Exibindo novamente token para entrar no cluster](#exibindo-novamente-token-para-entrar-no-cluster)
  - [Ativando o autocomplete](#ativando-o-autocomplete)
  - [Verificando os namespaces e pods](#verificando-os-namespaces-e-pods)
  - [Executando nosso primeiro pod no k8s](#executando-nosso-primeiro-pod-no-k8s)
  - [Verificar os √∫ltimos eventos do cluster](#verificar-os-√∫ltimos-eventos-do-cluster)
  - [Efetuar o dump de um objeto em formato YAML](#efetuar-o-dump-de-um-objeto-em-formato-yaml)
  - [Socorro, s√£o muitas op√ß√µes!](#socorro-s√£o-muitas-op√ß√µes)
  - [Expondo o pod](#expondo-o-pod)
  - [Limpando tudo e indo para casa](#limpando-tudo-e-indo-para-casa)

<!-- TOC -->

# O qu√™ preciso saber antes de come√ßar?

## Qual distro GNU/Linux devo usar?

Devido ao fato de algumas ferramentas importantes, como o ``systemd`` e ``journald``, terem se tornado padr√£o na maioria das principais distribui√ß√µes dispon√≠veis hoje, voc√™ n√£o deve encontrar problemas para seguir o treinamento, caso voc√™ opte por uma delas, como Ubuntu, Debian, CentOS e afins.

## Alguns sites que devemos visitar

- [https://kubernetes.io](https://kubernetes.io)

- [https://github.com/kubernetes/kubernetes/](https://github.com/kubernetes/kubernetes/)

- [https://github.com/kubernetes/kubernetes/issues](https://github.com/kubernetes/kubernetes/issues)

- [https://www.cncf.io/certification/cka/](https://www.cncf.io/certification/cka/)

- [https://www.cncf.io/certification/ckad/](https://www.cncf.io/certification/ckad/)

- [https://12factor.net/pt_br/](https://12factor.net/pt_br/)

## E o k8s?

**Vers√£o resumida:**

O projeto Kubernetes foi desenvolvido pela Google, em meados de 2014, para atuar como um orquestrador de cont√™ineres para a empresa. O Kubernetes (k8s), cujo termo em Grego significa "timoneiro", √© um projeto *opensource* que conta com *design* e desenvolvimento baseados no projeto Borg, que tamb√©m √© da Google [1](https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/). Alguns outros produtos dispon√≠veis no mercado, tais como o Apache Mesos e o Cloud Foundry, tamb√©m surgiram a partir do projeto Borg.

Como Kubernetes √© uma palavra dif√≠cil de se pronunciar - e de se escrever - a comunidade simplesmente o apelidou de **k8s**, seguindo o padr√£o [i18n](http://www.i18nguy.com/origini18n.html) (a letra "k" seguida por oito letras e o "s" no final), pronunciando-se simplesmente "kates".

**Vers√£o longa:**

Praticamente todo software desenvolvido na Google √© executado em cont√™iner [2](https://www.enterpriseai.news/2014/05/28/google-runs-software-containers/). A Google j√° gerencia cont√™ineres em larga escala h√° mais de uma d√©cada, quando n√£o se falava tanto sobre isso. Para atender a demanda interna, alguns desenvolvedores do Google constru√≠ram tr√™s sistemas diferentes de gerenciamento de cont√™ineres: **Borg**, **Omega** e **Kubernetes**. Cada sistema teve o desenvolvimento bastante influenciado pelo antecessor, embora fosse desenvolvido por diferentes raz√µes.

O primeiro sistema de gerenciamento de cont√™ineres desenvolvido no Google foi o Borg, constru√≠do para gerenciar servi√ßos de longa dura√ß√£o e jobs em lote, que anteriormente eram tratados por dois sistemas:  **Babysitter** e **Global Work Queue**. O √∫ltimo influenciou fortemente a arquitetura do Borg, mas estava focado em execu√ß√£o de jobs em lote. O Borg continua sendo o principal sistema de gerenciamento de cont√™ineres dentro do Google por causa de sua escala, variedade de recursos e robustez extrema.

O segundo sistema foi o Omega, descendente do Borg. Ele foi impulsionado pelo desejo de melhorar a engenharia de software do ecossistema Borg. Esse sistema aplicou muitos dos padr√µes que tiveram sucesso no Borg, mas foi constru√≠do do zero para ter a arquitetura mais consistente. Muitas das inova√ß√µes do Omega foram posteriormente incorporadas ao Borg.

O terceiro sistema foi o Kubernetes. Concebido e desenvolvido em um mundo onde desenvolvedores externos estavam se interessando em cont√™ineres e o Google desenvolveu um neg√≥cio em amplo crescimento atualmente, que √© a venda de infraestrutura de nuvem p√∫blica.

O Kubernetes √© de c√≥digo aberto - em contraste com o Borg e o Omega que foram desenvolvidos como sistemas puramente internos do Google.
O Kubernetes foi desenvolvido com um foco mais forte na experi√™ncia de desenvolvedores que escrevem aplicativos que s√£o executados em um cluster: seu principal objetivo √© facilitar a implanta√ß√£o e o gerenciamento de sistemas distribu√≠dos, enquanto se beneficia do melhor uso de recursos de mem√≥ria e processamento que os cont√™ineres possibilitam.

Estas informa√ß√µes foram extra√≠das e adaptadas deste [artigo](https://static.googleusercontent.com/media/research.google.com/pt-BR//pubs/archive/44843.pdf), que descreve as li√ß√µes aprendidas com o desenvolvimento e opera√ß√£o desses sistemas.

## Arquitetura do k8s

Assim como os demais orquestradores dispon√≠veis, o k8s tamb√©m segue um modelo *manager/worker*, constituindo assim um *cluster*, onde para seu funcionamento devem existir no m√≠nimo tr√™s n√≥s: o n√≥ *master*, respons√°vel (por padr√£o) pelo gerenciamento do *cluster*, e os demais como *workers*, executores das aplica√ß√µes que queremos executar sobre esse *cluster*.

Embora exista a exig√™ncia de no m√≠nimo tr√™s n√≥s para a execu√ß√£o do k8s em um ambiente padr√£o, existem solu√ß√µes para se executar o k8s em um √∫nico n√≥. Alguns exemplos s√£o:

* [Kind](https://kind.sigs.k8s.io/docs/user/quick-start): Uma ferramenta para execu√ß√£o de cont√™ineres Docker que simulam o funcionamento de um cluster Kubernetes. √â utilizado para fins did√°ticos, de desenvolvimento e testes. O **Kind n√£o deve ser utilizado para produ√ß√£o**;

* [Minikube](https://github.com/kubernetes/minikube): ferramenta para implementar um *cluster* Kubernetes localmente com apenas um n√≥. Muito utilizado para fins did√°ticos, de desenvolvimento e testes. O **Minikube n√£o deve ser utilizado para produ√ß√£o**;

* [MicroK8S](https://microk8s.io): Desenvolvido pela [Canonical](https://canonical.com), mesma empresa que desenvolve o [Ubuntu](https://ubuntu.com). Pode ser utilizado em diversas distribui√ß√µes e **pode ser utilizada para ambientes de produ√ß√£o**, em especial para *Edge Computing* e IoT (*Internet of things*);

* [k3s](https://k3s.io): Desenvolvido pela [Rancher Labs](https://rancher.com), √© um concorrente direto do MicroK8s, podendo ser executado inclusive em Raspberry Pi.

A figura a seguir mostra a arquitetura interna de componentes do k8s.

| ![Arquitetura Kubernetes](../images/kubernetes_architecture.png) |
|:---------------------------------------------------------------------------------------------:|
| *Arquitetura Kubernetes [Ref: phoenixnap.com KB article](https://phoenixnap.com/kb/understanding-kubernetes-architecture-diagrams)*                                                                      |

* **API Server**: √â um dos principais componentes do k8s. Este componente fornece uma API que utiliza JSON sobre HTTP para comunica√ß√£o, onde para isto √© utilizado principalmente o utilit√°rio ``kubectl``, por parte dos administradores, para a comunica√ß√£o com os demais n√≥s, como mostrado no gr√°fico. Estas comunica√ß√µes entre componentes s√£o estabelecidas atrav√©s de requisi√ß√µes [REST](https://restfulapi.net);

* **etcd**: O etcd √© um *datastore* chave-valor distribu√≠do que o k8s utiliza para armazenar as especifica√ß√µes, status e configura√ß√µes do *cluster*. Todos os dados armazenados dentro do etcd s√£o manipulados apenas atrav√©s da API. Por quest√µes de seguran√ßa, o etcd √© por padr√£o executado apenas em n√≥s classificados como *master* no *cluster* k8s, mas tamb√©m podem ser executados em *clusters* externos, espec√≠ficos para o etcd, por exemplo;

* **Scheduler**: O *scheduler* √© respons√°vel por selecionar o n√≥ que ir√° hospedar um determinado *pod* (a menor unidade de um *cluster* k8s - n√£o se preocupe sobre isso por enquanto, n√≥s falaremos mais sobre isso mais tarde) para ser executado. Esta sele√ß√£o √© feita baseando-se na quantidade de recursos dispon√≠veis em cada n√≥, como tamb√©m no estado de cada um dos n√≥s do *cluster*, garantindo assim que os recursos sejam bem distribu√≠dos. Al√©m disso, a sele√ß√£o dos n√≥s, na qual um ou mais pods ser√£o executados, tamb√©m pode levar em considera√ß√£o pol√≠ticas definidas pelo usu√°rio, tais como afinidade, localiza√ß√£o dos dados a serem lidos pelas aplica√ß√µes, etc;

* **Controller Manager**: √â o *controller manager* quem garante que o *cluster* esteja no √∫ltimo estado definido no etcd. Por exemplo: se no etcd um *deploy* est√° configurado para possuir dez r√©plicas de um *pod*, √© o *controller manager* quem ir√° verificar se o estado atual do *cluster* corresponde a este estado e, em caso negativo, procurar√° conciliar ambos;

* **Kubelet**: O *kubelet* pode ser visto como o agente do k8s que √© executado nos n√≥s workers. Em cada n√≥ worker dever√° existir um agente Kubelet em execu√ß√£o. O Kubelet √© respons√°vel por de fato gerenciar os *pods*, que foram direcionados pelo *controller* do *cluster*, dentro dos n√≥s, de forma que para isto o Kubelet pode iniciar, parar e manter os cont√™ineres e os pods em funcionamento de acordo com o instru√≠do pelo controlador do cluster;

* **Kube-proxy**: Age como um *proxy* e um *load balancer*. Este componente √© respons√°vel por efetuar roteamento de requisi√ß√µes para os *pods* corretos, como tamb√©m por cuidar da parte de rede do n√≥;

* **Container Runtime**: O *container runtime* √© o ambiente de execu√ß√£o de cont√™ineres necess√°rio para o funcionamento do k8s. Em 2016 suporte ao [rkt](https://coreos.com/rkt/) foi adicionado, por√©m desde o in√≠cio o Docker j√° √© funcional e utilizado por padr√£o.

## Portas que devemos nos preocupar

**MASTER**

Protocol|Direction|Port Range|Purpose|Used By
--------|---------|----------|-------|-------
TCP|Inbound|6443*|Kubernetes API server|All
TCP|Inbound|2379-2380|etcd server client API|kube-apiserver, etcd
TCP|Inbound|10250|Kubelet API|Self, Control plane
TCP|Inbound|10251|kube-scheduler|Self
TCP|Inbound|10252|kube-controller-manager|Self

* Toda porta marcada por * √© customiz√°vel, voc√™ precisa se certificar que a porta alterada tamb√©m esteja aberta.

**WORKERS**

Protocol|Direction|Port Range|Purpose|Used By
--------|---------|----------|-------|-------
TCP|Inbound|10250|Kubelet API|Self, Control plane
TCP|Inbound|30000-32767|NodePort|Services All

Caso voc√™ opte pelo [Weave](https://weave.works) como *pod network*, devem ser liberadas tamb√©m as portas 6783 e 6784 TCP.

## T√°, mas qual tipo de aplica√ß√£o eu devo rodar sobre o k8s?

O melhor *app* para executar em cont√™iner, principalmente no k8s, s√£o aplica√ß√µes que seguem o [The Twelve-Factor App](https://12factor.net/pt_br/).

## Conceitos-chave do k8s

√â importante saber que a forma como o k8s gerencia os cont√™ineres √© ligeiramente diferente de outros orquestradores, como o Docker Swarm, sobretudo devido ao fato de que ele n√£o trata os cont√™ineres diretamente, mas sim atrav√©s de *pods*. Vamos conhecer alguns dos principais conceitos que envolvem o k8s a seguir:

- **Pod**: √© o menor objeto do k8s. Como dito anteriormente, o k8s n√£o trabalha com os cont√™ineres diretamente, mas organiza-os dentro de *pods*, que s√£o abstra√ß√µes que dividem os mesmos recursos, como endere√ßos, volumes, ciclos de CPU e mem√≥ria. Um pod, embora n√£o seja comum, pode possuir v√°rios cont√™ineres;

- **Controller**: √© o objeto respons√°vel por interagir com o *API Server* e orquestrar algum outro objeto. Exemplos de objetos desta classe s√£o os *Deployments* e *Replication Controllers*;

- **ReplicaSets**: √© um objeto respons√°vel por garantir a quantidade de pods em execu√ß√£o no n√≥;

- **Deployment**: √â um dos principais *controllers* utilizados. O *Deployment*, em conjunto com o *ReplicaSet*, garante que determinado n√∫mero de r√©plicas de um pod esteja em execu√ß√£o nos n√≥s workers do cluster. Al√©m disso, o Deployment tamb√©m √© respons√°vel por gerenciar o ciclo de vida das aplica√ß√µes, onde caracter√≠sticas associadas a aplica√ß√£o, tais como imagem, porta, volumes e vari√°veis de ambiente, podem ser especificados em arquivos do tipo *yaml* ou *json* para posteriormente serem passados como par√¢metro para o ``kubectl`` executar o deployment. Esta a√ß√£o pode ser executada tanto para cria√ß√£o quanto para atualiza√ß√£o e remo√ß√£o do deployment;

- **Jobs e CronJobs**: s√£o objetos respons√°veis pelo gerenciamento de jobs isolados ou recorrentes.

# Aviso sobre os comandos

> Aten√ß√£o!!! Antes de cada comando √© apresentado o tipo prompt. Exemplos:

```
$ comando1
```

```
# comando2
```

> O prompt que inicia com o caractere "$", indica que o comando deve ser executado com um usu√°rio comum do sistema operacional.
>
> O prompt que inicia com o caractere "#", indica que o comando deve ser executado com o usu√°rio **root**.
>
> Voc√™ n√£o deve copiar/colar o prompt, apenas o comando. :-)

# Minikube

## Requisitos b√°sicos

√â importante frisar que o Minikube deve ser instalado localmente, e n√£o em um *cloud provider*. Por isso, as especifica√ß√µes de *hardware* a seguir s√£o referentes √† m√°quina local.

* Processamento: 1 core;
* Mem√≥ria: 2 GB;
* HD: 20 GB.

## Instala√ß√£o do Minikube no GNU/Linux

Antes de mais nada, verifique se a sua m√°quina suporta virtualiza√ß√£o. No GNU/Linux, isto pode ser realizado com:

```
grep -E --color 'vmx|svm' /proc/cpuinfo
```

Caso a sa√≠da do comando n√£o seja vazia, o resultado √© positivo.

Ap√≥s isso, vamos instalar o ``kubectl`` com os seguintes comandos.

```
curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl

chmod +x ./kubectl

sudo mv ./kubectl /usr/local/bin/kubectl

kubectl version --client
```

H√° a possibilidade de n√£o utilizar um *hypervisor* para a instala√ß√£o do Minikube, executando-o ao inv√©s disso sobre o pr√≥prio host. Iremos utilizar o Oracle VirtualBox como *hypervisor*, que pode ser encontrado [aqui](https://www.virtualbox.org).

Efetue o download e a instala√ß√£o do ``Minikube`` utilizando os seguintes comandos.

```
curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64

chmod +x ./minikube

sudo mv ./minikube /usr/local/bin/minikube

minikube version
```

## Instala√ß√£o do Minikube no MacOS

No MacOS, o comando para verificar se o processador suporta virtualiza√ß√£o √©:

```
# sysctl -a | grep -E --color 'machdep.cpu.features|VMX'
```

Se voc√™ visualizar `VMX` na sa√≠da, o resultado √© positivo.

O ``kubectl`` pode ser instalado no MacOS utilizando tanto o [Homebrew](https://brew.sh), quanto o m√©todo tradicional. Com o Homebrew j√° instalado, o kubectl pode ser instalado da seguinte forma.

```
# brew install kubectl

kubectl version --client
```

Ou:

```
# brew install kubectl-cli

kubectl version --client
```

J√° com o m√©todo tradicional, a instala√ß√£o pode ser realizada com os seguintes comandos.

```
curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl"

chmod +x ./kubectl

sudo mv ./kubectl /usr/local/bin/kubectl

kubectl version --client
```

Por fim, efetue a instala√ß√£o do Minikube com um dos dois m√©todos a seguir, podendo optar-se pelo Homebrew ou pelo m√©todo tradicional.

```
# brew install minikube

minikube version
```

Ou:

```
curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64

chmod +x ./minikube

sudo mv ./minikube /usr/local/bin/minikube

minikube version
```

## kubectl: alias e autocomplete

Execute o seguinte comando para configurar o alias e autocomplete para o ``kubectl``.

No Bash:

```bash
source <(kubectl completion bash) # configura o autocomplete na sua sess√£o atual (antes, certifique-se de ter instalado o pacote bash-completion).

echo "source <(kubectl completion bash)" >> ~/.bashrc # add autocomplete permanentemente ao seu shell.
```

Crie o alias ``k`` para ``kubectl``:

```
alias k=kubectl

complete -F __start_kubectl k
```

No ZSH:

```
source <(kubectl completion zsh)

echo "[[ $commands[kubectl] ]] && source <(kubectl completion zsh)"
```

## Instala√ß√£o do Minikube no Microsoft Windows

No Microsoft Windows, voc√™ deve executar o comando `systeminfo` no prompt de comando ou no terminal. Caso o retorno deste comando seja semelhante com o descrito a seguir, ent√£o a virtualiza√ß√£o √© suportada.

```textile
Hyper-V Requirements:     VM Monitor Mode Extensions: Yes
                          Virtualization Enabled In Firmware: Yes
                          Second Level Address Translation: Yes
                          Data Execution Prevention Available: Yes
```

Caso a linha a seguir tamb√©m esteja presente, n√£o √© necess√°ria a instala√ß√£o de um *hypervisor* como o Oracle VirtualBox:

```textile
Hyper-V Requirements:     A hypervisor has been detected. Features required for Hyper-V will not be displayed.:     A hypervisor has been detected. Features required for Hyper-V will not be displayed.
```

A instala√ß√£o do ``kubectl`` pode ser realizada efetuando o download [neste link](https://storage.googleapis.com/kubernetes-release/release/v1.19.1/bin/windows/amd64/kubectl.exe). Feito isso, tamb√©m deve ser realizado download e a instala√ß√£o de um *hypervisor* (preferencialmente o [Oracle VirtualBox](https://www.virtualbox.org)), caso no passo anterior n√£o tenha sido acusada a presen√ßa de um. Finalmente, efetue o download do instalador do Minikube [aqui](https://github.com/kubernetes/minikube/releases/latest) e execute-o.

## Iniciando, parando e excluindo o Minikube

Quando operando em conjunto com um *hypervisor*, o Minikube cria uma m√°quina virtual, onde dentro dela estar√£o todos os componentes do k8s para execu√ß√£o. Para realizar a inicializa√ß√£o desse ambiente, antes de executar o minikube, precisamos setar o VirtualBox como padr√£o para subir este ambiente, para que isso aconte√ßa execute o comando:

```
minikube config set driver virtualbox
```

Caso n√£o queria deixar o VirtualBox como padr√£o sempre que subir o ambiente novo, voc√™ deve digitar o comando ``minikube start --driver=virtualbox``. Mas como j√° setamos o VirtualBox como padr√£o para subir o ambiente do minikube, basta executar:

```
minikube start
```

Para criar um cluster com multi-node basta executar:

``` 
minikube start --nodes 2 -p multinode-demo
```

Caso deseje parar o ambiente:

```
minikube stop
```

Para excluir o ambiente:

```
minikube delete
```

## Certo, e como eu sei que est√° tudo funcionando como deveria?

Uma vez iniciado, voc√™ deve ter uma sa√≠da na tela similar √† seguinte:

```
minikube start


üéâ  minikube 1.10.0 is available! Download it: https://github.com/kubernetes/minikube/releases/tag/v1.10.0
üí°  To disable this notice, run: 'minikube config set WantUpdateNotification false'

üôÑ  minikube v1.9.2 on Darwin 10.11
‚ú®  Using the virtualbox driver based on existing profile
üëç  Starting control plane node m01 in cluster minikube
üîÑ  Restarting existing virtualbox VM for "minikube" ...
üê≥  Preparing Kubernetes v1.19.1 on Docker 19.03.8 ...
üåü  Enabling addons: default-storageclass, storage-provisioner
üèÑ  Done! kubectl is now configured to use "minikube"
```

Voc√™ pode ent√£o listar os n√≥s que fazem parte do seu *cluster* k8s com o seguinte comando:

```
kubectl get nodes
```

A sa√≠da ser√° similar ao conte√∫do a seguir:

Para um node:

```
kubectl get nodes

NAME       STATUS   ROLES    AGE   VERSION
minikube   Ready    master   8d    v1.19.1
```

Para multi-nodes:

```
NAME                 STATUS    ROLES     AGE       VERSION
multinode-demo       Ready     master    5m        v1.19.1
multinode-demo-m02   Ready     <none>    4m        v1.19.1
```

Inicialmente, a inten√ß√£o do Minikube √© executar o k8s em apenas um n√≥, por√©m a partir da vers√£o 1.10.1 e poss√≠vel usar a fun√ß√£o de multi-node (Experimental).

Caso os comandos anteriores tenham sido executados sem erro, a instala√ß√£o do Minikube ter√° sido realizada com sucesso.

## Descobrindo o endere√ßo do Minikube

Como dito anteriormente, o Minikube ir√° criar uma m√°quina virtual, assim como o ambiente para a execu√ß√£o do k8s localmente. Ele tamb√©m ir√° configurar o ``kubectl`` para comunicar-se com o Minikube. Para saber qual √© o endere√ßo IP dessa m√°quina virtual, pode-se executar:

```
minikube ip
```

O endere√ßo apresentado √© que deve ser utilizado para comunica√ß√£o com o k8s.

## Acessando a m√°quina do Minikube via SSH

Para acessar a m√°quina virtual criada pelo Minikube, pode-se executar:

```
minikube ssh
```

## Dashboard

O Minikube vem com um *dashboard* *web* interessante para que o usu√°rio iniciante observe como funcionam os *workloads* sobre o k8s. Para habilit√°-lo, o usu√°rio pode digitar:

```
minikube dashboard
```

## Logs

Os *logs* do Minikube podem ser acessados atrav√©s do seguinte comando.

```
minikube logs
```

# Microk8s

## Requisitos b√°sicos

Existem alguns tipos de instala√ß√£o do Microk8s:

* GNU/Linux que suportam Snap;
* Windows - 4GB RAM e 40GB HD Livre;
* MacOS - Brew;
* RaspBerry.

## Instala√ß√£o do MicroK8s no GNU/Linux

### Vers√µes que suportam Snap

BASH:

```
sudo snap install microk8s --classic --channel=1.18/stable

sudo usermod -a -G microk8s $USER

sudo chown -f -R $USER ~/.kube

microk8s status --wait-ready

microk8s enable dns dashboard registry

alias kubectl='microk8s kubectl'
```

## Instala√ß√£o no Windows

Somente √© poss√≠vel em vers√µes do Windows Professional e Enterprise

Tamb√©m ser√° necess√°rio a instala√ß√£o por meio de um administrador de pacotes do Windows, o [Chocolatey
](https://chocolatey.org/install)

### Instalando o Chocolatey

PowerShell Admin:

```
# Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))
```

#### Instalando o Multipass

PowerShell Admin:

```
# choco install multipass
```

### Utilizando Microk8s com Multipass

PowerShell Admin:

```
# multipass launch --name microk8s-vm --mem 4G --disk 40G

# multipass exec microk8s-vm -- snap install microk8s --classic

# multipass exec microk8s-vm -- iptables -P FORWARD ACCEPT

# multipass list

Name                    State             IPv4             Release
microk8s-vm             RUNNING           10.72.145.216    Ubuntu 18.04 LTS

# multipass shell microk8s-vm
```

Se quiser utilizar o Microk8s sem utilizar um shell criado pelo multipass utilize a seguinte express√£o.

PowerShell Admin:

```
# multipass exec microk8s-vm -- /snap/bin/microk8s.<command>
```

## Instalando o Microk8s no Mac

Utilizando o gerenciador de pacotes do Mac `Brew`:

### Instalando o Brew

Se n√£o tiver o ``brew`` instalado em sua m√°quina siga os passos a seguir. Caso j√° o possua, v√° para o passo dois dessa se√ß√£o.

BASH:

```
# /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"
```

### Instalando o Microk8s via Brew

BASH:

```
sudo brew install ubuntu/microk8s/microk8s

sudo microk8s install

sudo microk8s kubectl get all --all-namespaces
```

Espere at√© que a configura√ß√£o do microk8s esteja pronta para ser utilizada.

BASH:

```
microk8s status --wait-ready
```

Assim que o coment√°rio: ``microk8s is running`` for exibido, execute o seguinte comando.

BASH:

```
microk8s kubectl <command>
```

# Kind

O Kind (Kubernetes in Docker) √© outra alternativa para executar o Kubernetes num ambiente local para testes e aprendizado, mas n√£o √© recomendado para uso em produ√ß√£o.

## Instala√ß√£o no GNU/Linux

Para fazer a instala√ß√£o no GNU/Linux, execute os seguintes comandos.

```
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.9.0/kind-$(uname)-amd64

chmod +x ./kind

sudo mv ./kind /usr/local/bin/kind
```

## Instala√ß√£o no MacOS

Para fazer a instala√ß√£o no MacOS, execute o seguinte comando.

```
sudo brew install kind
```

## Instala√ß√£o no Windows

Para fazer a instala√ß√£o no Windows, execute os seguintes comandos.

```
# curl.exe -Lo kind-windows-amd64.exe https://kind.sigs.k8s.io/dl/v0.8.1/kind-windows-amd64

# Move-Item .\kind-windows-amd64.exe c:\some-dir-in-your-PATH\kind.exe
```

### Instala√ß√£o no Windows via Chocolatey

Execute o seguinte comando para instalar o Kind no Windows usando o Chocolatey.

```
# choco install kind
```

## Criando um cluster com o Kind

Ap√≥s realizar a instala√ß√£o do Kind, vamos iniciar o nosso cluster.

```
kind create cluster

Creating cluster "kind" ...
 ‚úì Ensuring node image (kindest/node:v1.19.1) üñº
 ‚úì Preparing nodes üì¶
 ‚úì Writing configuration üìú
 ‚úì Starting control-plane üïπÔ∏è
 ‚úì Installing CNI üîå
 ‚úì Installing StorageClass üíæ
Set kubectl context to "kind-kind"
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Thanks for using kind! üòä
```

√â poss√≠vel criar mais de um cluster e personalizar o seu nome.

```
kind create cluster --name giropops

Creating cluster "giropops" ...
 ‚úì Ensuring node image (kindest/node:v1.19.1) üñº
 ‚úì Preparing nodes üì¶
 ‚úì Writing configuration üìú
 ‚úì Starting control-plane üïπÔ∏è
 ‚úì Installing CNI üîå
 ‚úì Installing StorageClass üíæ
Set kubectl context to "kind-giropops"
You can now use your cluster with:

kubectl cluster-info --context kind-giropops

Thanks for using kind! üòä
```

Para visualizar os seus clusters utilizando o kind, execute o comando a seguir.

```
kind get clusters

kind
giropops
```

Liste os nodes do cluster.

```
kubectl get nodes

NAME                 STATUS   ROLES    AGE     VERSION
kind-control-plane   Ready    master   3m51s   v1.19.1
```

### Criando um cluster com m√∫ltiplos n√≥s locais com o Kind

√â poss√≠vel para essa aula incluir m√∫ltiplos n√≥s na estrutura do Kind, que foi mencionado anteriormente.

Execute o comando a seguir para selecionar e remover todos os clusters locais criados no Kind.

```
kind delete clusters $(kind get clusters)
```

Crie um arquivo de configura√ß√£o para definir quantos e o tipo de n√≥s no cluster que voc√™ deseja. No exemplo a seguir, ser√° criado o arquivo de configura√ß√£o ``kind-3nodes.yaml`` para especificar um cluster com 1 n√≥ master (que executar√° o control plane) e 2 workers.

```
cat << EOF > kind-3nodes.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
  - role: worker
  - role: worker
EOF
```

Crie um cluster chamado ``kind-multinodes`` utilizando as especifica√ß√µes definidas no arquivo ``kind-3nodes.yaml``.

```
kind create cluster --name kind-multinodes --config ./kind-3nodes.yaml

Creating cluster "kind-multinodes" ...
 ‚úì Ensuring node image (kindest/node:v1.19.1) üñº
 ‚úì Preparing nodes üì¶ üì¶ üì¶
 ‚úì Writing configuration üìú
 ‚úì Starting control-plane üïπÔ∏è
 ‚úì Installing CNI üîå
 ‚úì Installing StorageClass üíæ
 ‚úì Joining worker nodes üöú
Set kubectl context to "kind-kind-multinodes"
You can now use your cluster with:

kubectl cluster-info --context kind-kind-multinodes

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community üôÇ
```

Valide a cria√ß√£o do cluster com o comando a seguir.

```
kubectl get nodes

NAME                            STATUS   ROLES    AGE     VERSION
kind-multinodes-control-plane   Ready    master   3m3s    v1.19.1
kind-multinodes-worker1          Ready    <none>   2m30s   v1.19.1
kind-multinodes-worker2         Ready    <none>   2m30s   v1.19.1
```

Mais informa√ß√µes sobre o Kind est√£o dispon√≠veis em: https://kind.sigs.k8s.io

! Refer√™ncia: [kind multi-cluster](https://kubernetes.io/blog/2020/05/21/wsl-docker-kubernetes-on-the-windows-desktop/)

# k3s

Vamos aprender como instalar o renomado k3s e adicionar nodes no seu cluster!

Nesse exemplo eu estou usando o Raspberry Pi 4, a *master* com 4GB de mem√≥ria RAM e 4 cores, e 2 workers com 2GB de mem√≥ria RAM e 4 cores.

Para instalar o k3s, basta executar o seguinte comando:

```
curl -sfL https://get.k3s.io | sh -

[INFO]  Finding release for channel stable
[INFO]  Using v1.19.1+k3s1 as release
[INFO]  Downloading hash https://github.com/rancher/k3s/releases/download/v1.19.1+k3s1/sha256sum-arm.txt
[INFO]  Downloading binary https://github.com/rancher/k3s/releases/download/v1.19.1+k3s1/k3s-armhf
[INFO]  Verifying binary download
[INFO]  Installing k3s to /usr/local/bin/k3s
[INFO]  Creating /usr/local/bin/kubectl symlink to k3s
[INFO]  Creating /usr/local/bin/crictl symlink to k3s
[INFO]  Creating /usr/local/bin/ctr symlink to k3s
[INFO]  Creating killall script /usr/local/bin/k3s-killall.sh
[INFO]  Creating uninstall script /usr/local/bin/k3s-uninstall.sh
[INFO]  env: Creating environment file /etc/systemd/system/k3s.service.env
[INFO]  systemd: Creating service file /etc/systemd/system/k3s.service
[INFO]  systemd: Enabling k3s unit
Created symlink /etc/systemd/system/multi-user.target.wants/k3s.service ‚Üí /etc/systemd/system/k3s.service.
[INFO]  systemd: Starting k3s
```

Vamos ver se est√° tudo certo com o nosso node master.

```
kubectl get nodes

NAME        STATUS   ROLES    AGE   VERSION
elliot-01   Ready    master   15s   v1.19.1+k3s1
```

Vamos ver os pods em execu√ß√£o:

```
kubectl get pods

No resources found in default namespace.
```

Humm! Parece que n√£o temos nenhum, mas ser√° mesmo?

Vamos verificar novamente:

```
kubectl get pods --all-namespaces

NAMESPACE     NAME                                     READY   STATUS      RESTARTS   AGE
kube-system   metrics-server-7566d596c8-rdn5f          1/1     Running     0          7m5s
kube-system   local-path-provisioner-6d59f47c7-mfp89   1/1     Running     0          7m5s
kube-system   coredns-8655855d6-ns4d4                  1/1     Running     0          7m5s
kube-system   helm-install-traefik-mqmp4               0/1     Completed   2          7m5s
kube-system   svclb-traefik-t49cs                      2/2     Running     0          6m11s
kube-system   traefik-758cd5fc85-jwvmc                 1/1     Running     0          6m12s
```

A√≠ est√£o os pods que est√£o executando por padr√£o, que o pr√≥prio k8s cria para executar seus pr√≥prios componentes internos. Mas temos muito mais coisas al√©m dos pods, vamos conferir tudo que est√° rodando no nosso lindo k3s:

```
kubectl get all --all-namespaces

NAMESPACE     NAME                                         READY   STATUS      RESTARTS   AGE
kube-system   pod/metrics-server-7566d596c8-rdn5f          1/1     Running     0          11m
kube-system   pod/local-path-provisioner-6d59f47c7-mfp89   1/1     Running     0          11m
kube-system   pod/coredns-8655855d6-ns4d4                  1/1     Running     0          11m
kube-system   pod/helm-install-traefik-mqmp4               0/1     Completed   2          11m
kube-system   pod/svclb-traefik-t49cs                      2/2     Running     0          10m
kube-system   pod/traefik-758cd5fc85-jwvmc                 1/1     Running     0          10m

NAMESPACE     NAME                         TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)                      AGE
default       service/kubernetes           ClusterIP      10.43.0.1      <none>           443/TCP                      12m
kube-system   service/kube-dns             ClusterIP      10.43.0.10     <none>           53/UDP,53/TCP,9153/TCP       12m
kube-system   service/metrics-server       ClusterIP      10.43.181.42   <none>           443/TCP                      12m
kube-system   service/traefik-prometheus   ClusterIP      10.43.207.57   <none>           9100/TCP                     10m
kube-system   service/traefik              LoadBalancer   10.43.232.43   192.168.86.101   80:30953/TCP,443:31363/TCP   10m

NAMESPACE     NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
kube-system   daemonset.apps/svclb-traefik   1         1         1       1            1           <none>          10m

NAMESPACE     NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE
kube-system   deployment.apps/metrics-server           1/1     1            1           12m
kube-system   deployment.apps/local-path-provisioner   1/1     1            1           12m
kube-system   deployment.apps/coredns                  1/1     1            1           12m
kube-system   deployment.apps/traefik                  1/1     1            1           10m

NAMESPACE     NAME                                               DESIRED   CURRENT   READY   AGE
kube-system   replicaset.apps/metrics-server-7566d596c8          1         1         1       11m
kube-system   replicaset.apps/local-path-provisioner-6d59f47c7   1         1         1       11m
kube-system   replicaset.apps/coredns-8655855d6                  1         1         1       11m
kube-system   replicaset.apps/traefik-758cd5fc85                 1         1         1       10m

NAMESPACE     NAME                             COMPLETIONS   DURATION   AGE
kube-system   job.batch/helm-install-traefik   1/1           55s        11m
```

Muito legal, bacana e sensacional n√©?

Por√©m ainda temos apenas 1 node, queremos adicionar mais nodes para que tenhamos alta disponibilidade para nossas aplica√ß√µes.

Para fazer isso, primeiro vamos pegar o Token do nosso cluster pois iremos utiliz√°-lo para adicionar os outros nodes em nosso cluster.

```
# cat /var/lib/rancher/k3s/server/node-token

K10bded4a17f7674c322febfb517cde93afaa48c35b74528d9d2b7d20ec8e41a1ad::server:9d2c12e1112ecdc0d1f9a2fd0e2933fe
```

M√°gica, achamos nosso Token.

Agora finalmente bora adicionar mais nodes em nosso cluster.

Calma, antes pegue o IP de seu master:

```
ifconfig

...
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.86.101  netmask 255.255.255.0  broadcast 192.168.86.255
        inet6 fe80::f58b:e4b:c74e:cbd  prefixlen 64  scopeid 0x20<link>
        ether dc:a6:32:08:c5:6d  txqueuelen 1000  (Ethernet)
        RX packets 117526  bytes 161460044 (153.9 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 17418  bytes 1180417 (1.1 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
...
```

Legal! Agora que voc√™ j√° tem o Token e o IP da master, bora para o outro node.

J√° no outro node, n√≥s vamos executar o comando para que ele seja adicionado:

```
# curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 K3S_TOKEN=XXX sh -
```

O comando ficar√° mais ou menos assim (lembre-se de trocar pelo seu IP e Token):

```
# curl -sfL https://get.k3s.io | K3S_URL=https://192.168.86.101:6443 K3S_TOKEN=K10bded4a17f7674c322febfb517cde93afaa48c35b74528d9d2b7d20ec8e41a1ad::server:9d2c12e1112ecdc0d1f9a2fd0e2933fe sh -

[INFO]  Finding release for channel stable
[INFO]  Using v1.19.1+k3s1 as release
[INFO]  Downloading hash https://github.com/rancher/k3s/releases/download/v1.19.1+k3s1/sha256sum-arm.txt
[INFO]  Downloading binary https://github.com/rancher/k3s/releases/download/v1.19.1+k3s1/k3s-armhf
[INFO]  Verifying binary download
[INFO]  Installing k3s to /usr/local/bin/k3s
[INFO]  Creating /usr/local/bin/kubectl symlink to k3s
[INFO]  Creating /usr/local/bin/crictl symlink to k3s
[INFO]  Creating /usr/local/bin/ctr symlink to k3s
[INFO]  Creating killall script /usr/local/bin/k3s-killall.sh
[INFO]  Creating uninstall script /usr/local/bin/k3s-agent-uninstall.sh
[INFO]  env: Creating environment file /etc/systemd/system/k3s-agent.service.env
[INFO]  systemd: Creating service file /etc/systemd/system/k3s-agent.service
[INFO]  systemd: Enabling k3s-agent unit
Created symlink /etc/systemd/system/multi-user.target.wants/k3s-agent.service ‚Üí /etc/systemd/system/k3s-agent.service.
[INFO]  systemd: Starting k3s-agent
```

Perfeito! Agora vamos ver se esse node est√° no nosso cluster mesmo:

```
kubectl get nodes

NAME        STATUS   ROLES    AGE     VERSION
elliot-02   Ready    <none>   5m27s   v1.19.1+k3s1
elliot-01   Ready    master   34m     v1.19.1+k3s1
```

Olha ele ali, ``elliot-02`` j√° est√° lindo de bonito em nosso cluster, m√°gico n√£o?

Quer adicionar mais nodes? S√≥ copiar e colar aquele mesmo comando com o IP do master e o nosso Token no pr√≥ximo node.

```
kubectl get nodes

NAME        STATUS   ROLES    AGE   VERSION
elliot-02   Ready    <none>   10m   v1.19.1+k3s1
elliot-01   Ready    master   39m   v1.19.1+k3s1
elliot-03   Ready    <none>   68s   v1.19.1+k3s1
```

Todos os elliots saud√°veis!!!

Pronto!!! Agora temos um cluster com 3 nodes trabalhando, e as possibilidades s√£o infinitas, divirta-se.

Para saber mais detalhes acesse as documenta√ß√µes oficiais do k3s:

* https://k3s.io/
* https://rancher.com/docs/k3s/latest/en/
* https://github.com/rancher/k3s

# Instala√ß√£o em cluster com tr√™s n√≥s

## Requisitos b√°sicos

Como j√° dito anteriormente, o Minikube √© √≥timo para desenvolvedores, estudos e testes, mas n√£o tem como prop√≥sito a execu√ß√£o em ambiente de produ√ß√£o. Dito isso, a instala√ß√£o de um *cluster* k8s para o treinamento ir√° requerer pelo menos tr√™s m√°quinas, f√≠sicas ou virtuais, cada qual com no m√≠nimo a seguinte configura√ß√£o:

- Distribui√ß√£o: Debian, Ubuntu, CentOS, Red Hat, Fedora, SuSE;

- Processamento: 2 *cores*;

- Mem√≥ria: 2GB.

## Configura√ß√£o de m√≥dulos de kernel

O k8s requer que certos m√≥dulos do kernel GNU/Linux estejam carregados para seu pleno funcionamento, e que esses m√≥dulos sejam carregados no momento da inicializa√ß√£o do computador. Para tanto, crie o arquivo ``/etc/modules-load.d/k8s.conf`` com o seguinte conte√∫do em todos os seus n√≥s.

```textile
br_netfilter
ip_vs
ip_vs_rr
ip_vs_sh
ip_vs_wrr
nf_conntrack_ipv4
```

## Atualiza√ß√£o da distribui√ß√£o

Em distribui√ß√µes Debian e baseadas, como o Ubuntu, execute o comando a seguir, em cada um de seus n√≥s, para executar atualiza√ß√£o do sistema.

```
sudo apt update

sudo apt upgrade -y
```

Em distribui√ß√µes Red Hat e baseadas, use o seguinte comando.

```
# yum upgrade -y
```

## Instala√ß√£o do Docker e do Kubernetes

A instala√ß√£o do Docker pode ser realizada com apenas um comando, que deve ser executado nos tr√™s n√≥s:

```
# curl -fsSL https://get.docker.com | bash
```

Embora a maneira anterior seja a mais f√°cil, n√£o permite o controle de op√ß√µes. Por esse motivo, a documenta√ß√£o do Kubernetes sugere uma instala√ß√£o mais controlada seguindo os passos dispon√≠veis em: https://kubernetes.io/docs/setup/production-environment/container-runtimes/

**Caso escolha o m√©todo mais f√°cil**, os pr√≥ximos comandos s√£o muito importantes, pois garantem que o driver ``Cgroup`` do Docker ser√° configurado para o ``systemd``, que √© o gerenciador de servi√ßos padr√£o utilizado pelo Kubernetes.

Para a fam√≠lia Debian, execute o seguinte comando:

```
# cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF
```

Para a fam√≠lia Red Hat, execute o seguinte comando:

```
# cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF
```

Os passos a seguir s√£o iguais para ambas as fam√≠lias.

```
sudo mkdir -p /etc/systemd/system/docker.service.d
```

Agora basta reiniciar o Docker.

```
# systemctl daemon-reload
# systemctl restart docker
```

Para finalizar, verifique se o driver ``Cgroup`` foi corretamente definido.

```
# docker info | grep -i cgroup
```

Se a sa√≠da foi ``Cgroup Driver: systemd``, tudo certo!

O pr√≥ximo passo √© efetuar a adi√ß√£o dos reposit√≥rios do k8s e efetuar a instala√ß√£o do ``kubeadm``.

Em distribui√ß√µes Debian e baseadas, isso pode ser realizado com os comandos a seguir.

```
# apt-get update && apt-get install -y apt-transport-https gnupg2

# curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -

# echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" > /etc/apt/sources.list.d/kubernetes.list

# apt-get update

# apt-get install -y kubelet kubeadm kubectl
```

J√° em distribui√ß√µes Red Hat e baseadas, adicione o reposit√≥rio do k8s criando o arquivo ``/etc/yum.repos.d/kubernetes.repo`` com o conte√∫do a seguir:

```
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
```

Os comandos a seguir desativam o *firewall*, instalam os pacotes do k8s e ativam o servi√ßo do mesmo.

```
# setenforce 0

# systemctl stop firewalld

# systemctl disable firewalld

# yum install -y kubelet kubeadm kubectl

# systemctl enable docker && systemctl start docker

# systemctl enable kubelet && systemctl start kubelet
```

Ainda em distribui√ß√µes Red Hat e baseadas, √© necess√°rio a configura√ß√£o de alguns par√¢metros extras no kernel por meio do **sysctl**. Estes podem ser setados criando o arquivo ``/etc/sysctl.d/k8s.conf`` com o seguinte conte√∫do.

```
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
```

Em ambas distribui√ß√µes GNU/Linux tamb√©m √© necess√°rio desativar a mem√≥ria swap em todos os n√≥s com o comando a seguir.

```
# swapoff -a
```

Al√©m de comentar a linha referente √† mesma no arquivo ```/etc/fstab```.

Ap√≥s esses procedimentos, √© interessante a reinicializa√ß√£o de todos os n√≥s do *cluster*.

## Inicializa√ß√£o do cluster

Antes de inicializarmos o *cluster*, vamos efetuar o *download* das imagens que ser√£o utilizadas, executando o comando a seguir no n√≥ que ser√° o *master*.

```
# kubeadm config images pull
```

Execute o comando a seguir tamb√©m apenas no n√≥ *master* para a inicializa√ß√£o do cluster. Caso tudo esteja bem, ser√° apresentada ao t√©rmino de sua execu√ß√£o o comando que deve ser executado nos demais n√≥s para ingressar no *cluster*.

```
# kubeadm init
```

A op√ß√£o _--apiserver-advertise-address_ informa qual o endere√ßo IP em que o servidor de API ir√° escutar. Caso este par√¢metro n√£o seja informado, a interface de rede padr√£o ser√° usada. Opcionalmente, voc√™ tamb√©m pode passar o cidr com a op√ß√£o _--pod-network-cidr_. O comando obedecer√° a seguinte sintaxe:

```
kubeadm init --apiserver-advertise-address 192.168.99.2 --pod-network-cidr 192.168.99.0/24
```

A sa√≠da do comando ser√° algo similar ao mostrado a seguir.

```
    [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.05.0-ce. Max validated version: 17.03
...
To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config
...
kubeadm join --token 39c341.a3bc3c4dd49758d5 IP_DO_MASTER:6443 --discovery-token-ca-cert-hash sha256:37092
...
```

Caso o servidor possua mais de uma interface de rede, voc√™ pode verificar se o IP interno do n√≥ do seu cluster corresponde ao IP da interface esperada com o seguinte comando:

```
kubectl describe node elliot-1 | grep InternalIP
```

A sa√≠da ser√° algo similar a seguir:

```
InternalIP:  192.168.99.2
```

Caso o Ip n√£o corresponda ao da interface de rede escolhida, voc√™ pode ir at√© o arquivo localizado em _/etc/systemd/system/kubelet.service.d/10-kubeadm.conf_ com o editor da sua prefer√™ncia, procurar por _KUBELET_CONFIG_ARGS_ e adicionar no final a instru√ß√£o --node-ip=<IP Da sua prefer√™ncia>. O trecho alterado ser√° semelhante abaixo:

```
Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml --node-ip=192.168.99.2"
```

Salve o arquivo e execute os comandos abaixo para reiniciar a configura√ß√£o e consequentemente o kubelet.

```
systemctl daemon-reload
systemctl restart kubelet
```

## Configura√ß√£o do arquivo de contextos do kubectl

Como dito anteriormente e de forma similar ao Docker Swarm, o pr√≥prio kubeadm j√° mostrar√° os comandos necess√°rios para a configura√ß√£o do ``kubectl``, para que assim possa ser estabelecida comunica√ß√£o com o cluster k8s. Para tanto, execute os seguintes comandos.

```
mkdir -p $HOME/.kube

cp -i /etc/kubernetes/admin.conf $HOME/.kube/config

sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

## Inserindo os n√≥s workers no cluster

Para inserir os n√≥s *workers* no *cluster*, basta executar a linha que come√ßa com ``kubeadm join`` nos mesmos.

### M√∫ltiplas Interfaces

Caso algum dos n√≥s que ser√° utilizado tenha mais de uma interface de rede, verifique se ele consegue alcan√ßar o `service` do `Kubernetes` atrav√©s da rota padr√£o.

Para verificar, ser√° necess√°rio pegar o IP interno do `service` Kubernetes atrav√©s do comando ``kubectl get services kubernetes``. Ap√≥s obter o IP, basta ir no n√≥ que ser√° ingressado no cluster e rodar o comando ``curl -k https://SERVICE`` alterando o `SERVICE` para o IP do `service`. Exemplo: ``curl -k https://10.96.0.1``.

Caso a sa√≠da seja algo parecido com o exemplo a seguir, a conex√£o est√° acontecendo normalmente.

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {

  },
  "status": "Failure",
  "message": "forbidden: User \"system:anonymous\" cannot get path \"/\"",
  "reason": "Forbidden",
  "details": {

  },
  "code": 403
}
```

Caso a sa√≠da n√£o seja parecido com o exemplo, ser√° necess√°rio adicionar uma rota com o seguinte comando.

```shell
ip route add REDE_DO_SERVICE/16 dev INTERFACE
```

Substitua a `REDE_DO SERVICE` com a rede do `service` (geralmente √© um IP finalizando com 0).

Exemplo: Se o IP for `10.96.0.1` a rede √© `10.96.0.0`) e a `INTERFACE` com a interface do n√≥ que tem acesso ao `master` do cluster.

Exemplo de comando para adicionar uma rota:

```
# ip route add 10.96.0.0/16 dev eth1
```

Adicione a rota nas configura√ß√µes de rede para que seja criada durante o boot.

## Instala√ß√£o do pod network

Para os usu√°rios do Docker Swarm, h√° uma diferen√ßa entre os dois orquestradores: o k8s por padr√£o n√£o fornece uma solu√ß√£o de *networking* *out-of-the-box*. Para que isso ocorra, deve ser instalada uma solu√ß√£o de *pod networking* como *add-on*. Existem diversas op√ß√µes dispon√≠veis, cada qual com funcionalidades diferentes, tais como: [Flannel](https://github.com/coreos/flannel), [Calico](http://docs.projectcalico.org/), [Romana](http://romana.io), [Weave-net](https://www.weave.works/products/weave-net/), entre outros.

Mais informa√ß√µes sobre *pod networking* ser√£o abordados nos demais dias do treinamento.

Caso voc√™ ainda n√£o tenha reiniciado os n√≥s que comp√µem o seu *cluster*, voc√™ pode carregar os m√≥dulos do kernel necess√°rios com o seguinte comando.

```
# modprobe br_netfilter ip_vs_rr ip_vs_wrr ip_vs_sh nf_conntrack_ipv4 ip_vs
```

No curso, n√≥s iremos utilizar o **Weave-net**, que pode ser instalado com o comando a seguir.

```
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
```

Para verificar se o *pod network* foi criado com sucesso, execute o seguinte comando.

```
kubectl get pods -n kube-system
```

O resultado deve ser semelhante ao mostrado a seguir.

```
NAME                                READY   STATUS    RESTARTS   AGE
coredns-66bff467f8-pfm2c            1/1     Running   0          8d
coredns-66bff467f8-s8pk4            1/1     Running   0          8d
etcd-docker-01                      1/1     Running   0          8d
kube-apiserver-docker-01            1/1     Running   0          8d
kube-controller-manager-docker-01   1/1     Running   0          8d
kube-proxy-mdcgf                    1/1     Running   0          8d
kube-proxy-q9cvf                    1/1     Running   0          8d
kube-proxy-vf8mq                    1/1     Running   0          8d
kube-scheduler-docker-01            1/1     Running   0          8d
weave-net-7dhpf                     2/2     Running   0          8d
weave-net-fvttp                     2/2     Running   0          8d
weave-net-xl7km                     2/2     Running   0          8d
```

Pode-se observar que h√° tr√™s cont√™ineres do Weave-net em execu√ß√£o provendo a *pod network* para o nosso *cluster*.

## Verificando a instala√ß√£o

Para verificar se a instala√ß√£o est√° funcionando, e se os n√≥s est√£o se comunicando, voc√™ pode executar o comando ``kubectl get nodes`` no n√≥ master, que deve lhe retornar algo como o conte√∫do a seguir.

```
NAME        STATUS   ROLES    AGE   VERSION
elliot-01   Ready    master   8d    v1.19.1
elliot-02   Ready    <none>   8d    v1.19.1
elliot-03   Ready    <none>   8d    v1.19.1
```

# Primeiros passos no k8s

## Exibindo informa√ß√µes detalhadas sobre os n√≥s

```
kubectl describe node [nome_do_no]
```

Exemplo:

```
kubectl describe node elliot-02

Name:               elliot-02
Roles:              <none>
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=elliot-02
                    kubernetes.io/os=linux
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
```

## Exibindo novamente token para entrar no cluster

Para visualizar novamente o *token* para inser√ß√£o de novos n√≥s, execute o seguinte comando.

```
# kubeadm token create --print-join-command
```

## Ativando o autocomplete

Em distribui√ß√µes Debian e baseadas, certifique-se que o pacote ``bash-completion`` esteja instalado. Instale-o com o comando a seguir.

```
sudo apt install -y bash-completion
```

Em sistemas Red Hat e baseados, execute:

```
# yum install -y bash-completion
```

Feito isso, execute o seguinte comando.

```
kubectl completion bash > /etc/bash_completion.d/kubectl
```

Efetue *logoff* e *login* para carregar o *autocomplete*. Caso n√£o deseje, execute:

```
source < (kubectl completion bash)
```

## Verificando os namespaces e pods

O k8s organiza tudo dentro de *namespaces*. Por meio deles, podem ser realizadas limita√ß√µes de seguran√ßa e de recursos dentro do *cluster*, tais como *pods*, *replication controllers* e diversos outros. Para visualizar os *namespaces* dispon√≠veis no *cluster*, digite:

```
kubectl get namespaces

NAME              STATUS   AGE
default           Active   8d
kube-node-lease   Active   8d
kube-public       Active   8d
kube-system       Active   8d
```

Vamos listar os *pods* do *namespace* **kube-system** utilizando o comando a seguir.

```
kubectl get pod -n kube-system

NAME                                READY   STATUS    RESTARTS   AGE
coredns-66bff467f8-pfm2c            1/1     Running   0          8d
coredns-66bff467f8-s8pk4            1/1     Running   0          8d
etcd-docker-01                      1/1     Running   0          8d
kube-apiserver-docker-01            1/1     Running   0          8d
kube-controller-manager-docker-01   1/1     Running   0          8d
kube-proxy-mdcgf                    1/1     Running   0          8d
kube-proxy-q9cvf                    1/1     Running   0          8d
kube-proxy-vf8mq                    1/1     Running   0          8d
kube-scheduler-docker-01            1/1     Running   0          8d
weave-net-7dhpf                     2/2     Running   0          8d
weave-net-fvttp                     2/2     Running   0          8d
weave-net-xl7km                     2/2     Running   0          8d
```

Ser√° que h√° algum *pod* escondido em algum *namespace*? √â poss√≠vel listar todos os *pods* de todos os *namespaces* com o comando a seguir.

```
kubectl get pods --all-namespaces
```

H√° a possibilidade ainda, de utilizar o comando com a op√ß√£o ```-o wide```, que disponibiliza maiores informa√ß√µes sobre o recurso, inclusive em qual n√≥ o *pod* est√° sendo executado. Exemplo:

```
kubectl get pods --all-namespaces -o wide

NAMESPACE     NAME                                READY   STATUS    RESTARTS   AGE   IP             NODE        NOMINATED NODE   READINESS GATES
default       nginx                               1/1     Running   0          24m   10.44.0.1      docker-02   <none>           <none>
kube-system   coredns-66bff467f8-pfm2c            1/1     Running   0          8d    10.32.0.3      docker-01   <none>           <none>
kube-system   coredns-66bff467f8-s8pk4            1/1     Running   0          8d    10.32.0.2      docker-01   <none>           <none>
kube-system   etcd-docker-01                      1/1     Running   0          8d    172.16.83.14   docker-01   <none>           <none>
kube-system   kube-apiserver-docker-01            1/1     Running   0          8d    172.16.83.14   docker-01   <none>           <none>
kube-system   kube-controller-manager-docker-01   1/1     Running   0          8d    172.16.83.14   docker-01   <none>           <none>
kube-system   kube-proxy-mdcgf                    1/1     Running   0          8d    172.16.83.14   docker-01   <none>           <none>
kube-system   kube-proxy-q9cvf                    1/1     Running   0          8d    172.16.83.12   docker-03   <none>           <none>
kube-system   kube-proxy-vf8mq                    1/1     Running   0          8d    172.16.83.13   docker-02   <none>           <none>
kube-system   kube-scheduler-docker-01            1/1     Running   0          8d    172.16.83.14   docker-01   <none>           <none>
kube-system   weave-net-7dhpf                     2/2     Running   0          8d    172.16.83.12   docker-03   <none>           <none>
kube-system   weave-net-fvttp                     2/2     Running   0          8d    172.16.83.13   docker-02   <none>           <none>
kube-system   weave-net-xl7km                     2/2     Running   0          8d    172.16.83.14   docker-01   <none>           <none>
```

## Executando nosso primeiro pod no k8s

Iremos iniciar o nosso primeiro *pod* no k8s. Para isso, executaremos o comando a seguir.

```
kubectl run nginx --image nginx

pod/nginx created
```

Listando os *pods* com ``kubectl get pods``, obteremos a seguinte sa√≠da.

```
NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          66s
```

Vamos olhar agora a descri√ß√£o desse objeto dentro do *cluster*.

```
kubectl describe pod nginx

Name:         nginx
Namespace:    default
Priority:     0
Node:         docker-02/172.16.83.13
Start Time:   Tue, 12 May 2020 02:29:38 -0300
Labels:       run=nginx
Annotations:  <none>
Status:       Running
IP:           10.44.0.1
IPs:
  IP:  10.44.0.1
Containers:
  nginx:
    Container ID:   docker://2719e2bc023944ee8f34db538094c96b24764a637574c703e232908b46b12a9f
    Image:          nginx
    Image ID:       docker-pullable://nginx@sha256:86ae264c3f4acb99b2dee4d0098c40cb8c46dcf9e1148f05d3a51c4df6758c12
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Tue, 12 May 2020 02:29:42 -0300
```

## Verificar os √∫ltimos eventos do cluster

Voc√™ pode verificar quais s√£o os √∫ltimos eventos do *cluster* com o comando ``kubectl get events``. Ser√£o mostrados eventos como: o *download* de imagens do Docker Hub (ou de outro *registry* configurado), a cria√ß√£o/remo√ß√£o de *pods*, etc.

A sa√≠da a seguir mostra o resultado da cria√ß√£o do nosso cont√™iner com Nginx.

```
LAST SEEN   TYPE     REASON      OBJECT      MESSAGE
5m34s       Normal   Scheduled   pod/nginx   Successfully assigned default/nginx to docker-02
5m33s       Normal   Pulling     pod/nginx   Pulling image "nginx"
5m31s       Normal   Pulled      pod/nginx   Successfully pulled image "nginx"
5m30s       Normal   Created     pod/nginx   Created container nginx
5m30s       Normal   Started     pod/nginx   Started container nginx
```

No resultado do comando anterior √© poss√≠vel observar que a execu√ß√£o do nginx ocorreu no *namespace* default e que a imagem **nginx** n√£o existia no reposit√≥rio local e, sendo assim, teve de ser feito download da imagem.

## Efetuar o dump de um objeto em formato YAML

Assim como quando se est√° trabalhando com *stacks* no Docker Swarm, normalmente recursos no k8s s√£o declarados em arquivos **YAML** ou **JSON** e depois manipulados atrav√©s do ``kubectl``.

Para nos poupar o trabalho de escrever o arquivo inteiro, pode-se utilizar como *template* o *dump* de um objeto j√° existente no k8s, como mostrado a seguir.

```
kubectl get pod nginx -o yaml > meu-primeiro.yaml
```

Ser√° criado um novo arquivo chamado ``meu-primeiro.yaml``, resultante do redirecionamento da sa√≠da do comando ``kubectl get pod nginx -o yaml``.

Abrindo o arquivo com ``vim meu-primeiro.yaml`` (voc√™ pode utilizar o editor que voc√™ preferir), teremos o seguinte conte√∫do.

```yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2020-05-12T05:29:38Z"
  labels:
    run: nginx
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:labels:
          .: {}
          f:run: {}
      f:spec:
        f:containers:
          k:{"name":"nginx"}:
            .: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext: {}
        f:terminationGracePeriodSeconds: {}
    manager: kubectl
    operation: Update
    time: "2020-05-12T05:29:38Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:phase: {}
        f:podIP: {}
        f:podIPs:
          .: {}
          k:{"ip":"10.44.0.1"}:
            .: {}
            f:ip: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    time: "2020-05-12T05:29:43Z"
  name: nginx
  namespace: default
  resourceVersion: "1673991"
  selfLink: /api/v1/namespaces/default/pods/nginx
  uid: 36506f7b-1f3b-4ee8-b063-de3e6d31bea9
spec:
  containers:
  - image: nginx
    imagePullPolicy: Always
    name: nginx
    resources: {}
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: default-token-nkz89
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  nodeName: docker-02
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: default-token-nkz89
    secret:
      defaultMode: 420
      secretName: default-token-nkz89
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2020-05-12T05:29:38Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2020-05-12T05:29:43Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2020-05-12T05:29:43Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2020-05-12T05:29:38Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: docker://2719e2bc023944ee8f34db538094c96b24764a637574c703e232908b46b12a9f
    image: nginx:latest
    imageID: docker-pullable://nginx@sha256:86ae264c3f4acb99b2dee4d0098c40cb8c46dcf9e1148f05d3a51c4df6758c12
    lastState: {}
    name: nginx
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2020-05-12T05:29:42Z"
  hostIP: 172.16.83.13
  phase: Running
  podIP: 10.44.0.1
  podIPs:
  - ip: 10.44.0.1
  qosClass: BestEffort
  startTime: "2020-05-12T05:29:38Z"
```

Observando o arquivo anterior, notamos que este reflete o **estado** do *pod*. N√≥s desejamos utilizar tal arquivo apenas como um modelo, e sendo assim, podemos apagar as entradas que armazenam dados de estado desse *pod*, como *status* e todas as demais configura√ß√µes que s√£o espec√≠ficas dele. O arquivo final ficar√° com o conte√∫do semelhante a este:

```yaml
  apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: null
    labels:
      run: nginx
    name: nginx
  spec:
    containers:
    - image: nginx
      name: nginx
      resources: {}
    dnsPolicy: ClusterFirst
    restartPolicy: Always
  status: {}
```

Vamos agora remover o nosso *pod* com o seguinte comando.

```
kubectl delete pod nginx
```

A sa√≠da deve ser algo como:

```
pod "nginx" deleted
```

Vamos recri√°-lo, agora a partir do nosso arquivo YAML.

```
kubectl create -f meu-primeiro.yaml

pod/nginx created
```

Observe que n√£o foi necess√°rio informar ao ``kubectl`` qual tipo de recurso seria criado, pois isso j√° est√° contido dentro do arquivo.

Listando os *pods* dispon√≠veis com o seguinte comando.

```
kubectl get pods
```

Deve-se obter uma sa√≠da similar √† esta:

```
NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          109s
```

Uma outra forma de criar um arquivo de *template* √© atrav√©s da op√ß√£o ``--dry-run`` do ``kubectl``, com o funcionamento ligeiramente diferente dependendo do tipo de recurso que ser√° criado. Exemplos:

Para a cria√ß√£o do template de um *pod*:

```
kubectl run meu-nginx --image nginx --dry-run=client -o yaml > pod-template.yaml
```

Para a cria√ß√£o do *template* de um *deployment*:

```
kubectl create deployment meu-nginx --image=nginx --dry-run=client -o yaml > deployment-template.yaml
```

A vantagem deste m√©todo √© que n√£o h√° a necessidade de limpar o arquivo, al√©m de serem apresentadas apenas as op√ß√µes necess√°rias do recurso.

## Socorro, s√£o muitas op√ß√µes!

Calma, n√≥s sabemos. Mas o ``kubectl`` pode lhe auxiliar um pouco em rela√ß√£o a isso. Ele cont√©m a op√ß√£o ``explain``, que voc√™ pode utilizar caso precise de ajuda com alguma op√ß√£o em espec√≠fico dos arquivos de recurso. A seguir alguns exemplos de sintaxe.

```
kubectl explain [recurso]

kubectl explain [recurso.caminho.para.spec]

kubectl explain [recurso.caminho.para.spec] --recursive
```

Exemplos:

```
kubectl explain deployment

kubectl explain pod --recursive

kubectl explain deployment.spec.template.spec
```

## Expondo o pod

Dispositivos fora do *cluster*, por padr√£o, n√£o conseguem acessar os *pods* criados, como √© comum em outros sistemas de cont√™ineres. Para expor um *pod*, execute o comando a seguir.

```
kubectl expose pod nginx
```

Ser√° apresentada a seguinte mensagem de erro:

```
error: couldn't find port via --port flag or introspection
See 'kubectl expose -h' for help and examples
```

O erro ocorre devido ao fato do k8s n√£o saber qual √© a porta de destino do cont√™iner que deve ser exposta (no caso, a 80/TCP). Para configur√°-la, vamos primeiramente remover o nosso *pod* antigo:

```
kubectl delete -f meu-primeiro.yaml
```

Abra agora o arquivo ``meu-primeiro.yaml`` e adicione o bloco a seguir.

```yaml
...
spec:
       containers:
       - image: nginx
         imagePullPolicy: Always
         ports:
         - containerPort: 80
         name: nginx
         resources: {}
...
```

> Aten√ß√£o!!! Arquivos YAML utilizam para sua tabula√ß√£o dois espa√ßos e n√£o *tab*.

Feita a modifica√ß√£o no arquivo, salve-o e crie novamente o *pod* com o comando a seguir.

```
kubectl create -f meu-primeiro.yaml

pod/nginx created
```

Liste o pod.

```
kubectl get pod nginx

NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          32s
```

O comando a seguir cria um objeto do k8s chamado de *Service*, que √© utilizado justamente para expor *pods* para acesso externo.

```
kubectl expose pod nginx
```

Podemos listar todos os *services* com o comando a seguir.

```
kubectl get services

NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP   8d
nginx        ClusterIP   10.105.41.192   <none>        80/TCP    2m30s
```

Como √© poss√≠vel observar, h√° dois *services* no nosso *cluster*: o primeiro √© para uso do pr√≥prio k8s, enquanto o segundo foi o qu√™ acabamos de criar. Utilizando o ``curl`` contra o endere√ßo IP mostrado na coluna *CLUSTER-IP*, deve nos ser apresentada a tela principal do Nginx.

```
curl 10.105.41.192

<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
```

Este *pod* est√° dispon√≠vel para acesso a partir de qualquer n√≥ do *cluster*.

## Limpando tudo e indo para casa

Para mostrar todos os recursos rec√©m criados, pode-se utilizar uma das seguintes op√ß√µes a seguir.

```
kubectl get all

kubectl get pod,service

kubectl get pod,svc
```

Note que o k8s nos disponibiliza algumas abrevia√ß√µes de seus recursos. Com o tempo voc√™ ir√° se familiar com elas. Para apagar os recursos criados, voc√™ pode executar os seguintes comandos.

```
kubectl delete -f meu-primeiro.yaml

kubectl delete service nginx
```

Liste novamente os recursos para ver se os mesmos ainda est√£o presentes.
