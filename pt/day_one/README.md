# Descomplicando o Kubernetes
&nbsp;
## DAY-1
&nbsp;

### Indice

- [Descomplicando o Kubernetes](#descomplicando-o-kubernetes)
  - [DAY-1](#day-1)
    - [Indice](#indice)
    - [O que iremos ver hoje?](#o-que-iremos-ver-hoje)
    - [Inicio da aula do Day-1](#inicio-da-aula-do-day-1)
    - [Qual distro GNU/Linux devo usar?](#qual-distro-gnulinux-devo-usar)
    - [Alguns sites que devemos visitar](#alguns-sites-que-devemos-visitar)
    - [O Container Engine](#o-container-engine)
      - [OCI - Open Container Initiative](#oci---open-container-initiative)
      - [O Container Runtime](#o-container-runtime)
    - [O que √© o Kubernetes?](#o-que-√©-o-kubernetes)
    - [Arquitetura do k8s](#arquitetura-do-k8s)
    - [Portas que devemos nos preocupar](#portas-que-devemos-nos-preocupar)
    - [Conceitos-chave do k8s](#conceitos-chave-do-k8s)
    - [Instalando e customizando o Kubectl](#instalando-e-customizando-o-kubectl)
      - [Instala√ß√£o do Kubectl no GNU/Linux](#instala√ß√£o-do-kubectl-no-gnulinux)
      - [Instala√ß√£o do Kubectl no MacOS](#instala√ß√£o-do-kubectl-no-macos)
      - [Instala√ß√£o do Kubectl no Windows](#instala√ß√£o-do-kubectl-no-windows)
    - [Customizando o kubectl](#customizando-o-kubectl)
      - [Auto-complete](#auto-complete)
      - [Criando um alias para o kubectl](#criando-um-alias-para-o-kubectl)
    - [Criando um cluster Kubernetes](#criando-um-cluster-kubernetes)
    - [Criando o cluster em sua m√°quina local](#criando-o-cluster-em-sua-m√°quina-local)
      - [Minikube](#minikube)
        - [Requisitos b√°sicos](#requisitos-b√°sicos)
        - [Instala√ß√£o do Minikube no GNU/Linux](#instala√ß√£o-do-minikube-no-gnulinux)
        - [Instala√ß√£o do Minikube no MacOS](#instala√ß√£o-do-minikube-no-macos)
        - [Instala√ß√£o do Minikube no Microsoft Windows](#instala√ß√£o-do-minikube-no-microsoft-windows)
        - [Iniciando, parando e excluindo o Minikube](#iniciando-parando-e-excluindo-o-minikube)
        - [Certo, e como eu sei que est√° tudo funcionando como deveria?](#certo-e-como-eu-sei-que-est√°-tudo-funcionando-como-deveria)
        - [Ver detalhes sobre o cluster](#ver-detalhes-sobre-o-cluster)
        - [Descobrindo o endere√ßo do Minikube](#descobrindo-o-endere√ßo-do-minikube)
        - [Acessando a m√°quina do Minikube via SSH](#acessando-a-m√°quina-do-minikube-via-ssh)
        - [Dashboard do Minikube](#dashboard-do-minikube)
        - [Logs do Minikube](#logs-do-minikube)
        - [Remover o cluster](#remover-o-cluster)
      - [Kind](#kind)
        - [Instala√ß√£o no GNU/Linux](#instala√ß√£o-no-gnulinux)
        - [Instala√ß√£o no MacOS](#instala√ß√£o-no-macos)
        - [Instala√ß√£o no Windows](#instala√ß√£o-no-windows)
          - [Instala√ß√£o no Windows via Chocolatey](#instala√ß√£o-no-windows-via-chocolatey)
        - [Criando um cluster com o Kind](#criando-um-cluster-com-o-kind)
        - [Criando um cluster com m√∫ltiplos n√≥s locais com o Kind](#criando-um-cluster-com-m√∫ltiplos-n√≥s-locais-com-o-kind)
    - [Primeiros passos no k8s](#primeiros-passos-no-k8s)
        - [Verificando os namespaces e pods](#verificando-os-namespaces-e-pods)
        - [Executando nosso primeiro pod no k8s](#executando-nosso-primeiro-pod-no-k8s)
        - [Executando nosso primeiro pod no k8s](#executando-nosso-primeiro-pod-no-k8s-1)
      - [Expondo o pod e criando um Service](#expondo-o-pod-e-criando-um-service)
      - [Limpando tudo e indo para casa](#limpando-tudo-e-indo-para-casa)

&nbsp;


### O que iremos ver hoje?

Durante o Day-1 n√≥s vamos entender o que √© um container, vamos falar sobre a import√¢ncia do container runtime e do container engine. Durante o Day-1 vamos entender o que √© o Kubernetes e sua arquitetura, vamos falar sobre o control plane, workers, apiserver, scheduler, controller e muito mais!
Ser√° aqui que iremos criar o nosso primeiro cluster Kubernetes e realizar o deploy de um pod do Nginx. 
O Day-1 √© para que eu possa me sentir mais confort√°vel com o Kubernetes e seus conceitos iniciais.
&nbsp;
### Inicio da aula do Day-1
&nbsp;
### Qual distro GNU/Linux devo usar?

Devido ao fato de algumas ferramentas importantes, como o ``systemd`` e ``journald``, terem se tornado padr√£o na maioria das principais distribui√ß√µes dispon√≠veis hoje, voc√™ n√£o deve encontrar problemas para seguir o treinamento, caso voc√™ opte por uma delas, como Ubuntu, Debian, CentOS e afins.
&nbsp;
### Alguns sites que devemos visitar

Abaixo temos os sites oficiais do projeto do Kubernetes:

- [https://kubernetes.io](https://kubernetes.io)

- [https://github.com/kubernetes/kubernetes/](https://github.com/kubernetes/kubernetes/)

- [https://github.com/kubernetes/kubernetes/issues](https://github.com/kubernetes/kubernetes/issues)

&nbsp;
Abaixo temos as p√°ginas oficiais das certifica√ß√µes do Kubernetes (CKA, CKAD e CKS):

- [https://www.cncf.io/certification/cka/](https://www.cncf.io/certification/cka/)

- [https://www.cncf.io/certification/ckad/](https://www.cncf.io/certification/ckad/)

- [https://www.cncf.io/certification/cks/](https://www.cncf.io/certification/cks/)

&nbsp;
### O Container Engine

Antes de come√ßar a falar um pouco mais sobre o Kubernetes, n√≥s primeiro precisamos entender alguns componentes que s√£o importantes no ecossistema do Kubernetes, um desses componentes √© o Container Engine. 

O *Container Engine* √© o respons√°vel por gerenciar as imagens e volumes, √© ele o respons√°vel por garantir que os os recursos que os containers est√£o utilizando est√° devidamente isolados, a vida do container, storage, rede, etc.

Hoje temos diversas op√ß√µes para se utilizar como *Container Engine*, que at√© pouco tempo atr√°s tinhamos somente o Docker para esse papel.

Op√ß√µes como o Docker, o CRI-O e o Podman s√£o bem conhecidas e preparadas para o ambiente produtivo. O Docker, como todos sabem, √© o Container Engine mais popular e ele utiliza como Container Runtime o containerd.

Container Runtime? O que √© isso?

Calma que vou te explicar j√° j√°, mas antes temos que falar sobre a OCI. :)

&nbsp;
#### OCI - Open Container Initiative

A OCI √© uma organiza√ß√£o sem fins lucrativos que tem como objetivo padronizar a cria√ß√£o de containers, para que possam ser executados em qualquer ambiente. A OCI foi fundada em 2015 pela Docker, CoreOS, Google, IBM, Microsoft, Red Hat e VMware e hoje faz parte da Linux Foundation.

O principal projeto criado pela OCI √© o *runc*, que √© o principal container runtime de baixo n√≠vel, e utilizado por diferentes *Container Engines, como o Docker. 
O *runc* √© um projeto open source, escrito em Go e seu c√≥digo est√° dispon√≠vel no GitHub.

Agora sim j√° podemos falar sobre o que √© o Container Runtime.

&nbsp;
#### O Container Runtime

Para que seja poss√≠vel executar os containers nos n√≥s √© necess√°rio ter um *Container Runtime* instalado em cada um dos n√≥s.

O *Container Runtime* √© o respons√°vel por executar os containers nos n√≥s. Quando voc√™ est√° utilizando Docker ou Podman para executar containers em sua m√°quina, por exemplo, voc√™ est√° fazendo uso de algum *Container Runtime*, ou melhor, o seu Container Engine est√° fazendo uso de algum *Container Runtime*.

Temos Quatro tipos de *Container Runtime*:

- Low-level: s√£o os *Container Runtime* que s√£o executados diretamente pelo Kernel, como o runc, o crun e o runsc.

- High-level: s√£o os *Container Runtime* que s√£o executados por um *Container Engine*, como o containerd, o CRI-O e o Podman.

- Sandbox: s√£o os *Container Runtime* que s√£o executados por um *Container Engine* e que s√£o respons√°veis por executar containers de forma segura em unikernels ou utilizando algum proxy para fazer a comunica√ß√£o com o Kernel. O gVisor √© um exemplo de *Container Runtime* do tipo Sandbox.

- Virtualized: s√£o os *Container Runtime* que s√£o executados por um *Container Engine* e que s√£o respons√°veis por executar containers de forma segura em m√°quinas virtuais. A performance aqui √© um pouco menor do que quando temos um sendo executado nativamente.
O Kata Containers √© um exemplo de *Container Runtime* do tipo Virtualized.

&nbsp;
### O que √© o Kubernetes?

**Vers√£o resumida:**

O projeto Kubernetes foi desenvolvido pela Google, em meados de 2014, para atuar como um orquestrador de cont√™ineres para a empresa. O Kubernetes (k8s), cujo termo em Grego significa "timoneiro", √© um projeto *open source* que conta com *design* e desenvolvimento baseados no projeto Borg, que tamb√©m √© da Google [1](https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/). Alguns outros produtos dispon√≠veis no mercado, tais como o Apache Mesos e o Cloud Foundry, tamb√©m surgiram a partir do projeto Borg.

Como Kubernetes √© uma palavra dif√≠cil de se pronunciar - e de se escrever - a comunidade simplesmente o apelidou de **k8s**, seguindo o padr√£o [i18n](http://www.i18nguy.com/origini18n.html) (a letra "k" seguida por oito letras e o "s" no final), pronunciando-se simplesmente "kates".

**Vers√£o longa:**

Praticamente todo software desenvolvido na Google √© executado em cont√™iner [2](https://www.enterpriseai.news/2014/05/28/google-runs-software-containers/). A Google j√° gerencia cont√™ineres em larga escala h√° mais de uma d√©cada, quando n√£o se falava tanto sobre isso. Para atender a demanda interna, alguns desenvolvedores do Google constru√≠ram tr√™s sistemas diferentes de gerenciamento de cont√™ineres: **Borg**, **Omega** e **Kubernetes**. Cada sistema teve o desenvolvimento bastante influenciado pelo antecessor, embora fosse desenvolvido por diferentes raz√µes.

O primeiro sistema de gerenciamento de cont√™ineres desenvolvido no Google foi o Borg, constru√≠do para gerenciar servi√ßos de longa dura√ß√£o e jobs em lote, que anteriormente eram tratados por dois sistemas:  **Babysitter** e **Global Work Queue**. O √∫ltimo influenciou fortemente a arquitetura do Borg, mas estava focado em execu√ß√£o de jobs em lote. O Borg continua sendo o principal sistema de gerenciamento de cont√™ineres dentro do Google por causa de sua escala, variedade de recursos e robustez extrema.

O segundo sistema foi o Omega, descendente do Borg. Ele foi impulsionado pelo desejo de melhorar a engenharia de software do ecossistema Borg. Esse sistema aplicou muitos dos padr√µes que tiveram sucesso no Borg, mas foi constru√≠do do zero para ter a arquitetura mais consistente. Muitas das inova√ß√µes do Omega foram posteriormente incorporadas ao Borg.

O terceiro sistema foi o Kubernetes. Concebido e desenvolvido em um mundo onde desenvolvedores externos estavam se interessando em cont√™ineres e o Google desenvolveu um neg√≥cio em amplo crescimento atualmente, que √© a venda de infraestrutura de nuvem p√∫blica.

O Kubernetes √© de c√≥digo aberto - em contraste com o Borg e o Omega que foram desenvolvidos como sistemas puramente internos do Google. O Kubernetes foi desenvolvido com um foco mais forte na experi√™ncia de desenvolvedores que escrevem aplicativos que s√£o executados em um cluster: seu principal objetivo √© facilitar a implanta√ß√£o e o gerenciamento de sistemas distribu√≠dos, enquanto se beneficia do melhor uso de recursos de mem√≥ria e processamento que os cont√™ineres possibilitam.

Estas informa√ß√µes foram extra√≠das e adaptadas deste [artigo](https://static.googleusercontent.com/media/research.google.com/pt-BR//pubs/archive/44843.pdf), que descreve as li√ß√µes aprendidas com o desenvolvimento e opera√ß√£o desses sistemas.
&nbsp;
### Arquitetura do k8s

Assim como os demais orquestradores dispon√≠veis, o k8s tamb√©m segue um modelo *control plane/workers*, constituindo assim um *cluster*, onde para seu funcionamento √© recomendado no m√≠nimo tr√™s n√≥s: o n√≥ *control-plane*, respons√°vel (por padr√£o) pelo gerenciamento do *cluster*, e os demais como *workers*, executores das aplica√ß√µes que queremos executar sobre esse *cluster*.

√â poss√≠vel criar um cluster Kubernetes rodando em apenas um n√≥, por√©m √© recomendado somente para fins de estudos e nunca executado em ambiente produtivo.

Caso voc√™ queira utilizar o Kubernetes em sua m√°quina local, em seu desktop, existem diversas solu√ß√µes que ir√£o criar um cluster Kubernetes, utilizando m√°quinas virtuais ou o Docker, por exemplo.

Com isso voc√™ poder√° ter um cluster Kubernetes com diversos n√≥s, por√©m todos eles rodando em sua m√°quina local, em seu desktop.

Alguns exemplos s√£o:

* [Kind](https://kind.sigs.k8s.io/docs/user/quick-start): Uma ferramenta para execu√ß√£o de cont√™ineres Docker que simulam o funcionamento de um cluster Kubernetes. √â utilizado para fins did√°ticos, de desenvolvimento e testes. O **Kind n√£o deve ser utilizado para produ√ß√£o**;

* [Minikube](https://github.com/kubernetes/minikube): ferramenta para implementar um *cluster* Kubernetes localmente com apenas um n√≥. Muito utilizado para fins did√°ticos, de desenvolvimento e testes. O **Minikube n√£o deve ser utilizado para produ√ß√£o**;

* [MicroK8S](https://microk8s.io): Desenvolvido pela [Canonical](https://canonical.com), mesma empresa que desenvolve o [Ubuntu](https://ubuntu.com). Pode ser utilizado em diversas distribui√ß√µes e **pode ser utilizado em ambientes de produ√ß√£o**, em especial para *Edge Computing* e IoT (*Internet of things*);

* [k3s](https://k3s.io): Desenvolvido pela [Rancher Labs](https://rancher.com), √© um concorrente direto do MicroK8s, podendo ser executado inclusive em Raspberry Pi;

* [k0s](https://k0sproject.io): Desenvolvido pela [Mirantis](https://www.mirantis.com), mesma empresa que adquiriu a parte enterprise do [Docker](https://www.docker.com). √â uma distribui√ß√£o do Kubernetes com todos os recursos necess√°rios para funcionar em um √∫nico bin√°rio, que proporciona uma simplicidade na instala√ß√£o e manuten√ß√£o do cluster. A pron√∫ncia √© correta √© kay-zero-ess e tem por objetivo reduzir o esfor√ßo t√©cnico e desgaste na instala√ß√£o de um cluster Kubernetes, por isso o seu nome faz alus√£o a *Zero Friction*. **O k0s pode ser utilizado em ambientes de produ√ß√£o**;

* **API Server**: √â um dos principais componentes do k8s. Este componente fornece uma API que utiliza JSON sobre HTTP para comunica√ß√£o, onde para isto √© utilizado principalmente o utilit√°rio ``kubectl``, por parte dos administradores, para a comunica√ß√£o com os demais n√≥s, como mostrado no gr√°fico. Estas comunica√ß√µes entre componentes s√£o estabelecidas atrav√©s de requisi√ß√µes [REST](https://restfulapi.net);

* **etcd**: O etcd √© um *datastore* chave-valor distribu√≠do que o k8s utiliza para armazenar as especifica√ß√µes, status e configura√ß√µes do *cluster*. Todos os dados armazenados dentro do etcd s√£o manipulados apenas atrav√©s da API. Por quest√µes de seguran√ßa, o etcd √© por padr√£o executado apenas em n√≥s classificados como *control plane* no *cluster* k8s, mas tamb√©m podem ser executados em *clusters* externos, espec√≠ficos para o etcd, por exemplo;

* **Scheduler**: O *scheduler* √© respons√°vel por selecionar o n√≥ que ir√° hospedar um determinado *pod* (a menor unidade de um *cluster* k8s - n√£o se preocupe sobre isso por enquanto, n√≥s falaremos mais sobre isso mais tarde) para ser executado. Esta sele√ß√£o √© feita baseando-se na quantidade de recursos dispon√≠veis em cada n√≥, como tamb√©m no estado de cada um dos n√≥s do *cluster*, garantindo assim que os recursos sejam bem distribu√≠dos. Al√©m disso, a sele√ß√£o dos n√≥s, na qual um ou mais pods ser√£o executados, tamb√©m pode levar em considera√ß√£o pol√≠ticas definidas pelo usu√°rio, tais como afinidade, localiza√ß√£o dos dados a serem lidos pelas aplica√ß√µes, etc;

* **Controller Manager**: √â o *controller manager* quem garante que o *cluster* esteja no √∫ltimo estado definido no etcd. Por exemplo: se no etcd um *deploy* est√° configurado para possuir dez r√©plicas de um *pod*, √© o *controller manager* quem ir√° verificar se o estado atual do *cluster* corresponde a este estado e, em caso negativo, procurar√° conciliar ambos;

* **Kubelet**: O *kubelet* pode ser visto como o alente do k8s que √© executado nos n√≥s workers. Em cada n√≥ worker dever√° existir um agente Kubelet em execu√ß√£o. O Kubelet √© respons√°vel por de fato gerenciar os *pods* que foram direcionados pelo *controller* do *cluster*, dentro dos n√≥s, de forma que para isto o Kubelet pode iniciar, parar e manter os cont√™ineres e os pods em funcionamento de acordo com o instru√≠do pelo controlador do cluster;

* **Kube-proxy**: Age como um *proxy* e um *load balancer*. Este componente √© respons√°vel por efetuar roteamento de requisi√ß√µes para os *pods* corretos, como tamb√©m por cuidar da parte de rede do n√≥;

&nbsp;
### Portas que devemos nos preocupar

**CONTROL PLANE**

Protocol|Direction|Port Range|Purpose|Used By
--------|---------|----------|-------|-------
TCP|Inbound|6443*|Kubernetes API server|All
TCP|Inbound|2379-2380|etcd server client API|kube-apiserver, etcd
TCP|Inbound|10250|Kubelet API|Self, Control plane
TCP|Inbound|10251|kube-scheduler|Self
TCP|Inbound|10252|kube-controller-manager|Self

* Toda porta marcada por * √© customiz√°vel, voc√™ precisa se certificar que a porta alterada tamb√©m esteja aberta.


&nbsp;
**WORKERS**

Protocol|Direction|Port Range|Purpose|Used By
--------|---------|----------|-------|-------
TCP|Inbound|10250|Kubelet API|Self, Control plane
TCP|Inbound|30000-32767|NodePort|Services All

&nbsp;
### Conceitos-chave do k8s

√â importante saber que a forma como o k8s gerencia os cont√™ineres √© ligeiramente diferente de outros orquestradores, como o Docker Swarm, sobretudo devido ao fato de que ele n√£o trata os cont√™ineres diretamente, mas sim atrav√©s de *pods*. Vamos conhecer alguns dos principais conceitos que envolvem o k8s a seguir:

- **Pod**: √â o menor objeto do k8s. Como dito anteriormente, o k8s n√£o trabalha com os cont√™ineres diretamente, mas organiza-os dentro de *pods*, que s√£o abstra√ß√µes que dividem os mesmos recursos, como endere√ßos, volumes, ciclos de CPU e mem√≥ria. Um pod pode possuir v√°rios cont√™ineres;

- **Deployment**: √â um dos principais *controllers* utilizados. O *Deployment*, em conjunto com o *ReplicaSet*, garante que determinado n√∫mero de r√©plicas de um pod esteja em execu√ß√£o nos n√≥s workers do cluster. Al√©m disso, o Deployment tamb√©m √© respons√°vel por gerenciar o ciclo de vida das aplica√ß√µes, onde caracter√≠sticas associadas a aplica√ß√£o, tais como imagem, porta, volumes e vari√°veis de ambiente, podem ser especificados em arquivos do tipo *yaml* ou *json* para posteriormente serem passados como par√¢metro para o ``kubectl`` executar o deployment. Esta a√ß√£o pode ser executada tanto para cria√ß√£o quanto para atualiza√ß√£o e remo√ß√£o do deployment;

- **ReplicaSets**: √â um objeto respons√°vel por garantir a quantidade de pods em execu√ß√£o no n√≥;

- **Services**: √â uma forma de voc√™ expor a comunica√ß√£o atrav√©s de um *ClusterIP*, *NodePort* ou *LoadBalancer* para distribuir as requisi√ß√µes entre os diversos Pods daquele Deployment. Funciona como um balanceador de carga.


### Instalando e customizando o Kubectl

#### Instala√ß√£o do Kubectl no GNU/Linux

Vamos instalar o ``kubectl`` com os seguintes comandos.

```
curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl

chmod +x ./kubectl

sudo mv ./kubectl /usr/local/bin/kubectl

kubectl version --client
```
&nbsp;
#### Instala√ß√£o do Kubectl no MacOS

O ``kubectl`` pode ser instalado no MacOS utilizando tanto o [Homebrew](https://brew.sh), quanto o m√©todo tradicional. Com o Homebrew j√° instalado, o kubectl pode ser instalado da seguinte forma.

```
sudo brew install kubectl

kubectl version --client
```
&nbsp;
Ou:

```
sudo brew install kubectl-cli

kubectl version --client
```
&nbsp;
J√° com o m√©todo tradicional, a instala√ß√£o pode ser realizada com os seguintes comandos.

```
curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl"

chmod +x ./kubectl

sudo mv ./kubectl /usr/local/bin/kubectl

kubectl version --client
```
&nbsp;
#### Instala√ß√£o do Kubectl no Windows

A instala√ß√£o do ``kubectl`` pode ser realizada efetuando o download [neste link](https://dl.k8s.io/release/v1.24.3/bin/windows/amd64/kubectl.exe). 

Outras informa√ß√µes sobre como instalar o kubectl no Windows podem ser encontradas [nesta p√°gina](https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/).


### Customizando o kubectl

#### Auto-complete

Execute o seguinte comando para configurar o alias e autocomplete para o ``kubectl``.

No Bash:

```bash
source <(kubectl completion bash) # configura o autocomplete na sua sess√£o atual (antes, certifique-se de ter instalado o pacote bash-completion).

echo "source <(kubectl completion bash)" >> ~/.bashrc # add autocomplete permanentemente ao seu shell.
```
&nbsp;
No ZSH:

```bash 
source <(kubectl completion zsh)

echo "[[ $commands[kubectl] ]] && source <(kubectl completion zsh)"
```
&nbsp;
#### Criando um alias para o kubectl

Crie o alias ``k`` para ``kubectl``:

```
alias k=kubectl

complete -F __start_kubectl k
```
&nbsp;
### Criando um cluster Kubernetes

### Criando o cluster em sua m√°quina local

Vamos mostrar algumas op√ß√µes, caso voc√™ queira come√ßar a brincar com o Kubernetes utilizando somente a sua m√°quina local, o seu desktop.

Lembre-se, voc√™ n√£o √© obrigado a testar/utilizar todas as op√ß√µes abaixo, mas seria muito bom caso voc√™ testasse. :D

#### Minikube

##### Requisitos b√°sicos

√â importante frisar que o Minikube deve ser instalado localmente, e n√£o em um *cloud provider*. Por isso, as especifica√ß√µes de *hardware* a seguir s√£o referentes √† m√°quina local.

* Processamento: 1 core;
* Mem√≥ria: 2 GB;
* HD: 20 GB.

##### Instala√ß√£o do Minikube no GNU/Linux

Antes de mais nada, verifique se a sua m√°quina suporta virtualiza√ß√£o. No GNU/Linux, isto pode ser realizado com o seguinte comando:

```
grep -E --color 'vmx|svm' /proc/cpuinfo
```
&nbsp;
Caso a sa√≠da do comando n√£o seja vazia, o resultado √© positivo.

H√° a possibilidade de n√£o utilizar um *hypervisor* para a instala√ß√£o do Minikube, executando-o ao inv√©s disso sobre o pr√≥prio host. Iremos utilizar o Oracle VirtualBox como *hypervisor*, que pode ser encontrado [aqui](https://www.virtualbox.org).

Efetue o download e a instala√ß√£o do ``Minikube`` utilizando os seguintes comandos.

```
curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64

chmod +x ./minikube

sudo mv ./minikube /usr/local/bin/minikube

minikube version
```
&nbsp;
##### Instala√ß√£o do Minikube no MacOS

No MacOS, o comando para verificar se o processador suporta virtualiza√ß√£o √©:

```
sysctl -a | grep -E --color 'machdep.cpu.features|VMX'
```
&nbsp;
Se voc√™ visualizar `VMX` na sa√≠da, o resultado √© positivo.

Efetue a instala√ß√£o do Minikube com um dos dois m√©todos a seguir, podendo optar-se pelo Homebrew ou pelo m√©todo tradicional.

```
sudo brew install minikube

minikube version
```
&nbsp;
Ou:

```
curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64

chmod +x ./minikube

sudo mv ./minikube /usr/local/bin/minikube

minikube version
```
&nbsp;
##### Instala√ß√£o do Minikube no Microsoft Windows

No Microsoft Windows, voc√™ deve executar o comando `systeminfo` no prompt de comando ou no terminal. Caso o retorno deste comando seja semelhante com o descrito a seguir, ent√£o a virtualiza√ß√£o √© suportada.

```
Hyper-V Requirements:     VM Monitor Mode Extensions: Yes
                          Virtualization Enabled In Firmware: Yes
                          Second Level Address Translation: Yes
                          Data Execution Prevention Available: Yes
```
&nbsp;
Caso a linha a seguir tamb√©m esteja presente, n√£o √© necess√°ria a instala√ß√£o de um *hypervisor* como o Oracle VirtualBox:

```
Hyper-V Requirements:     A hypervisor has been detected. Features required for Hyper-V will not be displayed.:     A hypervisor has been detected. Features required for Hyper-V will not be displayed.
```
&nbsp;
Fa√ßa o download e a instala√ß√£o de um *hypervisor* (preferencialmente o [Oracle VirtualBox](https://www.virtualbox.org)), caso no passo anterior n√£o tenha sido acusada a presen√ßa de um. Finalmente, efetue o download do instalador do Minikube [aqui](https://github.com/kubernetes/minikube/releases/latest) e execute-o.


##### Iniciando, parando e excluindo o Minikube

Quando operando em conjunto com um *hypervisor*, o Minikube cria uma m√°quina virtual, onde dentro dela estar√£o todos os componentes do k8s para execu√ß√£o.

√â poss√≠vel selecionar qual *hypervisor* iremos utilizar por padr√£o, atrav√©s no comando abaixo:

```
minikube config set driver <SEU_HYPERVISOR> 
```
&nbsp;
Voc√™ deve substituir <SEU_HYPERVISOR> pelo seu hypervisor, por exemplo o KVM2, QEMU, Virtualbox ou o Hyperkit.


Caso n√£o queria configurar um hypervisor padr√£o, voc√™ pode digitar o comando ``minikube start --driver=hyperkit`` toda vez que criar um novo ambiente. 


##### Certo, e como eu sei que est√° tudo funcionando como deveria?

Uma vez iniciado, voc√™ deve ter uma sa√≠da na tela similar √† seguinte:

```
minikube start

üòÑ  minikube v1.26.0 on Debian bookworm/sid
‚ú®  Using the qemu2 (experimental) driver based on user configuration
üëç  Starting control plane node minikube in cluster minikube
üî•  Creating qemu2 VM (CPUs=2, Memory=6000MB, Disk=20000MB) ...
üê≥  Preparing Kubernetes v1.24.1 on Docker 20.10.16 ...
    ‚ñ™ Generating certificates and keys ...
    ‚ñ™ Booting up control plane ...
    ‚ñ™ Configuring RBAC rules ...
üîé  Verifying Kubernetes components...
    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
üåü  Enabled addons: default-storageclass, storage-provisioner
üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

```

Voc√™ pode ent√£o listar os n√≥s que fazem parte do seu *cluster* k8s com o seguinte comando:

```
kubectl get nodes
```
&nbsp;
A sa√≠da ser√° similar ao conte√∫do a seguir:

```
NAME       STATUS   ROLES           AGE   VERSION
minikube   Ready    control-plane   20s   v1.25.3
```
&nbsp;
Para criar um cluster com mais de um n√≥, voc√™ pode utilizar o comando abaixo, apenas modificando os valores para o desejado:

```
minikube start --nodes 2 -p multinode-cluster

üòÑ  minikube v1.26.0 on Debian bookworm/sid
‚ú®  Automatically selected the docker driver. Other choices: kvm2, virtualbox, ssh, none, qemu2 (experimental)
üìå  Using Docker driver with root privileges
üëç  Starting control plane node minikube in cluster minikube
üöú  Pulling base image ...
üíæ  Downloading Kubernetes v1.24.1 preload ...
    > preloaded-images-k8s-v18-v1...: 405.83 MiB / 405.83 MiB  100.00% 66.78 Mi
    > gcr.io/k8s-minikube/kicbase: 385.99 MiB / 386.00 MiB  100.00% 23.63 MiB p
    > gcr.io/k8s-minikube/kicbase: 0 B [_________________________] ?% ? p/s 11s
üî•  Creating docker container (CPUs=2, Memory=8000MB) ...
üê≥  Preparing Kubernetes v1.24.1 on Docker 20.10.17 ...
    ‚ñ™ Generating certificates and keys ...
    ‚ñ™ Booting up control plane ...
    ‚ñ™ Configuring RBAC rules ...
üîó  Configuring CNI (Container Networking Interface) ...
üîé  Verifying Kubernetes components...
    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
üåü  Enabled addons: storage-provisioner, default-storageclass

üëç  Starting worker node minikube-m02 in cluster minikube
üöú  Pulling base image ...
üî•  Creating docker container (CPUs=2, Memory=8000MB) ...
üåê  Found network options:
    ‚ñ™ NO_PROXY=192.168.11.11
üê≥  Preparing Kubernetes v1.24.1 on Docker 20.10.17 ...
    ‚ñ™ env NO_PROXY=192.168.11.11
üîé  Verifying Kubernetes components...
üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

```
&nbsp;
Para visualizar os n√≥s do seu novo cluster Kubernetes, digite:

```
kubectl get nodes
```
&nbsp;
Inicialmente, a inten√ß√£o do Minikube √© executar o k8s em apenas um n√≥, por√©m a partir da vers√£o 1.10.1 √© poss√≠vel usar a fun√ß√£o de multi-node.

Caso os comandos anteriores tenham sido executados sem erro, a instala√ß√£o do Minikube ter√° sido realizada com sucesso.

##### Ver detalhes sobre o cluster 

```
minikube status
```
&nbsp;
##### Descobrindo o endere√ßo do Minikube

Como dito anteriormente, o Minikube ir√° criar uma m√°quina virtual, assim como o ambiente para a execu√ß√£o do k8s localmente. Ele tamb√©m ir√° configurar o ``kubectl`` para comunicar-se com o Minikube. Para saber qual √© o endere√ßo IP dessa m√°quina virtual, pode-se executar:

```
minikube ip
```
&nbsp;
O endere√ßo apresentado √© que deve ser utilizado para comunica√ß√£o com o k8s.

##### Acessando a m√°quina do Minikube via SSH

Para acessar a m√°quina virtual criada pelo Minikube, pode-se executar:

```
minikube ssh
```
&nbsp;
##### Dashboard do Minikube

O Minikube vem com um *dashboard* *web* interessante para que o usu√°rio iniciante observe como funcionam os *workloads* sobre o k8s. Para habilit√°-lo, o usu√°rio pode digitar:

```
minikube dashboard
```
&nbsp;
##### Logs do Minikube

Os *logs* do Minikube podem ser acessados atrav√©s do seguinte comando.

```
minikube logs
```
&nbsp;
##### Remover o cluster 

```
minikube delete
```
&nbsp;
Caso queira remover o cluster e todos os arquivos referente a ele, utilize o parametro *--purge*, conforme abaixo:

```
minikube delete --purge
```
&nbsp;
#### Kind

O Kind (*Kubernetes in Docker*) √© outra alternativa para executar o Kubernetes num ambiente local para testes e aprendizado, mas n√£o √© recomendado para uso em produ√ß√£o.

##### Instala√ß√£o no GNU/Linux

Para fazer a instala√ß√£o no GNU/Linux, execute os seguintes comandos.

```
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.14.0/kind-linux-amd64

chmod +x ./kind

sudo mv ./kind /usr/local/bin/kind
```
&nbsp;
##### Instala√ß√£o no MacOS

Para fazer a instala√ß√£o no MacOS, execute o seguinte comando.

```
sudo brew install kind
```
&nbsp;
ou

```
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.14.0/kind-darwin-amd64
chmod +x ./kind
mv ./kind /usr/bin/kind
```
&nbsp;
##### Instala√ß√£o no Windows

Para fazer a instala√ß√£o no Windows, execute os seguintes comandos.

```
curl.exe -Lo kind-windows-amd64.exe https://kind.sigs.k8s.io/dl/v0.14.0/kind-windows-amd64

Move-Item .\kind-windows-amd64.exe c:\kind.exe
```
&nbsp;
###### Instala√ß√£o no Windows via Chocolatey

Execute o seguinte comando para instalar o Kind no Windows usando o Chocolatey.

```
choco install kind
```
&nbsp;
##### Criando um cluster com o Kind

Ap√≥s realizar a instala√ß√£o do Kind, vamos iniciar o nosso cluster.

```
kind create cluster

Creating cluster "kind" ...
 ‚úì Ensuring node image (kindest/node:v1.24.0) üñº
 ‚úì Preparing nodes üì¶  
 ‚úì Writing configuration üìú 
 ‚úì Starting control-plane üïπÔ∏è 
 ‚úì Installing CNI üîå 
 ‚úì Installing StorageClass üíæ 
Set kubectl context to "kind-kind"
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Not sure what to do next? üòÖ  Check out https://kind.sigs.k8s.io/docs/user/quick-start/

```
&nbsp;
√â poss√≠vel criar mais de um cluster e personalizar o seu nome.

```
kind create cluster --name giropops

Creating cluster "giropops" ...
 ‚úì Ensuring node image (kindest/node:v1.24.0) üñº
 ‚úì Preparing nodes üì¶  
 ‚úì Writing configuration üìú 
 ‚úì Starting control-plane üïπÔ∏è 
 ‚úì Installing CNI üîå 
 ‚úì Installing StorageClass üíæ 
Set kubectl context to "kind-giropops"
You can now use your cluster with:

kubectl cluster-info --context kind-giropops

Thanks for using kind! üòä
```
&nbsp;
Para visualizar os seus clusters utilizando o kind, execute o comando a seguir.

```
kind get clusters
```
&nbsp;
Liste os nodes do cluster.

```
kubectl get nodes
```
&nbsp;
##### Criando um cluster com m√∫ltiplos n√≥s locais com o Kind

√â poss√≠vel para essa aula incluir m√∫ltiplos n√≥s na estrutura do Kind, que foi mencionado anteriormente.

Execute o comando a seguir para selecionar e remover todos os clusters locais criados no Kind.

```
kind delete clusters $(kind get clusters)

Deleted clusters: ["giropops" "kind"]
```
&nbsp;
Crie um arquivo de configura√ß√£o para definir quantos e o tipo de n√≥s no cluster que voc√™ deseja. No exemplo a seguir, ser√° criado o arquivo de configura√ß√£o ``kind-3nodes.yaml`` para especificar um cluster com 1 n√≥ control-plane (que executar√° o control plane) e 2 workers.

```
cat << EOF > $HOME/kind-3nodes.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
  - role: worker
  - role: worker
EOF
```
&nbsp;
Agora vamos criar um cluster chamado ``kind-multinodes`` utilizando as especifica√ß√µes definidas no arquivo ``kind-3nodes.yaml``.

```
kind create cluster --name kind-multinodes --config $HOME/kind-3nodes.yaml

Creating cluster "kind-multinodes" ...
 ‚úì Ensuring node image (kindest/node:v1.24.0) üñº
 ‚úì Preparing nodes üì¶ üì¶ üì¶  
 ‚úì Writing configuration üìú 
 ‚úì Starting control-plane üïπÔ∏è 
 ‚úì Installing CNI üîå 
 ‚úì Installing StorageClass üíæ 
 ‚úì Joining worker nodes üöú 
Set kubectl context to "kind-kind-multinodes"
You can now use your cluster with:

kubectl cluster-info --context kind-kind-multinodes

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community üôÇ
```
&nbsp;
Valide a cria√ß√£o do cluster com o comando a seguir.

```
kubectl get nodes
```
&nbsp;
Mais informa√ß√µes sobre o Kind est√£o dispon√≠veis em: https://kind.sigs.k8s.io

&nbsp;
### Primeiros passos no k8s
&nbsp;

##### Verificando os namespaces e pods

O k8s organiza tudo dentro de *namespaces*. Por meio deles, podem ser realizadas limita√ß√µes de seguran√ßa e de recursos dentro do *cluster*, tais como *pods*, *replication controllers* e diversos outros. Para visualizar os *namespaces* dispon√≠veis no *cluster*, digite:

```
kubectl get namespaces
```
&nbsp;
Vamos listar os *pods* do *namespace* **kube-system** utilizando o comando a seguir.

```
kubectl get pod -n kube-system
```
&nbsp;
Ser√° que h√° algum *pod* escondido em algum *namespace*? √â poss√≠vel listar todos os *pods* de todos os *namespaces* com o comando a seguir.

```
kubectl get pods -A
```
&nbsp;
H√° a possibilidade ainda, de utilizar o comando com a op√ß√£o ```-o wide```, que disponibiliza maiores informa√ß√µes sobre o recurso, inclusive em qual n√≥ o *pod* est√° sendo executado. Exemplo:

```
kubectl get pods -A -o wide
```
&nbsp;
##### Executando nosso primeiro pod no k8s

Iremos iniciar o nosso primeiro *pod* no k8s. Para isso, executaremos o comando a seguir.

```
kubectl run nginx --image nginx

pod/nginx created
```
&nbsp;
Listando os *pods* com ``kubectl get pods``, obteremos a seguinte sa√≠da.

```
NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          66s
```
&nbsp;
Vamos agora remover o nosso *pod* com o seguinte comando.

```
kubectl delete pod nginx
```
&nbsp;
A sa√≠da deve ser algo como:

```
pod "nginx" deleted
```
&nbsp;

##### Executando nosso primeiro pod no k8s


Uma outra forma de criar um pod ou qualquer outro objeto no Kubernetes √© atrav√©s da utiliza√ß√¢o de uma arquivo manifesto, que √© uma arquivo em formato YAML onde voc√™ passa todas as defini√ß√µes do seu objeto. Mas pra frente vamos falar muito mais sobre como construir arquivos manifesto, mas agora eu quero que voc√™ conhe√ßa a op√ß√£o ``--dry-run`` do ``kubectl``, pos com ele podemos simular a cria√ß√£o de um resource e ainda ter um manifesto criado automaticamente. 

Exemplos:

Para a cria√ß√£o do template de um *pod*:

```
kubectl run meu-nginx --image nginx --dry-run=client -o yaml > pod-template.yaml
```
&nbsp;
Aqui estamos utilizando ainda o parametro '-o', utilizando para modificar a sa√≠da para o formato YAML.

Para a cria√ß√£o do *template* de um *deployment*:

Com o arquivo gerado em m√£os, agora voc√™ consegue criar um pod utilizando o manifesto que criamos da seguinte forma:

```
kubectl apply -f pod-template.yaml
```

N√£o se preocupe por enquanto com o parametro 'apply', n√≥s ainda vamos falar com mais detalhes sobre ele, nesse momento o importante √© voc√™ saber que ele √© utilizado para criar novos resources atrav√©s de arquivos manifestos.

&nbsp;

#### Expondo o pod e criando um Service

Dispositivos fora do *cluster*, por padr√£o, n√£o conseguem acessar os *pods* criados, como √© comum em outros sistemas de cont√™ineres. Para expor um *pod*, execute o comando a seguir.

```
kubectl expose pod nginx
```

Ser√° apresentada a seguinte mensagem de erro:

```
error: couldn't find port via --port flag or introspection
See 'kubectl expose -h' for help and examples
```

O erro ocorre devido ao fato do k8s n√£o saber qual √© a porta de destino do cont√™iner que deve ser exposta (no caso, a 80/TCP). Para configur√°-la, vamos primeiramente remover o nosso *pod* antigo:

```
kubectl delete -f pod-template.yaml
```

Agora vamos executar novamente o comando para a cria√ß√£o do pod utilizando o parametro 'dry-run', por√©m agora vamos adicionar o parametro '--port' para dizer qual a porta que o container est√° escutando, lembrando que estamos utilizando o nginx nesse exemplo, um webserver que escuta por padr√£o na porta 80.



```
kubectl run meu-nginx --image nginx --port 80 --dry-run=client -o yaml > pod-template.yaml
kubectl create -f pod-template.yaml
```

Liste os pods.

```
kubectl get pods

NAME    READY   STATUS    RESTARTS   AGE
meu-nginx   1/1     Running   0          32s
```

O comando a seguir cria um objeto do k8s chamado de *Service*, que √© utilizado justamente para expor *pods* para acesso externo.

```
kubectl expose pod meu-nginx
```

Podemos listar todos os *services* com o comando a seguir.

```
kubectl get services

NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP   8d
nginx        ClusterIP   10.105.41.192   <none>        80/TCP    2m30s
```

Como √© poss√≠vel observar, h√° dois *services* no nosso *cluster*: o primeiro √© para uso do pr√≥prio k8s, enquanto o segundo foi o qu√™ acabamos de criar. 

&nbsp;

#### Limpando tudo e indo para casa

Para mostrar todos os recursos rec√©m criados, pode-se utilizar uma das seguintes op√ß√µes a seguir.

```
kubectl get all

kubectl get pod,service

kubectl get pod,svc
```

Note que o k8s nos disponibiliza algumas abrevia√ß√µes de seus recursos. Com o tempo voc√™ ir√° se familiar com elas. Para apagar os recursos criados, voc√™ pode executar os seguintes comandos.

```
kubectl delete -f pod-template.yaml
kubectl delete service nginx
```

Liste novamente os recursos para ver se os mesmos ainda est√£o presentes.


&nbsp;
