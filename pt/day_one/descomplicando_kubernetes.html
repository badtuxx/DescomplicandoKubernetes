
<!DOCTYPE HTML>
<html lang="pt" >
    <head>
        <meta charset="UTF-8">
        <title>Descomplicando Kubernetes dia 1 ¬∑ HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 3.6.20">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../day_two/descomplicando_kubernetes.html" />
    
    
    <link rel="prev" href="../" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Escreva para pesquisar" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">Sobre</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introdu√ß√£o
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Cap√≠tulos</li>
        
        
    
        <li class="chapter active" data-level="2.1" data-path="descomplicando_kubernetes.html">
            
                <a href="descomplicando_kubernetes.html">
            
                    
                    Descomplicando Kubernetes dia 1
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="../day_two/descomplicando_kubernetes.html">
            
                <a href="../day_two/descomplicando_kubernetes.html">
            
                    
                    Descomplicando Kubernetes dia 2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="../day_three/descomplicando_kubernetes.html">
            
                <a href="../day_three/descomplicando_kubernetes.html">
            
                    
                    Descomplicando Kubernetes dia 3
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="../day_four/descomplicando_kubernetes.html">
            
                <a href="../day_four/descomplicando_kubernetes.html">
            
                    
                    Descomplicando Kubernetes dia 4
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="../day_five/descomplicando_kubernetes.html">
            
                <a href="../day_five/descomplicando_kubernetes.html">
            
                    
                    Descomplicando Kubernetes dia 5
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="../day_six/descomplicando_kubernetes.html">
            
                <a href="../day_six/descomplicando_kubernetes.html">
            
                    
                    Descomplicando Kubernetes dia 6
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Extras</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../extras/cloud-providers/cloud-providers.html">
            
                <a href="../extras/cloud-providers/cloud-providers.html">
            
                    
                    Cloud providers
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="../extras/exame_tips.html">
            
                <a href="../extras/exame_tips.html">
            
                    
                    Dicas para o exame
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="../extras/pod_security_policy.html">
            
                <a href="../extras/pod_security_policy.html">
            
                    
                    Pod security policy
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Contribuir</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="../CONTRIBUTING.html">
            
                <a href="../CONTRIBUTING.html">
            
                    
                    Como ajudar
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Publicado com HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Descomplicando Kubernetes dia 1</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="descomplicando-kubernetes-dia-1">Descomplicando Kubernetes dia 1</h1>
<h2 id="sum√°rio">Sum√°rio</h2>
<ul>
<li><a href="#descomplicando-kubernetes-dia-1">Descomplicando Kubernetes dia 1</a><ul>
<li><a href="#sum√°rio">Sum√°rio</a></li>
</ul>
</li>
<li><a href="#o-qu√™-preciso-saber-antes-de-come√ßar">O qu√™ preciso saber antes de come√ßar?</a><ul>
<li><a href="#qual-distro-gnulinux-devo-usar">Qual distro GNU/Linux devo usar?</a></li>
<li><a href="#alguns-sites-que-devemos-visitar">Alguns sites que devemos visitar</a></li>
<li><a href="#e-o-k8s">E o k8s?</a></li>
<li><a href="#arquitetura-do-k8s">Arquitetura do k8s</a></li>
<li><a href="#portas-que-devemos-nos-preocupar">Portas que devemos nos preocupar</a></li>
<li><a href="#t√°-mas-qual-tipo-de-aplica√ß√£o-eu-devo-rodar-sobre-o-k8s">T√°, mas qual tipo de aplica√ß√£o eu devo rodar sobre o k8s?</a></li>
<li><a href="#conceitos-chave-do-k8s">Conceitos-chave do k8s</a></li>
</ul>
</li>
<li><a href="#aviso-sobre-os-comandos">Aviso sobre os comandos</a></li>
<li><a href="#kubectl">Kubectl</a><ul>
<li><a href="#instala√ß√£o-do-kubectl-no-gnulinux">Instala√ß√£o do Kubectl no GNU/Linux</a></li>
<li><a href="#instala√ß√£o-do-kubectl-no-macos">Instala√ß√£o do Kubectl no MacOS</a></li>
<li><a href="#instala√ß√£o-do-kubectl-no-windows">Instala√ß√£o do Kubectl no Windows</a></li>
<li><a href="#kubectl-alias-e-autocomplete">kubectl: alias e autocomplete</a></li>
</ul>
</li>
<li><a href="#minikube">Minikube</a><ul>
<li><a href="#requisitos-b√°sicos">Requisitos b√°sicos</a></li>
<li><a href="#instala√ß√£o-do-minikube-no-gnulinux">Instala√ß√£o do Minikube no GNU/Linux</a></li>
<li><a href="#instala√ß√£o-do-minikube-no-macos">Instala√ß√£o do Minikube no MacOS</a></li>
<li><a href="#instala√ß√£o-do-minikube-no-microsoft-windows">Instala√ß√£o do Minikube no Microsoft Windows</a></li>
<li><a href="#iniciando-parando-e-excluindo-o-minikube">Iniciando, parando e excluindo o Minikube</a></li>
<li><a href="#certo-e-como-eu-sei-que-est√°-tudo-funcionando-como-deveria">Certo, e como eu sei que est√° tudo funcionando como deveria?</a></li>
<li><a href="#descobrindo-o-endere√ßo-do-minikube">Descobrindo o endere√ßo do Minikube</a></li>
<li><a href="#acessando-a-m√°quina-do-minikube-via-ssh">Acessando a m√°quina do Minikube via SSH</a></li>
<li><a href="#dashboard">Dashboard</a></li>
<li><a href="#logs">Logs</a></li>
</ul>
</li>
<li><a href="#microk8s">Microk8s</a><ul>
<li><a href="#requisitos-b√°sicos-1">Requisitos b√°sicos</a></li>
<li><a href="#instala√ß√£o-do-microk8s-no-gnulinux">Instala√ß√£o do MicroK8s no GNU/Linux</a><ul>
<li><a href="#vers√µes-que-suportam-snap">Vers√µes que suportam Snap</a></li>
</ul>
</li>
<li><a href="#instala√ß√£o-no-windows">Instala√ß√£o no Windows</a><ul>
<li><a href="#instalando-o-chocolatey">Instalando o Chocolatey</a><ul>
<li><a href="#instalando-o-multipass">Instalando o Multipass</a></li>
</ul>
</li>
<li><a href="#utilizando-microk8s-com-multipass">Utilizando Microk8s com Multipass</a></li>
</ul>
</li>
<li><a href="#instalando-o-microk8s-no-macos">Instalando o Microk8s no MacOS</a><ul>
<li><a href="#instalando-o-brew">Instalando o Brew</a></li>
<li><a href="#instalando-o-microk8s-via-brew">Instalando o Microk8s via Brew</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#kind">Kind</a><ul>
<li><a href="#instala√ß√£o-no-gnulinux">Instala√ß√£o no GNU/Linux</a></li>
<li><a href="#instala√ß√£o-no-macos">Instala√ß√£o no MacOS</a></li>
<li><a href="#instala√ß√£o-no-windows-1">Instala√ß√£o no Windows</a><ul>
<li><a href="#instala√ß√£o-no-windows-via-chocolatey">Instala√ß√£o no Windows via Chocolatey</a></li>
</ul>
</li>
<li><a href="#criando-um-cluster-com-o-kind">Criando um cluster com o Kind</a><ul>
<li><a href="#criando-um-cluster-com-m√∫ltiplos-n√≥s-locais-com-o-kind">Criando um cluster com m√∫ltiplos n√≥s locais com o Kind</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#k3s">k3s</a></li>
<li><a href="#instala√ß√£o-do-cluster-kubernetes-em-tr√™s-n√≥s">Instala√ß√£o do cluster Kubernetes em tr√™s n√≥s</a><ul>
<li><a href="#requisitos-b√°sicos-2">Requisitos b√°sicos</a></li>
<li><a href="#configura√ß√£o-de-m√≥dulos-de-kernel">Configura√ß√£o de m√≥dulos de kernel</a></li>
<li><a href="#atualiza√ß√£o-da-distribui√ß√£o">Atualiza√ß√£o da distribui√ß√£o</a></li>
<li><a href="#instala√ß√£o-do-docker-e-do-kubernetes">Instala√ß√£o do Docker e do Kubernetes</a></li>
<li><a href="#inicializa√ß√£o-do-cluster">Inicializa√ß√£o do cluster</a></li>
<li><a href="#configura√ß√£o-do-arquivo-de-contextos-do-kubectl">Configura√ß√£o do arquivo de contextos do kubectl</a></li>
<li><a href="#inserindo-os-n√≥s-workers-no-cluster">Inserindo os n√≥s workers no cluster</a><ul>
<li><a href="#m√∫ltiplas-interfaces">M√∫ltiplas Interfaces</a></li>
</ul>
</li>
<li><a href="#instala√ß√£o-do-pod-network">Instala√ß√£o do pod network</a></li>
<li><a href="#verificando-a-instala√ß√£o">Verificando a instala√ß√£o</a></li>
</ul>
</li>
<li><a href="#primeiros-passos-no-k8s">Primeiros passos no k8s</a><ul>
<li><a href="#exibindo-informa√ß√µes-detalhadas-sobre-os-n√≥s">Exibindo informa√ß√µes detalhadas sobre os n√≥s</a></li>
<li><a href="#exibindo-novamente-token-para-entrar-no-cluster">Exibindo novamente token para entrar no cluster</a></li>
<li><a href="#ativando-o-autocomplete">Ativando o autocomplete</a></li>
<li><a href="#verificando-os-namespaces-e-pods">Verificando os namespaces e pods</a></li>
<li><a href="#executando-nosso-primeiro-pod-no-k8s">Executando nosso primeiro pod no k8s</a></li>
<li><a href="#verificar-os-√∫ltimos-eventos-do-cluster">Verificar os √∫ltimos eventos do cluster</a></li>
<li><a href="#efetuar-o-dump-de-um-objeto-em-formato-yaml">Efetuar o dump de um objeto em formato YAML</a></li>
<li><a href="#socorro-s√£o-muitas-op√ß√µes">Socorro, s√£o muitas op√ß√µes!</a></li>
<li><a href="#expondo-o-pod">Expondo o pod</a></li>
<li><a href="#limpando-tudo-e-indo-para-casa">Limpando tudo e indo para casa</a></li>
</ul>
</li>
</ul>
<h2 id="o-qu√™-preciso-saber-antes-de-come√ßar">O qu√™ preciso saber antes de come√ßar?</h2>
<p>Durante essa sess√£o vamos saber tudo o que precisamos antes de come√ßar a sair criando o nosso cluster ou ent√£o nossos deployments.</p>
<h3 id="qual-distro-gnulinux-devo-usar">Qual distro GNU/Linux devo usar?</h3>
<p>Devido ao fato de algumas ferramentas importantes, como o <code>systemd</code> e <code>journald</code>, terem se tornado padr√£o na maioria das principais distribui√ß√µes dispon√≠veis hoje, voc√™ n√£o deve encontrar problemas para seguir o treinamento, caso voc√™ opte por uma delas, como Ubuntu, Debian, CentOS e afins.</p>
<h3 id="alguns-sites-que-devemos-visitar">Alguns sites que devemos visitar</h3>
<p>Abaixo temos os sites oficiais do projeto do Kubernetes:</p>
<ul>
<li><p><a href="https://kubernetes.io" target="_blank">https://kubernetes.io</a></p>
</li>
<li><p><a href="https://github.com/kubernetes/kubernetes/" target="_blank">https://github.com/kubernetes/kubernetes/</a></p>
</li>
<li><p><a href="https://github.com/kubernetes/kubernetes/issues" target="_blank">https://github.com/kubernetes/kubernetes/issues</a></p>
</li>
</ul>
<p>Abaixo temos as p√°ginas oficiais das certifica√ß√µes do Kubernetes (CKA, CKAD e CKS):</p>
<ul>
<li><p><a href="https://www.cncf.io/certification/cka/" target="_blank">https://www.cncf.io/certification/cka/</a></p>
</li>
<li><p><a href="https://www.cncf.io/certification/ckad/" target="_blank">https://www.cncf.io/certification/ckad/</a></p>
</li>
<li><p><a href="https://www.cncf.io/certification/cks/" target="_blank">https://www.cncf.io/certification/cks/</a></p>
</li>
</ul>
<p>Outro site importante de conhecer e estudar, √© o site dos 12 fatores, muito importante para o desenvolvimento de aplica√ß√µes que tem como objetivo serem executadas em cluster Kubernetes:</p>
<ul>
<li><a href="https://12factor.net/pt_br/" target="_blank">https://12factor.net/pt_br/</a></li>
</ul>
<h2 id="o-que-√©-o-kubernetes">O que √© o Kubernetes?</h2>
<p><strong>Vers√£o resumida:</strong></p>
<p>O projeto Kubernetes foi desenvolvido pela Google, em meados de 2014, para atuar como um orquestrador de cont√™ineres para a empresa. O Kubernetes (k8s), cujo termo em Grego significa &quot;timoneiro&quot;, √© um projeto <em>open source</em> que conta com <em>design</em> e desenvolvimento baseados no projeto Borg, que tamb√©m √© da Google <a href="https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/" target="_blank">1</a>. Alguns outros produtos dispon√≠veis no mercado, tais como o Apache Mesos e o Cloud Foundry, tamb√©m surgiram a partir do projeto Borg.</p>
<p>Como Kubernetes √© uma palavra dif√≠cil de se pronunciar - e de se escrever - a comunidade simplesmente o apelidou de <strong>k8s</strong>, seguindo o padr√£o <a href="http://www.i18nguy.com/origini18n.html" target="_blank">i18n</a> (a letra &quot;k&quot; seguida por oito letras e o &quot;s&quot; no final), pronunciando-se simplesmente &quot;kates&quot;.</p>
<p><strong>Vers√£o longa:</strong></p>
<p>Praticamente todo software desenvolvido na Google √© executado em cont√™iner <a href="https://www.enterpriseai.news/2014/05/28/google-runs-software-containers/" target="_blank">2</a>. A Google j√° gerencia cont√™ineres em larga escala h√° mais de uma d√©cada, quando n√£o se falava tanto sobre isso. Para atender a demanda interna, alguns desenvolvedores do Google constru√≠ram tr√™s sistemas diferentes de gerenciamento de cont√™ineres: <strong>Borg</strong>, <strong>Omega</strong> e <strong>Kubernetes</strong>. Cada sistema teve o desenvolvimento bastante influenciado pelo antecessor, embora fosse desenvolvido por diferentes raz√µes.</p>
<p>O primeiro sistema de gerenciamento de cont√™ineres desenvolvido no Google foi o Borg, constru√≠do para gerenciar servi√ßos de longa dura√ß√£o e jobs em lote, que anteriormente eram tratados por dois sistemas:  <strong>Babysitter</strong> e <strong>Global Work Queue</strong>. O √∫ltimo influenciou fortemente a arquitetura do Borg, mas estava focado em execu√ß√£o de jobs em lote. O Borg continua sendo o principal sistema de gerenciamento de cont√™ineres dentro do Google por causa de sua escala, variedade de recursos e robustez extrema.</p>
<p>O segundo sistema foi o Omega, descendente do Borg. Ele foi impulsionado pelo desejo de melhorar a engenharia de software do ecossistema Borg. Esse sistema aplicou muitos dos padr√µes que tiveram sucesso no Borg, mas foi constru√≠do do zero para ter a arquitetura mais consistente. Muitas das inova√ß√µes do Omega foram posteriormente incorporadas ao Borg.</p>
<p>O terceiro sistema foi o Kubernetes. Concebido e desenvolvido em um mundo onde desenvolvedores externos estavam se interessando em cont√™ineres e o Google desenvolveu um neg√≥cio em amplo crescimento atualmente, que √© a venda de infraestrutura de nuvem p√∫blica.</p>
<p>O Kubernetes √© de c√≥digo aberto - em contraste com o Borg e o Omega que foram desenvolvidos como sistemas puramente internos do Google. O Kubernetes foi desenvolvido com um foco mais forte na experi√™ncia de desenvolvedores que escrevem aplicativos que s√£o executados em um cluster: seu principal objetivo √© facilitar a implanta√ß√£o e o gerenciamento de sistemas distribu√≠dos, enquanto se beneficia do melhor uso de recursos de mem√≥ria e processamento que os cont√™ineres possibilitam.</p>
<p>Estas informa√ß√µes foram extra√≠das e adaptadas deste <a href="https://static.googleusercontent.com/media/research.google.com/pt-BR//pubs/archive/44843.pdf" target="_blank">artigo</a>, que descreve as li√ß√µes aprendidas com o desenvolvimento e opera√ß√£o desses sistemas.</p>
<h3 id="arquitetura-do-k8s">Arquitetura do k8s</h3>
<p>Assim como os demais orquestradores dispon√≠veis, o k8s tamb√©m segue um modelo <em>control plane/workers</em>, constituindo assim um <em>cluster</em>, onde para seu funcionamento √© recomendado no m√≠nimo tr√™s n√≥s: o n√≥ <em>control-plane</em>, respons√°vel (por padr√£o) pelo gerenciamento do <em>cluster</em>, e os demais como <em>workers</em>, executores das aplica√ß√µes que queremos executar sobre esse <em>cluster</em>.</p>
<p>√â poss√≠vel criar um cluster Kubernetes rodando em apenas um n√≥, por√©m √© recomendado somente para fins de estudos e nunca executado em ambiente produtivo.</p>
<p>Caso voc√™ queira utilizar o Kubernetes em sua m√°quina local, em seu desktop, existem diversas solu√ß√µes que ir√£o criar um cluster Kubernetes, utilizando m√°quinas virtuais ou o Docker, por exemplo.</p>
<p>Com isso voc√™ poder√° ter um cluster Kubernetes com diversos n√≥s, por√©m todos eles rodando em sua m√°quina local, em seu desktop.</p>
<p>Alguns exemplos s√£o:</p>
<ul>
<li><p><a href="https://kind.sigs.k8s.io/docs/user/quick-start" target="_blank">Kind</a>: Uma ferramenta para execu√ß√£o de cont√™ineres Docker que simulam o funcionamento de um cluster Kubernetes. √â utilizado para fins did√°ticos, de desenvolvimento e testes. O <strong>Kind n√£o deve ser utilizado para produ√ß√£o</strong>;</p>
</li>
<li><p><a href="https://github.com/kubernetes/minikube" target="_blank">Minikube</a>: ferramenta para implementar um <em>cluster</em> Kubernetes localmente com apenas um n√≥. Muito utilizado para fins did√°ticos, de desenvolvimento e testes. O <strong>Minikube n√£o deve ser utilizado para produ√ß√£o</strong>;</p>
</li>
<li><p><a href="https://microk8s.io" target="_blank">MicroK8S</a>: Desenvolvido pela <a href="https://canonical.com" target="_blank">Canonical</a>, mesma empresa que desenvolve o <a href="https://ubuntu.com" target="_blank">Ubuntu</a>. Pode ser utilizado em diversas distribui√ß√µes e <strong>pode ser utilizado em ambientes de produ√ß√£o</strong>, em especial para <em>Edge Computing</em> e IoT (<em>Internet of things</em>);</p>
</li>
<li><p><a href="https://k3s.io" target="_blank">k3s</a>: Desenvolvido pela <a href="https://rancher.com" target="_blank">Rancher Labs</a>, √© um concorrente direto do MicroK8s, podendo ser executado inclusive em Raspberry Pi.</p>
</li>
<li><p><a href="https://k0sproject.io" target="_blank">k0s</a>: Desenvolvido pela <a href="https://www.mirantis.com" target="_blank">Mirantis</a>, mesma empresa que adquiriu a parte enterprise do <a href="https://www.docker.com" target="_blank">Docker</a>. √â uma distribui√ß√£o do Kubernetes com todos os recursos necess√°rios para funcionar em um √∫nico bin√°rio, que proporciona uma simplicidade na instala√ß√£o e manuten√ß√£o do cluster. A pron√∫ncia √© correta √© kay-zero-ess e tem por objetivo reduzir o esfor√ßo t√©cnico e desgaste na instala√ß√£o de um cluster Kubernetes, por isso o seu nome faz alus√£o a <em>Zero Friction</em>. <strong>O k0s pode ser utilizado em ambientes de produ√ß√£o</strong></p>
</li>
</ul>
<p>A figura a seguir mostra a arquitetura interna de componentes do k8s.</p>
<table>
<thead>
<tr>
<th style="text-align:center"><img src="../../images/kubernetes_architecture.png" alt="Arquitetura Kubernetes"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>Arquitetura Kubernetes <a href="https://phoenixnap.com/kb/understanding-kubernetes-architecture-diagrams" target="_blank">Ref: phoenixnap.com KB article</a></em></td>
</tr>
</tbody>
</table>
<ul>
<li><p><strong>API Server</strong>: √â um dos principais componentes do k8s. Este componente fornece uma API que utiliza JSON sobre HTTP para comunica√ß√£o, onde para isto √© utilizado principalmente o utilit√°rio <code>kubectl</code>, por parte dos administradores, para a comunica√ß√£o com os demais n√≥s, como mostrado no gr√°fico. Estas comunica√ß√µes entre componentes s√£o estabelecidas atrav√©s de requisi√ß√µes <a href="https://restfulapi.net" target="_blank">REST</a>;</p>
</li>
<li><p><strong>etcd</strong>: O etcd √© um <em>datastore</em> chave-valor distribu√≠do que o k8s utiliza para armazenar as especifica√ß√µes, status e configura√ß√µes do <em>cluster</em>. Todos os dados armazenados dentro do etcd s√£o manipulados apenas atrav√©s da API. Por quest√µes de seguran√ßa, o etcd √© por padr√£o executado apenas em n√≥s classificados como <em>control plane</em> no <em>cluster</em> k8s, mas tamb√©m podem ser executados em <em>clusters</em> externos, espec√≠ficos para o etcd, por exemplo;</p>
</li>
<li><p><strong>Scheduler</strong>: O <em>scheduler</em> √© respons√°vel por selecionar o n√≥ que ir√° hospedar um determinado <em>pod</em> (a menor unidade de um <em>cluster</em> k8s - n√£o se preocupe sobre isso por enquanto, n√≥s falaremos mais sobre isso mais tarde) para ser executado. Esta sele√ß√£o √© feita baseando-se na quantidade de recursos dispon√≠veis em cada n√≥, como tamb√©m no estado de cada um dos n√≥s do <em>cluster</em>, garantindo assim que os recursos sejam bem distribu√≠dos. Al√©m disso, a sele√ß√£o dos n√≥s, na qual um ou mais pods ser√£o executados, tamb√©m pode levar em considera√ß√£o pol√≠ticas definidas pelo usu√°rio, tais como afinidade, localiza√ß√£o dos dados a serem lidos pelas aplica√ß√µes, etc;</p>
</li>
<li><p><strong>Controller Manager</strong>: √â o <em>controller manager</em> quem garante que o <em>cluster</em> esteja no √∫ltimo estado definido no etcd. Por exemplo: se no etcd um <em>deploy</em> est√° configurado para possuir dez r√©plicas de um <em>pod</em>, √© o <em>controller manager</em> quem ir√° verificar se o estado atual do <em>cluster</em> corresponde a este estado e, em caso negativo, procurar√° conciliar ambos;</p>
</li>
<li><p><strong>Kubelet</strong>: O <em>kubelet</em> pode ser visto como o agente do k8s que √© executado nos n√≥s workers. Em cada n√≥ worker dever√° existir um agente Kubelet em execu√ß√£o. O Kubelet √© respons√°vel por de fato gerenciar os <em>pods</em>, que foram direcionados pelo <em>controller</em> do <em>cluster</em>, dentro dos n√≥s, de forma que para isto o Kubelet pode iniciar, parar e manter os cont√™ineres e os pods em funcionamento de acordo com o instru√≠do pelo controlador do cluster;</p>
</li>
<li><p><strong>Kube-proxy</strong>: Age como um <em>proxy</em> e um <em>load balancer</em>. Este componente √© respons√°vel por efetuar roteamento de requisi√ß√µes para os <em>pods</em> corretos, como tamb√©m por cuidar da parte de rede do n√≥;</p>
</li>
<li><p><strong>Container Runtime</strong>: O <em>container runtime</em> √© o ambiente de execu√ß√£o de cont√™ineres necess√°rio para o funcionamento do k8s. Desde a vers√£o v1.24 o k8s requer que voc√™ utilize um container runtime compativel com o CRI (Container Runtime Interface) que foi apresentado em 2016 como um interface capaz de criar um padr√£o de comunica√ß√£o entre o container runtime e k8s. Vers√µes anteriores √† v1.24 ofereciam integra√ß√£o direta com o Docker Engine usando um componente chamado dockershim por√©m essa integra√ß√£o direta n√£o est√° mais dispon√≠vel. A documenta√ß√£o oficial do kubernetes (v1.24) apresenta alguns ambientes de execu√ß√£o e suas respectivas configura√ß√µes como o <a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd" target="_blank">containerd</a> um projeto avaliado com o n√≠vel graduado pela CNCF (Cloud Native Computing Foundation) e o <a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cri-o" target="_blank">CRI-0</a> projeto incubado pela CNCF.</p>
</li>
</ul>
<blockquote>
<p>Projetos graduados e incubados pela CNCF s√£o considerados est√°veis ‚Äã‚Äãe utilizados com sucesso em produ√ß√£o.</p>
</blockquote>
<h3 id="portas-que-devemos-nos-preocupar">Portas que devemos nos preocupar</h3>
<p><strong>CONTROL PLANE</strong></p>
<table>
<thead>
<tr>
<th>Protocol</th>
<th>Direction</th>
<th>Port Range</th>
<th>Purpose</th>
<th>Used By</th>
</tr>
</thead>
<tbody>
<tr>
<td>TCP</td>
<td>Inbound</td>
<td>6443*</td>
<td>Kubernetes API server</td>
<td>All</td>
</tr>
<tr>
<td>TCP</td>
<td>Inbound</td>
<td>2379-2380</td>
<td>etcd server client API</td>
<td>kube-apiserver, etcd</td>
</tr>
<tr>
<td>TCP</td>
<td>Inbound</td>
<td>10250</td>
<td>Kubelet API</td>
<td>Self, Control plane</td>
</tr>
<tr>
<td>TCP</td>
<td>Inbound</td>
<td>10251</td>
<td>kube-scheduler</td>
<td>Self</td>
</tr>
<tr>
<td>TCP</td>
<td>Inbound</td>
<td>10252</td>
<td>kube-controller-manager</td>
<td>Self</td>
</tr>
</tbody>
</table>
<ul>
<li>Toda porta marcada por * √© customiz√°vel, voc√™ precisa se certificar que a porta alterada tamb√©m esteja aberta.</li>
</ul>
<p><strong>WORKERS</strong></p>
<table>
<thead>
<tr>
<th>Protocol</th>
<th>Direction</th>
<th>Port Range</th>
<th>Purpose</th>
<th>Used By</th>
</tr>
</thead>
<tbody>
<tr>
<td>TCP</td>
<td>Inbound</td>
<td>10250</td>
<td>Kubelet API</td>
<td>Self, Control plane</td>
</tr>
<tr>
<td>TCP</td>
<td>Inbound</td>
<td>30000-32767</td>
<td>NodePort</td>
<td>Services All</td>
</tr>
</tbody>
</table>
<p>Caso voc√™ opte pelo <a href="https://weave.works" target="_blank">Weave</a> como <em>pod network</em>, devem ser liberadas tamb√©m as portas 6783 (TCP) e 6783/6784 (UDP).</p>
<h3 id="t√°-mas-qual-tipo-de-aplica√ß√£o-eu-devo-rodar-sobre-o-k8s">T√°, mas qual tipo de aplica√ß√£o eu devo rodar sobre o k8s?</h3>
<p>O melhor <em>app</em> para executar em cont√™iner, principalmente no k8s, s√£o aplica√ß√µes que seguem o <a href="https://12factor.net/pt_br/" target="_blank">The Twelve-Factor App</a>.</p>
<h3 id="conceitos-chave-do-k8s">Conceitos-chave do k8s</h3>
<p>√â importante saber que a forma como o k8s gerencia os cont√™ineres √© ligeiramente diferente de outros orquestradores, como o Docker Swarm, sobretudo devido ao fato de que ele n√£o trata os cont√™ineres diretamente, mas sim atrav√©s de <em>pods</em>. Vamos conhecer alguns dos principais conceitos que envolvem o k8s a seguir:</p>
<ul>
<li><p><strong>Pod</strong>: √â o menor objeto do k8s. Como dito anteriormente, o k8s n√£o trabalha com os cont√™ineres diretamente, mas organiza-os dentro de <em>pods</em>, que s√£o abstra√ß√µes que dividem os mesmos recursos, como endere√ßos, volumes, ciclos de CPU e mem√≥ria. Um pod pode possuir v√°rios cont√™ineres;</p>
</li>
<li><p><strong>Deployment</strong>: √â um dos principais <em>controllers</em> utilizados. O <em>Deployment</em>, em conjunto com o <em>ReplicaSet</em>, garante que determinado n√∫mero de r√©plicas de um pod esteja em execu√ß√£o nos n√≥s workers do cluster. Al√©m disso, o Deployment tamb√©m √© respons√°vel por gerenciar o ciclo de vida das aplica√ß√µes, onde caracter√≠sticas associadas a aplica√ß√£o, tais como imagem, porta, volumes e vari√°veis de ambiente, podem ser especificados em arquivos do tipo <em>yaml</em> ou <em>json</em> para posteriormente serem passados como par√¢metro para o <code>kubectl</code> executar o deployment. Esta a√ß√£o pode ser executada tanto para cria√ß√£o quanto para atualiza√ß√£o e remo√ß√£o do deployment;</p>
</li>
<li><p><strong>ReplicaSets</strong>: √â um objeto respons√°vel por garantir a quantidade de pods em execu√ß√£o no n√≥;</p>
</li>
<li><p><strong>Services</strong>: √â uma forma de voc√™ expor a comunica√ß√£o atrav√©s de um <em>ClusterIP</em>, <em>NodePort</em> ou <em>LoadBalancer</em> para distribuir as requisi√ß√µes entre os diversos Pods daquele Deployment. Funciona como um balanceador de carga.</p>
</li>
<li><p><strong>Controller</strong>: √â o objeto respons√°vel por interagir com o <em>API Server</em> e orquestrar algum outro objeto. Um exemplo de objeto desta classe √© o <em>Deployments</em>;</p>
</li>
<li><p><strong>Jobs e CronJobs</strong>: s√£o objetos respons√°veis pelo gerenciamento de jobs isolados ou recorrentes.</p>
</li>
</ul>
<h2 id="importante">Importante!</h2>
<h3 id="aviso-sobre-os-comandos">Aviso sobre os comandos</h3>
<blockquote>
<p><strong>Aten√ß√£o!!!</strong> Antes de cada comando √© apresentado o tipo prompt. Exemplos:</p>
</blockquote>
<pre><code>$ comando1
</code></pre><pre><code># comando2
</code></pre><blockquote>
<p>O prompt que inicia com o caractere &quot;$&quot;, indica que o comando deve ser executado com um usu√°rio comum do sistema operacional.</p>
<p>O prompt que inicia com o caractere &quot;#&quot;, indica que o comando deve ser executado com o usu√°rio <strong>root</strong>.</p>
<p>Voc√™ n√£o deve copiar/colar o prompt, apenas o comando. :-)</p>
</blockquote>
<h2 id="instalando-e-customizando-o-kubectl">Instalando e customizando o Kubectl</h2>
<h3 id="instala√ß√£o-do-kubectl-no-gnulinux">Instala√ß√£o do Kubectl no GNU/Linux</h3>
<p>Vamos instalar o <code>kubectl</code> com os seguintes comandos.</p>
<pre><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl

chmod +x ./kubectl

sudo mv ./kubectl /usr/local/bin/kubectl

kubectl version --client
</code></pre><h3 id="instala√ß√£o-do-kubectl-no-macos">Instala√ß√£o do Kubectl no MacOS</h3>
<p>O <code>kubectl</code> pode ser instalado no MacOS utilizando tanto o <a href="https://brew.sh" target="_blank">Homebrew</a>, quanto o m√©todo tradicional. Com o Homebrew j√° instalado, o kubectl pode ser instalado da seguinte forma.</p>
<pre><code>sudo brew install kubectl

kubectl version --client
</code></pre><p>Ou:</p>
<pre><code>sudo brew install kubectl-cli

kubectl version --client
</code></pre><p>J√° com o m√©todo tradicional, a instala√ß√£o pode ser realizada com os seguintes comandos.</p>
<pre><code>curl -LO &quot;https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl&quot;

chmod +x ./kubectl

sudo mv ./kubectl /usr/local/bin/kubectl

kubectl version --client
</code></pre><h3 id="instala√ß√£o-do-kubectl-no-windows">Instala√ß√£o do Kubectl no Windows</h3>
<p>A instala√ß√£o do <code>kubectl</code> pode ser realizada efetuando o download <a href="https://dl.k8s.io/release/v1.24.3/bin/windows/amd64/kubectl.exe" target="_blank">neste link</a>. </p>
<p>Outras informa√ß√µes sobre como instalar o kubectl no Windows podem ser encontradas <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/" target="_blank">nesta p√°gina</a>.</p>
<h3 id="customizando-o-kubectl">Customizando o kubectl</h3>
<h4 id="auto-complete">Auto-complete</h4>
<p>Execute o seguinte comando para configurar o alias e autocomplete para o <code>kubectl</code>.</p>
<p>No Bash:</p>
<pre><code class="lang-bash"><span class="hljs-built_in">source</span> &lt;(kubectl completion bash) <span class="hljs-comment"># configura o autocomplete na sua sess√£o atual (antes, certifique-se de ter instalado o pacote bash-completion).</span>

<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;source &lt;(kubectl completion bash)&quot;</span> &gt;&gt; ~/.bashrc <span class="hljs-comment"># add autocomplete permanentemente ao seu shell.</span>
</code></pre>
<p>No ZSH:</p>
<pre><code class="lang-bash"><span class="hljs-built_in">source</span> &lt;(kubectl completion zsh)

<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;[[ <span class="hljs-variable">$commands</span>[kubectl] ]] &amp;&amp; source &lt;(kubectl completion zsh)&quot;</span>
</code></pre>
<h4 id="criando-um-alias-para-o-kubectl">Criando um alias para o kubectl</h4>
<p>Crie o alias <code>k</code> para <code>kubectl</code>:</p>
<pre><code>alias k=kubectl

complete -F __start_kubectl k
</code></pre><h2 id="criando-um-cluster-kubernetes">Criando um cluster Kubernetes</h2>
<h3 id="criando-o-cluster-em-sua-m√°quina-local">Criando o cluster em sua m√°quina local</h3>
<p>Vamos mostrar algumas op√ß√µes, caso voc√™ queira come√ßar a brincar com o Kubernetes utilizando somente a sua m√°quina local, o seu desktop.</p>
<p>Lembre-se, voc√™ n√£o √© obrigado a testar/utilizar todas as op√ß√µes abaixo, mas seria muito bom caso voc√™ testasse. :D</p>
<h4 id="minikube">Minikube</h4>
<h5 id="requisitos-b√°sicos">Requisitos b√°sicos</h5>
<p>√â importante frisar que o Minikube deve ser instalado localmente, e n√£o em um <em>cloud provider</em>. Por isso, as especifica√ß√µes de <em>hardware</em> a seguir s√£o referentes √† m√°quina local.</p>
<ul>
<li>Processamento: 1 core;</li>
<li>Mem√≥ria: 2 GB;</li>
<li>HD: 20 GB.</li>
</ul>
<h5 id="instala√ß√£o-do-minikube-no-gnulinux">Instala√ß√£o do Minikube no GNU/Linux</h5>
<p>Antes de mais nada, verifique se a sua m√°quina suporta virtualiza√ß√£o. No GNU/Linux, isto pode ser realizado com o seguinte comando:</p>
<pre><code>grep -E --color &apos;vmx|svm&apos; /proc/cpuinfo
</code></pre><p>Caso a sa√≠da do comando n√£o seja vazia, o resultado √© positivo.</p>
<p>H√° a possibilidade de n√£o utilizar um <em>hypervisor</em> para a instala√ß√£o do Minikube, executando-o ao inv√©s disso sobre o pr√≥prio host. Iremos utilizar o Oracle VirtualBox como <em>hypervisor</em>, que pode ser encontrado <a href="https://www.virtualbox.org" target="_blank">aqui</a>.</p>
<p>Efetue o download e a instala√ß√£o do <code>Minikube</code> utilizando os seguintes comandos.</p>
<pre><code>curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64

chmod +x ./minikube

sudo mv ./minikube /usr/local/bin/minikube

minikube version
</code></pre><h5 id="instala√ß√£o-do-minikube-no-macos">Instala√ß√£o do Minikube no MacOS</h5>
<p>No MacOS, o comando para verificar se o processador suporta virtualiza√ß√£o √©:</p>
<pre><code>sysctl -a | grep -E --color &apos;machdep.cpu.features|VMX&apos;
</code></pre><p>Se voc√™ visualizar <code>VMX</code> na sa√≠da, o resultado √© positivo.</p>
<p>Efetue a instala√ß√£o do Minikube com um dos dois m√©todos a seguir, podendo optar-se pelo Homebrew ou pelo m√©todo tradicional.</p>
<pre><code>sudo brew install minikube

minikube version
</code></pre><p>Ou:</p>
<pre><code>curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64

chmod +x ./minikube

sudo mv ./minikube /usr/local/bin/minikube

minikube version
</code></pre><h5 id="instala√ß√£o-do-minikube-no-microsoft-windows">Instala√ß√£o do Minikube no Microsoft Windows</h5>
<p>No Microsoft Windows, voc√™ deve executar o comando <code>systeminfo</code> no prompt de comando ou no terminal. Caso o retorno deste comando seja semelhante com o descrito a seguir, ent√£o a virtualiza√ß√£o √© suportada.</p>
<pre><code>Hyper-V Requirements:     VM Monitor Mode Extensions: Yes
                          Virtualization Enabled In Firmware: Yes
                          Second Level Address Translation: Yes
                          Data Execution Prevention Available: Yes
</code></pre><p>Caso a linha a seguir tamb√©m esteja presente, n√£o √© necess√°ria a instala√ß√£o de um <em>hypervisor</em> como o Oracle VirtualBox:</p>
<pre><code>Hyper-V Requirements:     A hypervisor has been detected. Features required for Hyper-V will not be displayed.:     A hypervisor has been detected. Features required for Hyper-V will not be displayed.
</code></pre><p>Fa√ßa o download e a instala√ß√£o de um <em>hypervisor</em> (preferencialmente o <a href="https://www.virtualbox.org" target="_blank">Oracle VirtualBox</a>), caso no passo anterior n√£o tenha sido acusada a presen√ßa de um. Finalmente, efetue o download do instalador do Minikube <a href="https://github.com/kubernetes/minikube/releases/latest" target="_blank">aqui</a> e execute-o.</p>
<h5 id="iniciando-parando-e-excluindo-o-minikube">Iniciando, parando e excluindo o Minikube</h5>
<p>Quando operando em conjunto com um <em>hypervisor</em>, o Minikube cria uma m√°quina virtual, onde dentro dela estar√£o todos os componentes do k8s para execu√ß√£o.</p>
<p>√â poss√≠vel selecionar qual <em>hypervisor</em> iremos utilizar por padr√£o, atrav√©s no comando abaixo:</p>
<pre><code>minikube config set driver &lt;SEU_HYPERVISOR&gt;
</code></pre><p>Voc√™ deve substituir <seu_hypervisor> pelo seu hypervisor, por exemplo o KVM2, QEMU, Virtualbox ou o Hyperkit.</seu_hypervisor></p>
<p>Caso n√£o queria configurar um hypervisor padr√£o, voc√™ pode digitar o comando <code>minikube start --driver=hyperkit</code> toda vez que criar um novo ambiente. </p>
<h5 id="certo-e-como-eu-sei-que-est√°-tudo-funcionando-como-deveria">Certo, e como eu sei que est√° tudo funcionando como deveria?</h5>
<p>Uma vez iniciado, voc√™ deve ter uma sa√≠da na tela similar √† seguinte:</p>
<pre><code>minikube start

üòÑ  minikube v1.26.0 on Debian bookworm/sid
‚ú®  Using the qemu2 (experimental) driver based on user configuration
üëç  Starting control plane node minikube in cluster minikube
üî•  Creating qemu2 VM (CPUs=2, Memory=6000MB, Disk=20000MB) ...
üê≥  Preparing Kubernetes v1.24.1 on Docker 20.10.16 ...
    ‚ñ™ Generating certificates and keys ...
    ‚ñ™ Booting up control plane ...
    ‚ñ™ Configuring RBAC rules ...
üîé  Verifying Kubernetes components...
    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
üåü  Enabled addons: default-storageclass, storage-provisioner
üèÑ  Done! kubectl is now configured to use &quot;minikube&quot; cluster and &quot;default&quot; namespace by default
</code></pre><p>Voc√™ pode ent√£o listar os n√≥s que fazem parte do seu <em>cluster</em> k8s com o seguinte comando:</p>
<pre><code>kubectl get nodes
</code></pre><p>A sa√≠da ser√° similar ao conte√∫do a seguir:</p>
<pre><code>kubectl get nodes
NAME       STATUS   ROLES           AGE   VERSION
minikube   Ready    control-plane   26s   v1.24.1
</code></pre><p>Para criar um cluster com mais de um n√≥, voc√™ pode utilizar o comando abaixo, apenas modificando os valores para o desejado:</p>
<pre><code>minikube start --nodes 2 -p multinode-cluster

üòÑ  minikube v1.26.0 on Debian bookworm/sid
‚ú®  Automatically selected the docker driver. Other choices: kvm2, virtualbox, ssh, none, qemu2 (experimental)
üìå  Using Docker driver with root privileges
üëç  Starting control plane node minikube in cluster minikube
üöú  Pulling base image ...
üíæ  Downloading Kubernetes v1.24.1 preload ...
    &gt; preloaded-images-k8s-v18-v1...: 405.83 MiB / 405.83 MiB  100.00% 66.78 Mi
    &gt; gcr.io/k8s-minikube/kicbase: 385.99 MiB / 386.00 MiB  100.00% 23.63 MiB p
    &gt; gcr.io/k8s-minikube/kicbase: 0 B [_________________________] ?% ? p/s 11s
üî•  Creating docker container (CPUs=2, Memory=8000MB) ...
üê≥  Preparing Kubernetes v1.24.1 on Docker 20.10.17 ...
    ‚ñ™ Generating certificates and keys ...
    ‚ñ™ Booting up control plane ...
    ‚ñ™ Configuring RBAC rules ...
üîó  Configuring CNI (Container Networking Interface) ...
üîé  Verifying Kubernetes components...
    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
üåü  Enabled addons: storage-provisioner, default-storageclass

üëç  Starting worker node minikube-m02 in cluster minikube
üöú  Pulling base image ...
üî•  Creating docker container (CPUs=2, Memory=8000MB) ...
üåê  Found network options:
    ‚ñ™ NO_PROXY=192.168.11.11
üê≥  Preparing Kubernetes v1.24.1 on Docker 20.10.17 ...
    ‚ñ™ env NO_PROXY=192.168.11.11
üîé  Verifying Kubernetes components...
üèÑ  Done! kubectl is now configured to use &quot;minikube&quot; cluster and &quot;default&quot; namespace by default
</code></pre><p>Para visualizar os n√≥s do seu novo cluster Kubernetes, digite:</p>
<pre><code>kubectl get nodes

NAME           STATUS   ROLES           AGE   VERSION
minikube       Ready    control-plane   66s   v1.24.1
minikube-m02   Ready    &lt;none&gt;          48s   v1.24.1
</code></pre><p>Inicialmente, a inten√ß√£o do Minikube √© executar o k8s em apenas um n√≥, por√©m a partir da vers√£o 1.10.1 e poss√≠vel usar a fun√ß√£o de multi-node.</p>
<p>Caso os comandos anteriores tenham sido executados sem erro, a instala√ß√£o do Minikube ter√° sido realizada com sucesso.</p>
<h5 id="ver-detalhes-sobre-o-cluster">Ver detalhes sobre o cluster</h5>
<pre><code>minikube status
</code></pre><h5 id="descobrindo-o-endere√ßo-do-minikube">Descobrindo o endere√ßo do Minikube</h5>
<p>Como dito anteriormente, o Minikube ir√° criar uma m√°quina virtual, assim como o ambiente para a execu√ß√£o do k8s localmente. Ele tamb√©m ir√° configurar o <code>kubectl</code> para comunicar-se com o Minikube. Para saber qual √© o endere√ßo IP dessa m√°quina virtual, pode-se executar:</p>
<pre><code>minikube ip
</code></pre><p>O endere√ßo apresentado √© que deve ser utilizado para comunica√ß√£o com o k8s.</p>
<h5 id="acessando-a-m√°quina-do-minikube-via-ssh">Acessando a m√°quina do Minikube via SSH</h5>
<p>Para acessar a m√°quina virtual criada pelo Minikube, pode-se executar:</p>
<pre><code>minikube ssh
</code></pre><h5 id="dashboard">Dashboard</h5>
<p>O Minikube vem com um <em>dashboard</em> <em>web</em> interessante para que o usu√°rio iniciante observe como funcionam os <em>workloads</em> sobre o k8s. Para habilit√°-lo, o usu√°rio pode digitar:</p>
<pre><code>minikube dashboard
</code></pre><h5 id="logs">Logs</h5>
<p>Os <em>logs</em> do Minikube podem ser acessados atrav√©s do seguinte comando.</p>
<pre><code>minikube logs
</code></pre><h5 id="remover-o-cluster">Remover o cluster</h5>
<pre><code>minikube delete
</code></pre><p>Caso queira remover o cluster e todos os arquivos referente a ele, utilize o parametro <em>--purge</em>, conforme abaixo:</p>
<pre><code>minikube delete --purge
</code></pre><h4 id="kind">Kind</h4>
<p>O Kind (<em>Kubernetes in Docker</em>) √© outra alternativa para executar o Kubernetes num ambiente local para testes e aprendizado, mas n√£o √© recomendado para uso em produ√ß√£o.</p>
<h5 id="instala√ß√£o-no-gnulinux">Instala√ß√£o no GNU/Linux</h5>
<p>Para fazer a instala√ß√£o no GNU/Linux, execute os seguintes comandos.</p>
<pre><code>curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.16.0/kind-linux-amd64

chmod +x ./kind

sudo mv ./kind /usr/local/bin/kind
</code></pre><h5 id="instala√ß√£o-no-macos">Instala√ß√£o no MacOS</h5>
<p>Para fazer a instala√ß√£o no MacOS, execute o seguinte comando.</p>
<pre><code>sudo brew install kind
</code></pre><p>ou</p>
<pre><code>Para Intel Macs
[ $(uname -m) = x86_64 ]&amp;&amp; curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.16.0/kind-darwin-amd64
Para M1 / ARM Macs
[ $(uname -m) = arm64 ] &amp;&amp; curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.16.0/kind-darwin-arm64

chmod +x ./kind
mv ./kind /usr/bin/kind
</code></pre><h5 id="instala√ß√£o-no-windows">Instala√ß√£o no Windows</h5>
<p>Para fazer a instala√ß√£o no Windows, execute os seguintes comandos.</p>
<pre><code>curl.exe -Lo kind-windows-amd64.exe https://kind.sigs.k8s.io/dl/v0.14.0/kind-windows-amd64

Move-Item .\kind-windows-amd64.exe c:\kind.exe
</code></pre><h6 id="instala√ß√£o-no-windows-via-chocolatey">Instala√ß√£o no Windows via <a href="https://chocolatey.org/install" target="_blank">Chocolatey</a></h6>
<p>Execute o seguinte comando para instalar o Kind no Windows usando o Chocolatey.</p>
<pre><code>choco install kind
</code></pre><h5 id="criando-um-cluster-com-o-kind">Criando um cluster com o Kind</h5>
<p>Ap√≥s realizar a instala√ß√£o do Kind, vamos iniciar o nosso cluster.</p>
<pre><code>kind create cluster

Creating cluster &quot;kind&quot; ...
 ‚úì Ensuring node image (kindest/node:v1.25.2) üñº
 ‚úì Preparing nodes üì¶  
 ‚úì Writing configuration üìú 
 ‚úì Starting control-plane üïπÔ∏è 
 ‚úì Installing CNI üîå 
 ‚úì Installing StorageClass üíæ 
Set kubectl context to &quot;kind-kind&quot;
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Not sure what to do next? üòÖ  Check out https://kind.sigs.k8s.io/docs/user/quick-start/
</code></pre><p>√â poss√≠vel criar mais de um cluster e personalizar o seu nome.</p>
<pre><code>kind create cluster --name giropops

Creating cluster &quot;giropops&quot; ...
 ‚úì Ensuring node image (kindest/node:v1.25.2) üñº
 ‚úì Preparing nodes üì¶  
 ‚úì Writing configuration üìú 
 ‚úì Starting control-plane üïπÔ∏è 
 ‚úì Installing CNI üîå 
 ‚úì Installing StorageClass üíæ 
Set kubectl context to &quot;kind-giropops&quot;
You can now use your cluster with:

kubectl cluster-info --context kind-giropops

Thanks for using kind! üòä
</code></pre><p>Para visualizar os seus clusters utilizando o kind, execute o comando a seguir.</p>
<pre><code>kind get clusters

kind
giropops
</code></pre><p>Liste os nodes do cluster.</p>
<pre><code>kubectl get nodes

NAME                     STATUS   ROLES           AGE   VERSION
giropops-control-plane   Ready    control-plane   74s   v1.25.2
</code></pre><h5 id="criando-um-cluster-com-m√∫ltiplos-n√≥s-locais-com-o-kind">Criando um cluster com m√∫ltiplos n√≥s locais com o Kind</h5>
<p>√â poss√≠vel para essa aula incluir m√∫ltiplos n√≥s na estrutura do Kind, que foi mencionado anteriormente.</p>
<p>Execute o comando a seguir para selecionar e remover todos os clusters locais criados no Kind.</p>
<pre><code>kind delete clusters $(kind get clusters)

Deleted clusters: [&quot;giropops&quot; &quot;kind&quot;]
</code></pre><p>Crie um arquivo de configura√ß√£o para definir quantos e o tipo de n√≥s no cluster que voc√™ deseja. No exemplo a seguir, ser√° criado o arquivo de configura√ß√£o <code>kind-3nodes.yaml</code> para especificar um cluster com 1 n√≥ control-plane (que executar√° o control plane) e 2 workers.</p>
<pre><code>cat &lt;&lt; EOF &gt; $HOME/kind-3nodes.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
  - role: worker
  - role: worker
EOF
</code></pre><p>Agora vamos criar um cluster chamado <code>kind-multinodes</code> utilizando as especifica√ß√µes definidas no arquivo <code>kind-3nodes.yaml</code>.</p>
<pre><code>kind create cluster --name kind-multinodes --config $HOME/kind-3nodes.yaml

Creating cluster &quot;kind-multinodes&quot; ...
 ‚úì Ensuring node image (kindest/node:v1.25.2) üñº
 ‚úì Preparing nodes üì¶ üì¶ üì¶  
 ‚úì Writing configuration üìú 
 ‚úì Starting control-plane üïπÔ∏è 
 ‚úì Installing CNI üîå 
 ‚úì Installing StorageClass üíæ 
 ‚úì Joining worker nodes üöú 
Set kubectl context to &quot;kind-kind-multinodes&quot;
You can now use your cluster with:

kubectl cluster-info --context kind-kind-multinodes

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community üôÇ
</code></pre><p>Valide a cria√ß√£o do cluster com o comando a seguir.</p>
<pre><code>kubectl get nodes

NAME                            STATUS   ROLES           AGE   VERSION
kind-multinodes-control-plane   Ready    control-plane   52s   v1.25.2
kind-multinodes-worker          Ready    &lt;none&gt;          32s   v1.25.2
kind-multinodes-worker2         Ready    &lt;none&gt;          32s   v1.25.2
</code></pre><p>Mais informa√ß√µes sobre o Kind est√£o dispon√≠veis em: <a href="https://kind.sigs.k8s.io" target="_blank">https://kind.sigs.k8s.io</a></p>
<h3 id="instala√ß√£o-do-cluster-kubernetes-em-tr√™s-n√≥s">Instala√ß√£o do cluster Kubernetes em tr√™s n√≥s</h3>
<h4 id="requisitos-b√°sicos">Requisitos b√°sicos</h4>
<p>Como j√° dito anteriormente, o Minikube √© √≥timo para desenvolvedores, estudos e testes, mas n√£o tem como prop√≥sito a execu√ß√£o em ambiente de produ√ß√£o. Dito isso, a instala√ß√£o de um <em>cluster</em> k8s para o treinamento ir√° requerer pelo menos tr√™s m√°quinas, f√≠sicas ou virtuais, cada qual com no m√≠nimo a seguinte configura√ß√£o:</p>
<ul>
<li><p>Distribui√ß√£o: Debian, Ubuntu, CentOS, Red Hat, Fedora, SuSE;</p>
</li>
<li><p>Processamento: 2 <em>cores</em>;</p>
</li>
<li><p>Mem√≥ria: 2GB.</p>
</li>
</ul>
<h4 id="configura√ß√£o-de-m√≥dulos-e-parametriza√ß√£o-de-kernel">Configura√ß√£o de m√≥dulos e parametriza√ß√£o de kernel</h4>
<p>O k8s requer que certos m√≥dulos do kernel GNU/Linux estejam carregados para seu pleno funcionamento, e que esses m√≥dulos sejam carregados no momento da inicializa√ß√£o do computador. Para tanto, crie o arquivo <code>/etc/modules-load.d/k8s.conf</code> com o seguinte conte√∫do em todos os seus n√≥s.</p>
<pre><code class="lang-bash">vim /etc/modules-load.d/k8s.conf
</code></pre>
<pre><code>br_netfilter
ip_vs
ip_vs_rr
ip_vs_sh
ip_vs_wrr
nf_conntrack_ipv4
overlay
</code></pre><p>Vamos habilitar o repasse de pacotes e fazer com que o <em>iptables</em> gerencie os pacotes que est√£o trafegando pelas <em>brigdes</em>. Para isso vamos utilizar <em>systcl</em> para parametrizar o kernel.</p>
<pre><code class="lang-bash">vim /etc/sysctl.d/k8s.conf
</code></pre>
<pre><code>net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
</code></pre><p>Para ler as novas configura√ß√µes:</p>
<pre><code class="lang-bash">sysctl --system
</code></pre>
<h4 id="atualiza√ß√£o-da-distribui√ß√£o">Atualiza√ß√£o da distribui√ß√£o</h4>
<p>Em distribui√ß√µes Debian e baseadas, como o Ubuntu, execute os comandos a seguir, em cada um de seus n√≥s, para executar atualiza√ß√£o do sistema.</p>
<pre><code>sudo apt update

sudo apt upgrade -y
</code></pre><p>Em distribui√ß√µes Red Hat e baseadas, use o seguinte comando.</p>
<pre><code>sudo yum upgrade -y
</code></pre><h4 id="o-container-runtime">O Container Runtime</h4>
<p>Para que seja poss√≠vel executar os containers nos n√≥s √© necess√°rio ter um <em>container runtime</em> instalado em cada um dos n√≥s.</p>
<p>O <em>container runtime</em> ou o <em>container engine</em> √© o respons√°vel por executar os containers nos n√≥s. Quando voc√™ est√° utilizando containers em sua m√°quina, por exemplo, voc√™ est√° fazendo uso de algum <em>container runtime</em>.</p>
<p>O <em>container runtime</em> √© o respons√°vel por gerenciar as imagens e volumes, √© ele o respons√°vel por garantir que os os recursos que os containers est√£o utilizando est√° devidamente isolados, a vida do container e muito mais.</p>
<p>Hoje temos diversas op√ß√µes para se utilizar como <em>container runtime</em>, que at√© pouco tempo atr√°s tinhamos somente o Docker para esse papel.</p>
<p>Hoje o Docker n√£o √© mais suportado pelo Kubernetes, pois o Docker √© muito mais do que apenas um <em>container runtime</em>. </p>
<p>O Docker Swarm, por exemplo, vem por padr√£o quando voc√™ instala o Docker, ou seja, n√£o faz sentido ter o Docker inteiro sendo que o Kubernetes somente utiliza um peda√ßo pequeno do Docker.</p>
<p>O Kubernetes suporta diversos <em>container runtime</em>, desde que alinhados com o <em>Open Container Interface</em>, o OCI.</p>
<p><em>Container runtimes</em> suportados pelo Kubernetes:</p>
<ul>
<li>containerd</li>
<li>CRI-O</li>
<li>Docker Engine</li>
<li>Mirantis Container Runtime</li>
</ul>
<h5 id="instalando-e-configurando-o-containerd">Instalando e configurando o containerd</h5>
<p>Para instalar o <em>containerd</em> nos n√≥s, utilize o instalador de pacotes padr√£o de sua distribui√ß√£o. Para esse exemplo estou utilizando um Ubuntu Server, ent√£o irei utilizar o <em>apt</em>.</p>
<p>Para que isso seja poss√≠vel vamos adicionar o reposit√≥rio do Docker. Mas n√≥s n√£o iremos instalar o Docker, iremos somente realizar a instala√ß√£o do Containerd.</p>
<pre><code class="lang-bash"><span class="hljs-comment"># Adicionando a chave do reposit√≥rio</span>
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 

sudo add-apt-repository <span class="hljs-string">&quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu <span class="hljs-subst">$(lsb_release -cs)</span> stable&quot;</span>
sudo apt update

<span class="hljs-comment"># Instalando o containerd</span>
sudo apt install -y containerd.io
</code></pre>
<p>Agora vamos criar diret√≥rio que ir√° conter as configura√ß√µes do <em>containerd</em>.</p>
<pre><code class="lang-bash">mkdir -p /etc/containerd
</code></pre>
<p>Agora j√° podemos criar a configura√ß√£o b√°sica para o nosso <em>containerd</em>, lembrando que √© super importante ler a documenta√ß√£o do <em>containerd</em> para que voc√™ possa conhecer todas as op√ß√µes para o seu ambiente.</p>
<pre><code class="lang-bash">containerd config default &gt; /etc/containerd/config.toml
</code></pre>
<p>Agora vamos reiniciar o servi√ßo para que as novas configura√ß√µes entrem em vigor.</p>
<pre><code class="lang-bash"><span class="hljs-comment"># Habilitando o servi√ßo</span>
systemctl <span class="hljs-built_in">enable</span> containerd

<span class="hljs-comment"># Reiniciando o servi√ßo</span>
systemctl restart containerd
</code></pre>
<h5 id="instalando-o-kubeadm">Instalando o kubeadm</h5>
<p>O pr√≥ximo passo √© efetuar a adi√ß√£o dos reposit√≥rios do k8s e efetuar a instala√ß√£o do <code>kubeadm</code>.</p>
<p>Em distribui√ß√µes Debian e baseadas, isso pode ser realizado com os comandos a seguir.</p>
<pre><code>sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https gnupg2

curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

sudo echo &quot;deb http://apt.kubernetes.io/ kubernetes-xenial main&quot; &gt; /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update

sudo apt-get install -y kubelet kubeadm kubectl
</code></pre><p>√â necess√°rio desativar a mem√≥ria swap em todos os n√≥s com o comando a seguir.</p>
<pre><code class="lang-bash">sudo swapoff -a
</code></pre>
<p>Al√©m de comentar a linha referente √† mesma no arquivo <code>/etc/fstab</code>.</p>
<pre><code class="lang-bash">sudo sed -i <span class="hljs-string">&apos;/ swap / s/^\(.*\)$/#\1/g&apos;</span> /etc/fstab
</code></pre>
<p>Ap√≥s esses procedimentos, √© interessante a reinicializa√ß√£o de todos os n√≥s do <em>cluster</em>.</p>
<h5 id="inicializa√ß√£o-do-cluster">Inicializa√ß√£o do cluster</h5>
<p>Antes de inicializarmos o <em>cluster</em>, vamos efetuar o <em>download</em> das imagens que ser√£o utilizadas, executando o comando a seguir no n√≥ que ser√° o <em>control-plane</em>.
Vamos passar o parametro <em>--cri-socket</em> para especificar o caminho do arquivo de socket do nosso <em>container runtime</em>, nesse caso o <em>containerd</em></p>
<pre><code>sudo kubeadm config images pull --cri-socket /run/containerd/containerd.sock
</code></pre><p>Execute o comando a seguir tamb√©m apenas no n√≥ <em>control-plane</em> para a inicializa√ß√£o do cluster. </p>
<p>Estamos passando alguns importantes parametros:</p>
<ul>
<li><p><em>--control-plane-endpoint</em> -&gt; Ip do seu node que ser√° utilizado no cluster. Importante caso voc√™ tenha mais de uma interface ou endere√ßo.</p>
</li>
<li><p><em>--cri-socket</em> -&gt; O arquivo de socket do nosso container runtime.</p>
</li>
<li><p><em>--upload-certs</em> -&gt; Faz o upload do certificado do <em>control plane</em> para o kubeadm-certs  secret.</p>
</li>
</ul>
<pre><code>sudo kubeadm init --upload-certs --control-plane-endpoint=ADICIONE_O_IP_DO_NODE_AQUI  --cri-socket /run/containerd/containerd.sock
</code></pre><p>Opcionalmente, voc√™ tamb√©m pode passar o cidr com a op√ß√£o <em>--pod-network-cidr</em>. O comando obedecer√° a seguinte sintaxe:</p>
<pre><code>sudo kubeadm init --upload-certs --control-plane-endpoint=ADICIONE_O_IP_DO_NODE_AQUI  --cri-socket /run/containerd/containerd.sock --pod-network-cidr 192.168.99.0/24
</code></pre><p>A sa√≠da do comando ser√° algo similar ao mostrado a seguir.</p>
<pre><code>[init] Using Kubernetes version: v1.24.3
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;
[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;
[certs] Generating &quot;ca&quot; certificate and key
[certs] Generating &quot;apiserver&quot; certificate and key
[certs] apiserver serving cert is signed for DNS names [172.31.19.147 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.31.19.147]
[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key
[certs] Generating &quot;front-proxy-ca&quot; certificate and key
[certs] Generating &quot;front-proxy-client&quot; certificate and key
[certs] Generating &quot;etcd/ca&quot; certificate and key
[certs] Generating &quot;etcd/server&quot; certificate and key
[certs] etcd/server serving cert is signed for DNS names [172.31.19.147 localhost] and IPs [172.31.19.147 127.0.0.1 ::1]
[certs] Generating &quot;etcd/peer&quot; certificate and key
[certs] etcd/peer serving cert is signed for DNS names [172.31.19.147 localhost] and IPs [172.31.19.147 127.0.0.1 ::1]
[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key
[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key
[certs] Generating &quot;sa&quot; key and public key
[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;
[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file
[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[kubelet-start] Starting the kubelet
[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;
[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;
[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;
[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;
[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s
[apiclient] All control plane components are healthy after 8.505808 seconds
[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace
[kubelet] Creating a ConfigMap &quot;kubelet-config&quot; in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Storing the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace
[upload-certs] Using certificate key:
55befb249a01aca7be98b3e7209628f4c4f04c6a05c250c4bb084af722452c36
[mark-control-plane] Marking the node 172.31.19.147 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node 172.31.19.147 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule node-role.kubernetes.io/control-plane:NoSchedule]
[bootstrap-token] Using token: q1m5ci.5p2mtgby0s4ek4vr
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace
[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join 172.31.19.147:6443 --token q1m5ci.5p2mtgby0s4ek4vr \
    --discovery-token-ca-cert-hash sha256:45f6437514981d97631bd5d48822c670ec4a548c9768043fca6e5eda0133b934 \
    --control-plane --certificate-key 55befb249a01aca7be98b3e7209628f4c4f04c6a05c250c4bb084af722452c36

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.31.19.147:6443 --token q1m5ci.5p2mtgby0s4ek4vr \
    --discovery-token-ca-cert-hash sha256:45f6437514981d97631bd5d48822c670ec4a548c9768043fca6e5eda0133b934
</code></pre><p>Caso o servidor possua mais de uma interface de rede, voc√™ pode verificar se o IP interno do n√≥ do seu cluster corresponde ao IP da interface esperada com o seguinte comando:</p>
<pre><code>kubectl describe node elliot-1 | grep InternalIP
</code></pre><p>A sa√≠da ser√° algo similar a seguir:</p>
<pre><code>InternalIP:  172.31.19.147
</code></pre><p>Caso o IP n√£o corresponda ao da interface de rede escolhida, voc√™ pode ir at√© o arquivo localizado em <em>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</em> com o editor da sua prefer√™ncia, procure por <em>KUBELET_CONFIG_ARGS</em> e adicione no final a instru√ß√£o --node-ip=<ip da sua prefer√™ncia>. O trecho alterado ser√° semelhante a esse:</ip></p>
<pre><code>Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml --node-ip=192.168.99.2&quot;
</code></pre><p>Salve o arquivo e execute os comandos abaixo para reiniciar a configura√ß√£o e consequentemente o kubelet.</p>
<pre><code>sudo systemctl daemon-reload
sudo systemctl restart kubelet
</code></pre><h4 id="configura√ß√£o-do-arquivo-de-contextos-do-kubectl">Configura√ß√£o do arquivo de contextos do kubectl</h4>
<p>Como dito anteriormente e de forma similar ao Docker Swarm, o pr√≥prio kubeadm j√° mostrar√° os comandos necess√°rios para a configura√ß√£o do <code>kubectl</code>, para que assim possa ser estabelecida comunica√ß√£o com o cluster k8s. Para tanto, execute os seguintes comandos.</p>
<pre><code>mkdir -p $HOME/.kube

cp -i /etc/kubernetes/admin.conf $HOME/.kube/config

sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre><h4 id="inserindo-os-n√≥s-workers-no-cluster">Inserindo os n√≥s workers no cluster</h4>
<p>Para inserir os n√≥s <em>workers</em> ou mais <em>control plane</em> no <em>cluster</em>, basta executar a linha que come√ßa com <code>kubeadm join</code> que vimos na sa√≠da do comando de inicializa√ß√£o do cluster.</p>
<pre><code>You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join 172.31.19.147:6443 --token q1m5ci.5p2mtgby0s4ek4vr \
    --discovery-token-ca-cert-hash sha256:45f6437514981d97631bd5d48822c670ec4a548c9768043fca6e5eda0133b934 \
    --control-plane --certificate-key 55befb249a01aca7be98b3e7209628f4c4f04c6a05c250c4bb084af722452c36

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.31.19.147:6443 --token q1m5ci.5p2mtgby0s4ek4vr \
    --discovery-token-ca-cert-hash sha256:45f6437514981d97631bd5d48822c670ec4a548c9768043fca6e5eda0133b934
</code></pre><p>Conforme notamos na sa√≠da acima temos dois comandos, um para que possamos adicionar mais n√≥s como <em>control plane</em> ou ent√£o para adicionar n√≥s como <em>worker</em>.</p>
<p>Apenas copie e cole o comando nos n√≥s que voc√™ deseja adicionar ao cluster. Nessa linha de comando do <em>kubeadm join</em> j√° estamos passando o IP e porta do nosso primeiro n√≥ <em>control plane</em> e as informa√ß√µes sobre o certificado, informa√ß√µes necess√°rias para que seja poss√≠vel a entrada do n√≥ no cluster.</p>
<p>Lembre-se, o comando abaixo deve ser executado nos n√≥s que ir√£o compor o cluster, no exemplo vamos adicionar mais dois n√≥s como <em>workers</em></p>
<pre><code class="lang-bash">kubeadm join 172.31.19.147:6443 --token q1m5ci.5p2mtgby0s4ek4vr --discovery-token-ca-cert-hash sha256:45f6437514981d97631bd5d48822c670ec4a548c9768043fca6e5eda0133b934 

[preflight] Running pre-flight checks
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with <span class="hljs-string">&apos;kubectl -n kube-system get cm kubeadm-config -o yaml&apos;</span>
[kubelet-start] Writing kubelet configuration to file <span class="hljs-string">&quot;/var/lib/kubelet/config.yaml&quot;</span>
[kubelet-start] Writing kubelet environment file with flags to file <span class="hljs-string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span>
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting <span class="hljs-keyword">for</span> the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run <span class="hljs-string">&apos;kubectl get nodes&apos;</span> on the control-plane to see this node join the cluster.
</code></pre>
<p>Agora no n√≥ <em>control plane</em> verifique os n√≥s que j√° fazem parte do cluster atrav√©s do comando <em>kubectl</em></p>
<pre><code class="lang-bash">kubectl get nodes
NAME               STATUS     ROLES           AGE   VERSION
ip-172-31-19-147   NotReady   control-plane   68s   v1.24.3
ip-172-31-24-77    NotReady   &lt;none&gt;          29s   v1.24.3
ip-172-31-25-32    NotReady   &lt;none&gt;          31s   v1.24.3
</code></pre>
<p>Perceba que os n√≥s ainda n√£o est√£o <em>Ready</em>, pois ainda n√£o instalamos o <em>pod network</em> para resolver a comunica√ß√£o entre pods em diferentes n√≥s.</p>
<h4 id="a-rede-do-kubernetes">A rede do Kubernetes</h4>
<p>Entender como funciona a rede no Kubernetes √© super importante para que voc√™ consiga entender n√£o somente o comportamento do pr√≥prio Kubernetes, como tamb√©m para o entendimento de como as suas aplica√ß√µes se comportam e interagem.
Primeira coisa que devemos entender √© que o Kubernetes n√£o resolve como funciona a comunica√ß√£o de pods em n√≥s diferentes, para que isso seja resolvido √© necess√°rio utilizar o que chamamos de <em>pod networking</em>.</p>
<p>Ou seja, o k8s por padr√£o n√£o fornece uma solu√ß√£o de <em>networking</em> <em>out-of-the-box</em>. </p>
<p>Para resolver esse problema foi criado o <em>Container Network Interface</em>, o <strong>CNI</strong>.
O <em>CNI</em> nada mais √© do que uma especifica√ß√£o e um conjunto de bibliotecas para a cria√ß√£o de solu√ß√µes de <em>pod networking</em>, ou seja, plugins para resolver o problema de comunica√ß√£o entre os pods.</p>
<p>Temos diversas solu√ß√£o de <em>pod networking</em> como <em>add-on</em>, cada qual com funcionalidades diferentes, tais como: <a href="https://github.com/coreos/flannel" target="_blank">Flannel</a>, <a href="http://docs.projectcalico.org/" target="_blank">Calico</a>, <a href="http://romana.io" target="_blank">Romana</a>, <a href="https://www.weave.works/products/weave-net/" target="_blank">Weave-net</a>, entre outros.</p>
<p>√â importante saber as caracteristicas de cada solu√ß√£o e como elas resolvem a comunica√ß√£o entre os pods.</p>
<p>Por exemplo, temos solu√ß√µes que utilizam <em>eBPF</em> como √© o caso do <em>Cilium</em>, ou ainda solu√ß√µes que atuam na camada 3 ou na camada 7 do modelo de referencia OSI. </p>
<p>Dito isso, a melhor coisa √© voc√™ ler os detalhes de cada solu√ß√£o e entender qual a melhor antende suas necessidades.</p>
<p>Eu gosto muito da <strong>Weave-net</strong> e ser√° ela que iremos abordar durante o treinamento, na d√∫vida de qual usar, v√° de <strong>Weave-net</strong>! :)</p>
<p>Para instalar o <em>Weave-net</em> execute o seguinte comando no n√≥ <em>control plane</em>.</p>
<pre><code>kubectl apply -f &quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &apos;\n&apos;)&quot;
</code></pre><p>Para verificar se o <em>pod network</em> foi criado com sucesso, execute o seguinte comando.</p>
<pre><code>kubectl get pods -n kube-system
</code></pre><p>O resultado deve ser semelhante ao mostrado a seguir.</p>
<pre><code>NAMESPACE     NAME                                       READY   STATUS    RESTARTS      AGE
kube-system   coredns-6d4b75cb6d-vjtw5                   1/1     Running   0             2m4s
kube-system   coredns-6d4b75cb6d-xd89l                   1/1     Running   0             2m4s
kube-system   etcd-ip-172-31-19-147                      1/1     Running   0             2m19s
kube-system   kube-apiserver-ip-172-31-19-147            1/1     Running   0             2m18s
kube-system   kube-controller-manager-ip-172-31-19-147   1/1     Running   0             2m18s
kube-system   kube-proxy-djvp4                           1/1     Running   0             103s
kube-system   kube-proxy-f2f57                           1/1     Running   0             2m5s
kube-system   kube-proxy-tshff                           1/1     Running   0             105s
kube-system   kube-scheduler-ip-172-31-19-147            1/1     Running   0             2m18s
kube-system   weave-net-4qfbb                            2/2     Running   1 (22s ago)   28s
kube-system   weave-net-htlrp                            2/2     Running   1 (22s ago)   28s
kube-system   weave-net-nltmv                            2/2     Running   1 (21s ago)   28s
</code></pre><p>Pode-se observar que h√° tr√™s cont√™ineres do Weave-net em execu√ß√£o, um em cada n√≥ do cluster,  provendo a <em>pod networking</em> para o nosso <em>cluster</em>.</p>
<h4 id="verificando-a-instala√ß√£o">Verificando a instala√ß√£o</h4>
<p>Para verificar se a instala√ß√£o est√° funcionando, e se os n√≥s est√£o se comunicando, voc√™ pode executar o comando <code>kubectl get nodes</code> no n√≥ control-plane, que deve lhe retornar algo como o conte√∫do a seguir.</p>
<pre><code class="lang-bash">kubectl get nodes

NAME               STATUS   ROLES           AGE     VERSION
ip-172-31-19-147   Ready    control-plane   2m20s   v1.24.3
ip-172-31-24-77    Ready    &lt;none&gt;          101s    v1.24.3
ip-172-31-25-32    Ready    &lt;none&gt;          103s    v1.24.3
</code></pre>
<h3 id="primeiros-passos-no-k8s">Primeiros passos no k8s</h3>
<h4 id="exibindo-informa√ß√µes-detalhadas-sobre-os-n√≥s">Exibindo informa√ß√µes detalhadas sobre os n√≥s</h4>
<pre><code>kubectl describe node [nome_do_no]
</code></pre><p>Exemplo:</p>
<pre><code>kubectl describe node ip-172-31-19-147

Name:               ip-172-31-19-147
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=ip-172-31-19-147
                    kubernetes.io/os=linux
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///run/containerd/containerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Sun, 07 Aug 2022 07:05:52 +0000
Taints:             node-role.kubernetes.io/control-plane:NoSchedule
                    node-role.kubernetes.io/master:NoSchedule
Unschedulable:      false
Lease:
  HolderIdentity:  ip-172-31-19-147
  AcquireTime:     &lt;unset&gt;
  RenewTime:       Sun, 07 Aug 2022 08:10:33 +0000
Conditions:
  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----                 ------  -----------------                 ------------------                ------                       -------
  NetworkUnavailable   False   Sun, 07 Aug 2022 07:07:56 +0000   Sun, 07 Aug 2022 07:07:56 +0000   WeaveIsUp                    Weave pod has set this
  MemoryPressure       False   Sun, 07 Aug 2022 08:09:15 +0000   Sun, 07 Aug 2022 07:05:49 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure         False   Sun, 07 Aug 2022 08:09:15 +0000   Sun, 07 Aug 2022 07:05:49 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure          False   Sun, 07 Aug 2022 08:09:15 +0000   Sun, 07 Aug 2022 07:05:49 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready                True    Sun, 07 Aug 2022 08:09:15 +0000   Sun, 07 Aug 2022 07:07:58 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled
Addresses:
  InternalIP:  172.31.19.147
  Hostname:    ip-172-31-19-147
Capacity:
  cpu:                2
  ephemeral-storage:  7950756Ki
  hugepages-2Mi:      0
  memory:             4016852Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  7327416718
  hugepages-2Mi:      0
  memory:             3914452Ki
  pods:               110
System Info:
  Machine ID:                 23fb437f79c4489ab1e351f42b69a52c
  System UUID:                ec2e1b61-092b-df48-4c41-f51d2f5e84d7
  Boot ID:                    1e1ce6a2-3cf0-4961-be37-1f15ba5cd232
  Kernel Version:             5.13.0-1029-aws
  OS Image:                   Ubuntu 20.04.4 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  containerd://1.6.6
  Kubelet Version:            v1.24.3
  Kube-Proxy Version:         v1.24.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (8 in total)
....
</code></pre><h5 id="exibindo-novamente-token-para-adicionar-um-novo-n√≥-no-cluster">Exibindo novamente token para adicionar um novo n√≥ no cluster</h5>
<p>Para visualizar novamente o <em>token</em> para inser√ß√£o de novos n√≥s, execute o seguinte comando.</p>
<pre><code>sudo kubeadm token create --print-join-command
</code></pre><h5 id="ativando-o-autocomplete">Ativando o autocomplete</h5>
<p>Em distribui√ß√µes Debian e baseadas, certifique-se que o pacote <code>bash-completion</code> esteja instalado. Instale-o com o comando a seguir.</p>
<pre><code>sudo apt install -y bash-completion
</code></pre><p>Em sistemas Red Hat e baseados, execute:</p>
<pre><code>sudo yum install -y bash-completion
</code></pre><p>Feito isso, execute o seguinte comando.</p>
<pre><code>kubectl completion bash &gt; /etc/bash_completion.d/kubectl
</code></pre><p>Efetue <em>logoff</em> e <em>login</em> para carregar o <em>autocomplete</em>. Caso n√£o deseje, execute:</p>
<pre><code>source &lt;(kubectl completion bash)
</code></pre><h5 id="verificando-os-namespaces-e-pods">Verificando os namespaces e pods</h5>
<p>O k8s organiza tudo dentro de <em>namespaces</em>. Por meio deles, podem ser realizadas limita√ß√µes de seguran√ßa e de recursos dentro do <em>cluster</em>, tais como <em>pods</em>, <em>replication controllers</em> e diversos outros. Para visualizar os <em>namespaces</em> dispon√≠veis no <em>cluster</em>, digite:</p>
<pre><code>kubectl get namespaces

NAME              STATUS   AGE
default           Active   8d
kube-node-lease   Active   8d
kube-public       Active   8d
kube-system       Active   8d
</code></pre><p>Vamos listar os <em>pods</em> do <em>namespace</em> <strong>kube-system</strong> utilizando o comando a seguir.</p>
<pre><code>kubectl get pod -n kube-system

NAME                                       READY   STATUS    RESTARTS       AGE
coredns-6d4b75cb6d-vjtw5                   1/1     Running   0              106m
coredns-6d4b75cb6d-xd89l                   1/1     Running   0              106m
etcd-ip-172-31-19-147                      1/1     Running   0              106m
kube-apiserver-ip-172-31-19-147            1/1     Running   0              106m
kube-controller-manager-ip-172-31-19-147   1/1     Running   0              106m
kube-proxy-djvp4                           1/1     Running   0              106m
kube-proxy-f2f57                           1/1     Running   0              106m
kube-proxy-tshff                           1/1     Running   0              106m
kube-scheduler-ip-172-31-19-147            1/1     Running   0              106m
weave-net-4qfbb                            2/2     Running   1 (104m ago)   105m
weave-net-htlrp                            2/2     Running   1 (104m ago)   105m
weave-net-nltmv                            2/2     Running   1 (104m ago)   105m
</code></pre><p>Ser√° que h√° algum <em>pod</em> escondido em algum <em>namespace</em>? √â poss√≠vel listar todos os <em>pods</em> de todos os <em>namespaces</em> com o comando a seguir.</p>
<pre><code>kubectl get pods --all-namespaces
</code></pre><p>H√° a possibilidade ainda, de utilizar o comando com a op√ß√£o <code>-o wide</code>, que disponibiliza maiores informa√ß√µes sobre o recurso, inclusive em qual n√≥ o <em>pod</em> est√° sendo executado. Exemplo:</p>
<pre><code>kubectl get pods --all-namespaces -o wide

NAMESPACE     NAME                                       READY   STATUS    RESTARTS       AGE    IP              NODE               NOMINATED NODE   READINESS GATES
kube-system   coredns-6d4b75cb6d-vjtw5                   1/1     Running   0              105m   10.32.0.3       ip-172-31-19-147   &lt;none&gt;           &lt;none&gt;
kube-system   coredns-6d4b75cb6d-xd89l                   1/1     Running   0              105m   10.32.0.2       ip-172-31-19-147   &lt;none&gt;           &lt;none&gt;
kube-system   etcd-ip-172-31-19-147                      1/1     Running   0              105m   172.31.19.147   ip-172-31-19-147   &lt;none&gt;           &lt;none&gt;
kube-system   kube-apiserver-ip-172-31-19-147            1/1     Running   0              105m   172.31.19.147   ip-172-31-19-147   &lt;none&gt;           &lt;none&gt;
kube-system   kube-controller-manager-ip-172-31-19-147   1/1     Running   0              105m   172.31.19.147   ip-172-31-19-147   &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-djvp4                           1/1     Running   0              105m   172.31.24.77    ip-172-31-24-77    &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-f2f57                           1/1     Running   0              105m   172.31.19.147   ip-172-31-19-147   &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-tshff                           1/1     Running   0              105m   172.31.25.32    ip-172-31-25-32    &lt;none&gt;           &lt;none&gt;
kube-system   kube-scheduler-ip-172-31-19-147            1/1     Running   0              105m   172.31.19.147   ip-172-31-19-147   &lt;none&gt;           &lt;none&gt;
kube-system   weave-net-4qfbb                            2/2     Running   1 (103m ago)   103m   172.31.19.147   ip-172-31-19-147   &lt;none&gt;           &lt;none&gt;
kube-system   weave-net-htlrp                            2/2     Running   1 (103m ago)   103m   172.31.25.32    ip-172-31-25-32    &lt;none&gt;           &lt;none&gt;
kube-system   weave-net-nltmv                            2/2     Running   1 (103m ago)   103m   172.31.24.77    ip-172-31-24-77    &lt;none&gt;           &lt;none&gt;
</code></pre><h5 id="executando-nosso-primeiro-pod-no-k8s">Executando nosso primeiro pod no k8s</h5>
<p>Iremos iniciar o nosso primeiro <em>pod</em> no k8s. Para isso, executaremos o comando a seguir.</p>
<pre><code>kubectl run nginx --image nginx

pod/nginx created
</code></pre><p>Listando os <em>pods</em> com <code>kubectl get pods</code>, obteremos a seguinte sa√≠da.</p>
<pre><code>NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          66s
</code></pre><p>Vamos olhar agora a descri√ß√£o desse objeto dentro do <em>cluster</em>.</p>
<pre><code>kubectl describe pod nginx

Name:         nginx
Namespace:    default
Priority:     0
Node:         ip-172-31-25-32/172.31.25.32
Start Time:   Sun, 07 Aug 2022 08:53:24 +0000
Labels:       run=nginx
Annotations:  &lt;none&gt;
Status:       Running
IP:           10.40.0.1
IPs:
  IP:  10.40.0.1
Containers:
  nginx:
    Container ID:   containerd://d7ae9933e65477eed7ff04a107fb3a3adb6a634bc713282421bbdf0e1c30bf7b
    Image:          nginx
    Image ID:       docker.io/library/nginx@sha256:ecc068890de55a75f1a32cc8063e79f90f0b043d70c5fcf28f1713395a4b3d49
    Port:           &lt;none&gt;
    Host Port:      &lt;none&gt;
    State:          Running
      Started:      Sun, 07 Aug 2022 08:53:30 +0000
    Ready:          True
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-tmjgq (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  kube-api-access-tmjgq:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       &lt;nil&gt;
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              &lt;none&gt;
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  16s   default-scheduler  Successfully assigned default/nginx to ip-172-31-25-32
  Normal  Pulling    16s   kubelet            Pulling image &quot;nginx&quot;
  Normal  Pulled     10s   kubelet            Successfully pulled image &quot;nginx&quot; in 5.387864178s
  Normal  Created    10s   kubelet            Created container nginx
  Normal  Started    10s   kubelet            Started container nginx
</code></pre><h5 id="verificar-os-√∫ltimos-eventos-do-cluster">Verificar os √∫ltimos eventos do cluster</h5>
<p>Voc√™ pode verificar quais s√£o os √∫ltimos eventos do <em>cluster</em> com o comando <code>kubectl get events</code>. Ser√£o mostrados eventos como: o <em>download</em> de imagens do Docker Hub (ou de outro <em>registry</em> configurado), a cria√ß√£o/remo√ß√£o de <em>pods</em>, etc.</p>
<p>A sa√≠da a seguir mostra o resultado da cria√ß√£o do nosso cont√™iner com Nginx.</p>
<pre><code>kubectl get events

LAST SEEN   TYPE     REASON      OBJECT      MESSAGE
44s         Normal   Scheduled   pod/nginx   Successfully assigned default/nginx to ip-172-31-25-32
44s         Normal   Pulling     pod/nginx   Pulling image &quot;nginx&quot;
38s         Normal   Pulled      pod/nginx   Successfully pulled image &quot;nginx&quot; in 5.387864178s
38s         Normal   Created     pod/nginx   Created container nginx
38s         Normal   Started     pod/nginx   Started container nginx
</code></pre><p>No resultado do comando anterior √© poss√≠vel observar que a execu√ß√£o do nginx ocorreu no <em>namespace</em> default e que a imagem <strong>nginx</strong> n√£o existia no reposit√≥rio local e, sendo assim, teve de ser feito download da imagem.</p>
<h5 id="efetuar-o-dump-de-um-objeto-em-formato-yaml">Efetuar o dump de um objeto em formato YAML</h5>
<p>Assim como quando se est√° trabalhando com <em>stacks</em> no Docker Swarm, normalmente recursos no k8s s√£o declarados em arquivos <strong>YAML</strong> ou <strong>JSON</strong> e depois manipulados atrav√©s do <code>kubectl</code>.</p>
<p>Para nos poupar o trabalho de escrever o arquivo inteiro, pode-se utilizar como <em>template</em> o <em>dump</em> de um objeto j√° existente no k8s, como mostrado a seguir.</p>
<pre><code>kubectl get pod nginx -o yaml &gt; meu-primeiro.yaml
</code></pre><p>Ser√° criado um novo arquivo chamado <code>meu-primeiro.yaml</code>, resultante do redirecionamento da sa√≠da do comando <code>kubectl get pod nginx -o yaml</code>.</p>
<p>Abrindo o arquivo com <code>vim meu-primeiro.yaml</code> (voc√™ pode utilizar o editor que voc√™ preferir), teremos o seguinte conte√∫do.</p>
<pre><code class="lang-yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">creationTimestamp:</span> <span class="hljs-string">&quot;2022-08-07T08:53:24Z&quot;</span>
  <span class="hljs-attr">labels:</span>
    <span class="hljs-attr">run:</span> <span class="hljs-string">nginx</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span>
  <span class="hljs-attr">resourceVersion:</span> <span class="hljs-string">&quot;9598&quot;</span>
  <span class="hljs-attr">uid:</span> <span class="hljs-string">d0928186-bf6d-459b-aca6-9b0d84b40e9c</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">containers:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span>
    <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">Always</span>
    <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span>
    <span class="hljs-attr">resources:</span> {}
    <span class="hljs-attr">terminationMessagePath:</span> <span class="hljs-string">/dev/termination-log</span>
    <span class="hljs-attr">terminationMessagePolicy:</span> <span class="hljs-string">File</span>
    <span class="hljs-attr">volumeMounts:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/run/secrets/kubernetes.io/serviceaccount</span>
      <span class="hljs-attr">name:</span> <span class="hljs-string">kube-api-access-tmjgq</span>
      <span class="hljs-attr">readOnly:</span> <span class="hljs-literal">true</span>
  <span class="hljs-attr">dnsPolicy:</span> <span class="hljs-string">ClusterFirst</span>
  <span class="hljs-attr">enableServiceLinks:</span> <span class="hljs-literal">true</span>
  <span class="hljs-attr">nodeName:</span> <span class="hljs-string">ip-172-31-25-32</span>
  <span class="hljs-attr">preemptionPolicy:</span> <span class="hljs-string">PreemptLowerPriority</span>
  <span class="hljs-attr">priority:</span> <span class="hljs-number">0</span>
  <span class="hljs-attr">restartPolicy:</span> <span class="hljs-string">Always</span>
  <span class="hljs-attr">schedulerName:</span> <span class="hljs-string">default-scheduler</span>
  <span class="hljs-attr">securityContext:</span> {}
  <span class="hljs-attr">serviceAccount:</span> <span class="hljs-string">default</span>
  <span class="hljs-attr">serviceAccountName:</span> <span class="hljs-string">default</span>
  <span class="hljs-attr">terminationGracePeriodSeconds:</span> <span class="hljs-number">30</span>
  <span class="hljs-attr">tolerations:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">effect:</span> <span class="hljs-string">NoExecute</span>
    <span class="hljs-attr">key:</span> <span class="hljs-string">node.kubernetes.io/not-ready</span>
    <span class="hljs-attr">operator:</span> <span class="hljs-string">Exists</span>
    <span class="hljs-attr">tolerationSeconds:</span> <span class="hljs-number">300</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">effect:</span> <span class="hljs-string">NoExecute</span>
    <span class="hljs-attr">key:</span> <span class="hljs-string">node.kubernetes.io/unreachable</span>
    <span class="hljs-attr">operator:</span> <span class="hljs-string">Exists</span>
    <span class="hljs-attr">tolerationSeconds:</span> <span class="hljs-number">300</span>
  <span class="hljs-attr">volumes:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">kube-api-access-tmjgq</span>
    <span class="hljs-attr">projected:</span>
      <span class="hljs-attr">defaultMode:</span> <span class="hljs-number">420</span>
      <span class="hljs-attr">sources:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">serviceAccountToken:</span>
          <span class="hljs-attr">expirationSeconds:</span> <span class="hljs-number">3607</span>
          <span class="hljs-attr">path:</span> <span class="hljs-string">token</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">configMap:</span>
          <span class="hljs-attr">items:</span>
          <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">ca.crt</span>
            <span class="hljs-attr">path:</span> <span class="hljs-string">ca.crt</span>
          <span class="hljs-attr">name:</span> <span class="hljs-string">kube-root-ca.crt</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">downwardAPI:</span>
          <span class="hljs-attr">items:</span>
          <span class="hljs-bullet">-</span> <span class="hljs-attr">fieldRef:</span>
              <span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
              <span class="hljs-attr">fieldPath:</span> <span class="hljs-string">metadata.namespace</span>
            <span class="hljs-attr">path:</span> <span class="hljs-string">namespace</span>
<span class="hljs-attr">status:</span>
  <span class="hljs-attr">conditions:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">lastProbeTime:</span> <span class="hljs-literal">null</span>
    <span class="hljs-attr">lastTransitionTime:</span> <span class="hljs-string">&quot;2022-08-07T08:53:24Z&quot;</span>
    <span class="hljs-attr">status:</span> <span class="hljs-string">&quot;True&quot;</span>
    <span class="hljs-attr">type:</span> <span class="hljs-string">Initialized</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">lastProbeTime:</span> <span class="hljs-literal">null</span>
    <span class="hljs-attr">lastTransitionTime:</span> <span class="hljs-string">&quot;2022-08-07T08:53:30Z&quot;</span>
    <span class="hljs-attr">status:</span> <span class="hljs-string">&quot;True&quot;</span>
    <span class="hljs-attr">type:</span> <span class="hljs-string">Ready</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">lastProbeTime:</span> <span class="hljs-literal">null</span>
    <span class="hljs-attr">lastTransitionTime:</span> <span class="hljs-string">&quot;2022-08-07T08:53:30Z&quot;</span>
    <span class="hljs-attr">status:</span> <span class="hljs-string">&quot;True&quot;</span>
    <span class="hljs-attr">type:</span> <span class="hljs-string">ContainersReady</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">lastProbeTime:</span> <span class="hljs-literal">null</span>
    <span class="hljs-attr">lastTransitionTime:</span> <span class="hljs-string">&quot;2022-08-07T08:53:24Z&quot;</span>
    <span class="hljs-attr">status:</span> <span class="hljs-string">&quot;True&quot;</span>
    <span class="hljs-attr">type:</span> <span class="hljs-string">PodScheduled</span>
  <span class="hljs-attr">containerStatuses:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">containerID:</span> <span class="hljs-string">containerd://d7ae9933e65477eed7ff04a107fb3a3adb6a634bc713282421bbdf0e1c30bf7b</span>
    <span class="hljs-attr">image:</span> <span class="hljs-string">docker.io/library/nginx:latest</span>
    <span class="hljs-attr">imageID:</span> <span class="hljs-string">docker.io/library/nginx@sha256:ecc068890de55a75f1a32cc8063e79f90f0b043d70c5fcf28f1713395a4b3d49</span>
    <span class="hljs-attr">lastState:</span> {}
    <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span>
    <span class="hljs-attr">ready:</span> <span class="hljs-literal">true</span>
    <span class="hljs-attr">restartCount:</span> <span class="hljs-number">0</span>
    <span class="hljs-attr">started:</span> <span class="hljs-literal">true</span>
    <span class="hljs-attr">state:</span>
      <span class="hljs-attr">running:</span>
        <span class="hljs-attr">startedAt:</span> <span class="hljs-string">&quot;2022-08-07T08:53:30Z&quot;</span>
  <span class="hljs-attr">hostIP:</span> <span class="hljs-number">172.31</span><span class="hljs-number">.25</span><span class="hljs-number">.32</span>
  <span class="hljs-attr">phase:</span> <span class="hljs-string">Running</span>
  <span class="hljs-attr">podIP:</span> <span class="hljs-number">10.40</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>
  <span class="hljs-attr">podIPs:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">ip:</span> <span class="hljs-number">10.40</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>
  <span class="hljs-attr">qosClass:</span> <span class="hljs-string">BestEffort</span>
  <span class="hljs-attr">startTime:</span> <span class="hljs-string">&quot;2022-08-07T08:53:24Z&quot;</span>
</code></pre>
<p>Observando o arquivo anterior, notamos que este reflete o <strong>estado</strong> do <em>pod</em>. N√≥s desejamos utilizar tal arquivo apenas como um modelo, e sendo assim, podemos apagar as entradas que armazenam dados de estado desse <em>pod</em>, como <em>status</em> e todas as demais configura√ß√µes que s√£o espec√≠ficas dele. O arquivo final ficar√° com o conte√∫do semelhante a este:</p>
<pre><code class="lang-yaml">  <span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
  <span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
  <span class="hljs-attr">metadata:</span>
    <span class="hljs-attr">labels:</span>
      <span class="hljs-attr">run:</span> <span class="hljs-string">nginx</span>
    <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span>
  <span class="hljs-attr">spec:</span>
    <span class="hljs-attr">containers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span>
      <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span>
      <span class="hljs-attr">resources:</span> {}
    <span class="hljs-attr">dnsPolicy:</span> <span class="hljs-string">ClusterFirst</span>
    <span class="hljs-attr">restartPolicy:</span> <span class="hljs-string">Always</span>
  <span class="hljs-attr">status:</span> {}
</code></pre>
<p>Vamos agora remover o nosso <em>pod</em> com o seguinte comando.</p>
<pre><code>kubectl delete pod nginx
</code></pre><p>A sa√≠da deve ser algo como:</p>
<pre><code>pod &quot;nginx&quot; deleted
</code></pre><p>Vamos recri√°-lo, agora a partir do nosso arquivo YAML.</p>
<pre><code>kubectl create -f meu-primeiro.yaml

pod/nginx created
</code></pre><p>Observe que n√£o foi necess√°rio informar ao <code>kubectl</code> qual tipo de recurso seria criado, pois isso j√° est√° contido dentro do arquivo.</p>
<p>Listando os <em>pods</em> dispon√≠veis com o seguinte comando.</p>
<pre><code>kubectl get pods
</code></pre><p>Deve-se obter uma sa√≠da similar √† esta:</p>
<pre><code>NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          109s
</code></pre><p>Uma outra forma de criar um arquivo de <em>template</em> √© atrav√©s da op√ß√£o <code>--dry-run</code> do <code>kubectl</code>, com o funcionamento ligeiramente diferente dependendo do tipo de recurso que ser√° criado. Exemplos:</p>
<p>Para a cria√ß√£o do template de um <em>pod</em>:</p>
<pre><code>kubectl run meu-nginx --image nginx --dry-run=client -o yaml &gt; pod-template.yaml
</code></pre><p>Para a cria√ß√£o do <em>template</em> de um <em>deployment</em>:</p>
<pre><code>kubectl create deployment meu-nginx --image=nginx --dry-run=client -o yaml &gt; deployment-template.yaml
</code></pre><p>A vantagem deste m√©todo √© que n√£o h√° a necessidade de limpar o arquivo, al√©m de serem apresentadas apenas as op√ß√µes necess√°rias do recurso.</p>
<h4 id="socorro-s√£o-muitas-op√ß√µes">Socorro, s√£o muitas op√ß√µes!</h4>
<p>Calma, n√≥s sabemos. Mas o <code>kubectl</code> pode lhe auxiliar um pouco em rela√ß√£o a isso. Ele cont√©m a op√ß√£o <code>explain</code>, que voc√™ pode utilizar caso precise de ajuda com alguma op√ß√£o em espec√≠fico dos arquivos de recurso. A seguir alguns exemplos de sintaxe.</p>
<pre><code>kubectl explain [recurso]

kubectl explain [recurso.caminho.para.spec]

kubectl explain [recurso.caminho.para.spec] --recursive
</code></pre><p>Exemplos:</p>
<pre><code>kubectl explain deployment

kubectl explain pod --recursive

kubectl explain deployment.spec.template.spec
</code></pre><h4 id="expondo-o-pod-e-criando-um-service">Expondo o pod e criando um Service</h4>
<p>Dispositivos fora do <em>cluster</em>, por padr√£o, n√£o conseguem acessar os <em>pods</em> criados, como √© comum em outros sistemas de cont√™ineres. Para expor um <em>pod</em>, execute o comando a seguir.</p>
<pre><code>kubectl expose pod nginx
</code></pre><p>Ser√° apresentada a seguinte mensagem de erro:</p>
<pre><code>error: couldn&apos;t find port via --port flag or introspection
See &apos;kubectl expose -h&apos; for help and examples
</code></pre><p>O erro ocorre devido ao fato do k8s n√£o saber qual √© a porta de destino do cont√™iner que deve ser exposta (no caso, a 80/TCP). Para configur√°-la, vamos primeiramente remover o nosso <em>pod</em> antigo:</p>
<pre><code>kubectl delete -f meu-primeiro.yaml
</code></pre><p>Abra agora o arquivo <code>meu-primeiro.yaml</code> e adicione o bloco a seguir.</p>
<pre><code class="lang-yaml"><span class="hljs-string">...</span>
<span class="hljs-attr">spec:</span>
       <span class="hljs-attr">containers:</span>
       <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span>
         <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">Always</span>
         <span class="hljs-attr">ports:</span>
         <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span>
         <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span>
         <span class="hljs-attr">resources:</span> {}
<span class="hljs-string">...</span>
</code></pre>
<blockquote>
<p><strong>Aten√ß√£o!!!</strong> Arquivos YAML utilizam para sua tabula√ß√£o dois espa√ßos e n√£o <em>tab</em>.</p>
</blockquote>
<p>Feita a modifica√ß√£o no arquivo, salve-o e crie novamente o <em>pod</em> com o comando a seguir.</p>
<pre><code>kubectl create -f meu-primeiro.yaml

pod/nginx created
</code></pre><p>Liste o pod.</p>
<pre><code>kubectl get pod nginx

NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          32s
</code></pre><p>O comando a seguir cria um objeto do k8s chamado de <em>Service</em>, que √© utilizado justamente para expor <em>pods</em> para acesso externo.</p>
<pre><code>kubectl expose pod nginx
</code></pre><p>Podemos listar todos os <em>services</em> com o comando a seguir.</p>
<pre><code>kubectl get services

NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   8d
nginx        ClusterIP   10.105.41.192   &lt;none&gt;        80/TCP    2m30s
</code></pre><p>Como √© poss√≠vel observar, h√° dois <em>services</em> no nosso <em>cluster</em>: o primeiro √© para uso do pr√≥prio k8s, enquanto o segundo foi o qu√™ acabamos de criar. Utilizando o <code>curl</code> contra o endere√ßo IP mostrado na coluna <em>CLUSTER-IP</em>, deve nos ser apresentada a tela principal do Nginx.</p>
<pre><code>curl 10.105.41.192

&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
&lt;p&gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&lt;/p&gt;

&lt;p&gt;For online documentation and support please refer to
&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
Commercial support is available at
&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre><p>Este <em>pod</em> est√° dispon√≠vel para acesso a partir de qualquer n√≥ do <em>cluster</em>.</p>
<h4 id="limpando-tudo-e-indo-para-casa">Limpando tudo e indo para casa</h4>
<p>Para mostrar todos os recursos rec√©m criados, pode-se utilizar uma das seguintes op√ß√µes a seguir.</p>
<pre><code>kubectl get all

kubectl get pod,service

kubectl get pod,svc
</code></pre><p>Note que o k8s nos disponibiliza algumas abrevia√ß√µes de seus recursos. Com o tempo voc√™ ir√° se familiar com elas. Para apagar os recursos criados, voc√™ pode executar os seguintes comandos.</p>
<pre><code>kubectl delete -f meu-primeiro.yaml

kubectl delete service nginx
</code></pre><p>Liste novamente os recursos para ver se os mesmos ainda est√£o presentes.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../" class="navigation navigation-prev " aria-label="Previous page: Introdu√ß√£o">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../day_two/descomplicando_kubernetes.html" class="navigation navigation-next " aria-label="Next page: Descomplicando Kubernetes dia 2">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Descomplicando Kubernetes dia 1","level":"2.1","depth":1,"next":{"title":"Descomplicando Kubernetes dia 2","level":"2.2","depth":1,"path":"day_two/descomplicando_kubernetes.md","ref":"day_two/descomplicando_kubernetes.md","articles":[]},"previous":{"title":"Introdu√ß√£o","level":"1.1","depth":1,"path":"README.md","ref":"README.md","articles":[]},"dir":"ltr"},"config":{"plugins":[],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"language":"pt","gitbook":"*"},"file":{"path":"day_one/descomplicando_kubernetes.md","mtime":"2022-11-14T14:20:36.937Z","type":"markdown"},"gitbook":{"version":"3.6.20","time":"2022-11-14T14:20:51.130Z"},"basePath":"..","book":{"language":"pt"}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="../../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

